<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GAMES101课程笔记（八）——Cameras, Lenses and Light Fields</title>
      <link href="/2024/07/29/games101-ke-cheng-bi-ji-ba-cameras-lenses-and-light-fields/"/>
      <url>/2024/07/29/games101-ke-cheng-bi-ji-ba-cameras-lenses-and-light-fields/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（八）——Cameras-Lenses-and-Light-Fields"><a href="#GAMES101课程笔记（八）——Cameras-Lenses-and-Light-Fields" class="headerlink" title="GAMES101课程笔记（八）——Cameras, Lenses and Light Fields"></a>GAMES101课程笔记（八）——Cameras, Lenses and Light Fields</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>相机、透镜与光场，今天的这个章节其实并不是图形学专属的主题，我们主要来谈谈成像相关的一些知识，比起图形学其实更偏向于物理学。内容总的来说还是挺基础的，就算没看过本系列之前的内容，应该也能够进行消化。</p><p>其实吧，咱们搞图形的，多学点物理挺好的，毕竟我们的目的是为了呈现出想象中的视觉效果，必然脱离不了这些知识（尤其是光学）。闲话也不多说，咱们直接进入今天的主题。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><p><a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a></p><p><a href="/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/">GAMES101课程笔记（四）——Geometry</a></p><p><a href="">GAMES101课程笔记（五）——Ray Tracing</a></p><p><a href="">GAMES101课程笔记（七）——Advanced Topics in Rendering</a></p><h2 id="成像"><a href="#成像" class="headerlink" title="成像"></a>成像</h2><p>此前的课程中，我们提到过光栅化成像和光线追踪成像，它们其实都属于同一种成像方法——合成。</p><p>成像的方法主要就是合成和捕捉，刚才说到的合成是指用一些本来不存在于自然界中的东西进行成像；相对地，捕捉指的就是将现实生活中存在的东西进行成像，最简单的例子就是用相机拍摄。</p><p><img src="1.png" width="50%"></p><h2 id="相机"><a href="#相机" class="headerlink" title="相机"></a>相机</h2><p>那么我们就从相机开始，这里给出一个相机的剖面图：</p><p><img src="2.png" width="40%"></p><p>可以看到相机内包含多个透镜和感光元件，接下来我们就来介绍一下相机的工作原理。</p><h3 id="基本构造"><a href="#基本构造" class="headerlink" title="基本构造"></a>基本构造</h3><p>虽然现在我们提到相机，会很自然地联想到其<strong>镜头</strong>上的透镜，但在更早以前，人们对成像的认知还是通过小孔：</p><p><img src="3.png" width="40%"></p><p>基于这种原理的相机被称为针孔相机，如上图上，它假定对象上每一点会向小孔反射一条光线，最后这些光线在传感器上成像。不过针孔相机基本上已经被淘汰了，现在的相机大都基于上图下的这种透镜成像，原理这里就先不细究了。</p><p>在镜头之后，就是相机的<strong>快门</strong>了，这个部件是用来控制光进入感光元件的时间：</p><p><img src="4.png" width="40%"></p><p>光线通过快门后，需要被捕捉才能成像，<strong>传感器</strong>就是这个用于捕捉的部件：</p><p><img src="5.png" width="40%"></p><p>值得一提的是，传感器记录的物理量就是Irradiance，这也能解释为什么一定需要一个透镜（或者小孔），才能正常成像。</p><p><img src="6.png" width="30%"></p><p>如上图所示，由于Irradiance记录各个方向上的能量，所以直接使用传感器的话，传感器上任一点都会收到对象上所有点反射的能量，导致无法成像。</p><p>不过小孔和透镜的原理并不一样，小孔是控制进入光线的数量（这么说并不严谨），理想情况下只留下一个点的光线；透镜是将进入光线的方向聚焦到一点，避免出现上图中的情况。</p><h3 id="针孔相机"><a href="#针孔相机" class="headerlink" title="针孔相机"></a>针孔相机</h3><p>虽说针孔相机逐渐被淘汰了，但它依然是可以使用的，下图展示了一个用硬纸板制作的针孔相机：</p><p><img src="7.png" width="40%"></p><p>这里再展示一张世界上最大的针孔相机照片：</p><p><img src="8.png" width="40%"></p><p>针孔相机拍摄的照片并没有深度信息，其所有像素都是锐利的，没有现代相机的“虚化”效果，这个话题我们后面会具体说明。</p><h3 id="Field-of-View（FOV）——视场"><a href="#Field-of-View（FOV）——视场" class="headerlink" title="Field of View（FOV）——视场"></a>Field of View（FOV）——视场</h3><p>FOV——视场，是我们在聊到摄像时经常提到的一个名词，FOV代表了相机能拍摄到多大的范围，其定义式为：</p><script type="math/tex; mode=display">\mathrm{FOV}=2\arctan{\frac{h}{2f}}</script><p>其中$h$指的是传感器的长度（FOV一般会在水平和竖直两个方向上定义），$f$是相机的焦距，一般传感器的大小不会改变，所以在真实世界中，影响FOV的主要因素是相机的焦距，焦距越大，FOV越小：</p><p><img src="9.png" width="40%"></p><p>一般我们购买相机时，看到的参数却并非FOV，而是只标注焦距，这会有一个问题：FOV需要胶片（传感器）大小和焦距二者决定，只给出焦距的情况下，我不就无法得知FOV了吗？</p><p>这里的焦距其实是“等效焦距”，由于历史原因，现在这种标注的焦距都是假设胶片大小为35mm下的等效焦距：</p><p><img src="10.png" width="40%"></p><p>例如我们买手机的时候，看见手机摄像头参数为28mm，显然这是不现实的，手机总共就这么点厚度，根本塞不下这么大一个摄像头。</p><p>这是因为手机的传感器比较小，放到35mm胶片的等效焦距下，自然比实际焦距大很多。</p><p>以下是不同FOV下的拍摄效果：</p><p><img src="11.png" width="50%"></p><h3 id="Exposure——曝光"><a href="#Exposure——曝光" class="headerlink" title="Exposure——曝光"></a>Exposure——曝光</h3><p>接下来我们介绍另外一个概念——曝光，其表达式如下：</p><script type="math/tex; mode=display">\mathrm{H(Exposure)}=\mathrm{T(Time)}×\mathrm{E(Irradiance)}</script><p>其中曝光时间由快门决定，而Irradiance则会受到很多方面的影响，例如光圈、焦距等。</p><p>在真实摄影中，影响成像的因素主要有以下三点：</p><ol><li><p>光圈大小：</p><p>光圈是仿照人的瞳孔进行设计的，目的在于控制光进入的多少，显然当光圈比较大时，Irradiance越大，反之越小。</p></li><li><p>快门速度：</p><p>快门的速度实际影响的是传感器接受光线的持续时间，持续时间越长，曝光度越高。</p></li><li><p>ISO（感光度）：</p><p>感光度用以修正传感器值到实际像素值的过程，可以是硬件实现也能是软件实现（例如放大几倍）。</p></li></ol><p>这里展示不同参数组合下的照片效果：</p><p><img src="12.png" width="50%"></p><p>接下来我们给出各个参数的“基本”介绍，<strong>注意，这里的介绍并不正确，只是简单地进行理解</strong>，后期我们会给出正确的原理。</p><h4 id="光圈"><a href="#光圈" class="headerlink" title="光圈"></a>光圈</h4><p>光圈大小用F数（缩写为FN或者F/N）来进行表达，F数越大，光圈越小（这里的逗号是欧洲写法，代表的其实就是小数点）。当光圈很小时，相机就接近于针孔相机，照片的各个像素都会变得锐利；当光圈很大，照片上的某些深度区域就会出现虚化现象。</p><p>FN代表光圈大小的倒数，通过增大光圈，可以增加相同时间内的曝光度：</p><p><img src="13.png" width="50%"></p><h4 id="快门速度"><a href="#快门速度" class="headerlink" title="快门速度"></a>快门速度</h4><p>快门速度直接用时间进行衡量，单位为秒。假设拍摄一个正在奔跑的人，用短时间的快门更容易捕获其某个时刻的动作，如果快门的时间过长，会导致传感器记录下对象这段时间内的运动，导致照片模糊。</p><p>不光是因为对象移动，即使是自己拍照时手抖也会出现这种问题，这被称之为运动模糊（Motion blur）：</p><p><img src="14.png" width="40%"></p><p>但运动模糊不一定是坏事，因为在一张静态照片中，如果想要表达动感，就需要这种模糊，如下图：</p><p><img src="15.png" width="50%"></p><p>明显感觉左图更有锤击的感觉，右图更像是锤子悬浮在半空。</p><p>之前我们聊到反走样时，用模糊来解决反走样的问题，如果把这里的运动理解为在时间维度上采样，那运动模糊的使用其实和解决反走样的思路是非常相似的。</p><p>另外快门还有一个问题——Rolling shutter。当物体的运动速度极快时，每个像素上采集到的不一定是同一时刻的光照，从而导致照片出现扭曲，如下图中飞机的螺旋桨：</p><p><img src="16.png" width="50%"></p><h4 id="ISO"><a href="#ISO" class="headerlink" title="ISO"></a>ISO</h4><p>ISO的话，我们就暂且理解为将像素值按照对应比例放大，例如200就是在100的基础上再翻一倍。增大ISO可以增加照片的亮度，但同时也会使得信号里的噪点更加明显，出现预期之外的成像（变得更加noisy）。</p><p><img src="17.png" width="50%"></p><h4 id="光圈与快门"><a href="#光圈与快门" class="headerlink" title="光圈与快门"></a>光圈与快门</h4><p>从之前的内容来看，如果我们因为拍摄需求不得不调整参数，例如为了拍摄一张静态照片，必须使用很短的快门时间，会导致曝光度的下降。为了解决这个问题，可以调整光圈的大小，使得单位时间进入的光照更多，从曝光度的计算式来看，这其实是令光圈和快门达到了一种平衡。（不过严格来说，并非简单相乘）</p><p><img src="18.png" width="50%"></p><p>上图中的这些参数组合，最后拍摄出来的曝光度都是差不多的，在现实中，这种技巧非常有用，两个代表例子就是高速摄影和低速摄影。</p><h5 id="高速摄影"><a href="#高速摄影" class="headerlink" title="高速摄影"></a>高速摄影</h5><p>高速摄像用于拍摄运动物体某些时刻的样子，因此快门时间非常短，此时就需要调大光圈，维持曝光度：</p><p><img src="19.png" width="30%"></p><h5 id="低速摄影"><a href="#低速摄影" class="headerlink" title="低速摄影"></a>低速摄影</h5><p>低速摄影的光圈非常小，但有很长的快门时间，可以记录下物体的运动轨迹，也被称为“延时摄影”：</p><p><img src="20.png" width="40%"></p><h2 id="薄透镜近似"><a href="#薄透镜近似" class="headerlink" title="薄透镜近似"></a>薄透镜近似</h2><p>目前市面上的相机都不是用简单的一个透镜来做镜头，一般都是使用一个透镜组，结构非常复杂：</p><p><img src="21.png" width="30%"></p><p>另外还有一些奇怪的透镜，它们并不能把平行光聚于一点，这种情况被称为Aberration：</p><p><img src="22.png" width="40%"></p><p>这里我们先讨论我们理想中的透镜。</p><h3 id="焦点"><a href="#焦点" class="headerlink" title="焦点"></a>焦点</h3><p>在理想薄透镜中，平行光穿过透镜后，最终会聚集到一点上：</p><p><img src="23.png" width="40%"></p><p>这一点被称之为<strong>焦点</strong>，而焦点到透镜中心的距离就是<strong>焦距</strong>。</p><p>由于光路是可逆的，因此理想薄透镜还有另一个性质：从焦点处射出的光线经过透镜后，会变成平行光。</p><p>另外再补充一条性质：穿过透镜中心的光线，方向不会发生改变。</p><p>总结一下：</p><ol><li>平行光经过透镜后，会聚集到焦点。</li><li>从焦点处射出的光线经过透镜后，会变成平行光。</li><li>穿过透镜中心的光线，方向不会发生改变。</li></ol><p>除了上述三条性质，<strong>在以下的讨论中，我们认为透镜的焦距是可以调整的</strong>。这其实是现代摄像机使用透镜组的一个好处，通过不同透镜间的排列组合，能够调整整个镜头的焦距。</p><h3 id="薄透镜公式"><a href="#薄透镜公式" class="headerlink" title="薄透镜公式"></a>薄透镜公式</h3><p>假设我们有这样一个场景：</p><p><img src="24.png" width="50%"></p><p>左侧箭头代表物体，右侧箭头代表成像，其中物体到透镜的距离为$z_0$，这个距离称为<strong>物距</strong>；成像到透镜的距离为$z_i$，这个距离称为<strong>像距</strong>。</p><p>初中物理课上我们应该都学过，焦距、物距和相距满足：</p><script type="math/tex; mode=display">\frac{1}{f}=\frac{1}{z_0}+\frac{1}{z_i}</script><p>这个公式的推理其实并不复杂，其实就是借助于两对相似三角形：</p><p><img src="25.png" width="50%"></p><p>通过蓝色和红色的两对相似三角形，我们可以获得两组等式：</p><script type="math/tex; mode=display">\frac{h_0}{z_0-f}=\frac{h_i}{f} \\\frac{h_0}{f}=\frac{h_i}{z_i-f}</script><p>经过一些简单的代换和变形，就能获得上述公式，这里就直接贴一张推导的过程图在这里了：</p><p><img src="26.png" width="40%"></p><h3 id="Defocus-Blur——散焦模糊"><a href="#Defocus-Blur——散焦模糊" class="headerlink" title="Defocus Blur——散焦模糊"></a>Defocus Blur——散焦模糊</h3><p>考虑这样一个场景，我们有一个很小的点物体，它反射的光线经过透镜后聚集在一点上（使用上述公式），但我的传感器平面却不在这个距离上，而是比像距更远，如下图所示：</p><p><img src="27.png" width="50%"></p><p>此时由该点反射的光线分散到了一片区域（圆形）上，这个区域被称之为Circle of Confusion（CoC），同样使用相似三角形性质，有：</p><script type="math/tex; mode=display">\frac{C}{A}=\frac{d'}{z_i}=\frac{|z_s-z_i|}{z_i}</script><p>当各个距离都维持不变时，CoC的大小和光圈直径$A$成正比，由于一点的光线被分散，最终的照片上会出现模糊，这就是散焦模糊。</p><p>下图中印证了这一点，大光圈中，散焦模糊会更加明显：</p><p><img src="28.png" width="50%"></p><p>到这里我们可以来正确定义一下光圈F数的含义了，F数的正确定义是<strong>焦距和光圈直径的比值</strong>，即：</p><script type="math/tex; mode=display">N=\frac{f}{A}</script><p>从而有：</p><script type="math/tex; mode=display">C=A\frac{|z_s-z_i|}{z_i}=\frac{f}{N}\frac{|z_s-z_i|}{z_i}</script><p>因此F数越大，整个图像就更加锐利：</p><p><img src="29.png" width="40%"></p><h3 id="使用透镜的光线追踪"><a href="#使用透镜的光线追踪" class="headerlink" title="使用透镜的光线追踪"></a>使用透镜的光线追踪</h3><p>回想之前我们介绍的光线追踪算法，其实默认都使用的是小孔成像的原理，我们可以将刚才的透镜引入，渲染出下图这样的效果：</p><p><img src="30.png" width="50%"></p><p>为了实现这个目标，我们自然需要定义很多属性，这里给出一种定义方式：</p><ul><li>选定传感器大小，透镜焦距和光圈大小</li><li>选定兴趣平面的位置$z_0$（就是要着重拍摄的距离）</li><li>运用薄透镜公式，计算出传感器到透镜的距离$z_i$</li></ul><p><img src="31.png" width="50%"></p><p>具体的渲染过程为：</p><ul><li>对于传感器上的每一点$x’$：<ul><li>在透镜平面上随机采样一点$x’’$</li><li>假设有光线$x’x’’$，可以计算出该光线会被折射到兴趣平面上一点$x’’’$</li><li>估计光线$x’’x’’’$上的Irradiance</li></ul></li></ul><h3 id="景深"><a href="#景深" class="headerlink" title="景深"></a>景深</h3><p>我们之前提到过，光圈的大小会影响模糊的范围，现在我们来具体探讨一下这个问题：</p><p><img src="32.png" width="50%"></p><p>其实就是在聚焦的过程中，理想焦点前后的一小块区域内，CoC的面积非常小，因而这部分图像的清晰度会很高：</p><p><img src="33.png" width="50%"></p><p>而这部分区域对应的，真实世界中的物体到相机的距离，就被称之为<strong>景深</strong>，接下来我们来看看景深如何计算：</p><p><img src="34.png" width="50%"></p><p>上图左侧这片区域对应的距离就是景深，右侧对应的就是CoC很小的那块区域。</p><p>这张图看上去很复杂，其实用到的无非还是之前的公式，列出右边六条公式后简单解一下，就可以得到景深（DOF）的公式。</p><h2 id="Light-Field-Lumigraph——光场"><a href="#Light-Field-Lumigraph——光场" class="headerlink" title="Light Field/Lumigraph——光场"></a>Light Field/Lumigraph——光场</h2><p>光场，对应的英文名有Light Field和Lumigraph两个，这属于历史遗留问题，我们就不再纠结这个问题。</p><p>在说明光场之前，我们先想象这样一个普通的场景：我们坐在椅子上观察这个世界，最终形成了一副二维的图像。</p><p><img src="35.png" width="50%"></p><p>现在我们在这个过程中改动一点点：我们在房间中拉上一块幕布，但这块幕布严格地将之前的光线复刻，那在我们眼中的图像，看上去就像没发生任何变化一样。</p><p><img src="36.png" width="50%"></p><p>（这其实就是虚拟现实的原理）</p><h4 id="全光函数"><a href="#全光函数" class="headerlink" title="全光函数"></a>全光函数</h4><p>这里我们提出一个概念——全光函数，它用以描述我们可以看到的所有东西的集合。</p><p><img src="37.png" width="50%"></p><p>现在这个描述听上去非常抽象，接下来我们从最简单的全光函数开始，一层层理解。</p><p>由于需要描述空间中观察任何角度时的信息，全光函数一定会有<strong>角度</strong>作为参数，告诉我们向某个方向观测时，获取到的值：</p><p><img src="38.png" width="50%"></p><p>由于只有一个值，所以此时的全光函数只能描述灰度。</p><p>为了加入颜色，我们可以再引入一个参数——<strong>波长</strong>，表示该方向上特定波长光的值：</p><p><img src="39.png" width="50%"></p><p>这样，全光函数就包含了颜色信息。</p><p>接着我们考虑时间维度，为了能包含所有东西，自然要加上一个时间参数：</p><p><img src="40.png" width="50%"></p><p>最后，我们让观测者可以在空间中任何一地方，在函数中加上观测者的位置参数：</p><p><img src="41.png" width="50%"></p><p>现在这个函数涵盖了所有空间和时间，真的可以描述我们可以看到的所有东西，这便是全光函数。</p><p>全光函数的示意图如下，不过要注意的是，全光函数是连续值，而下图中只绘制了部分，因此看上去是离散的：</p><p><img src="42.png" width="40%"></p><p>而我们要介绍的光场，就是全光函数中的一个部分。</p><h4 id="光场"><a href="#光场" class="headerlink" title="光场"></a>光场</h4><p>正式定义光场之前，我们要先定义光线，回忆我们定义过的光线，当时我们是这么做的：</p><p><img src="43.png" width="40%"></p><p>即使用一个起点（3维）和一个方向（2维）来定义一条光线，这里使用了5个维度。</p><p>不过在光场这个背景下，我们只需要一个点（2维）和一个方向（2维）就可以定义一条光线：</p><p><img src="44.png" width="40%"></p><p>这样就只需要4个维度，接下来我们解释为什么。</p><p>假设我们要描述一个物体，我们只需要描述从任何角度看向该物体的信息，根据光路的可逆性，这就等同于描述物体向所有方向放射出的光照信息：</p><p><img src="45.png" width="30%"></p><p>于这些信息就是我们的主角——光场，光场被定义为：在任何一个位置，向任何一个方向放出的光的强度。</p><p>根据前面的知识，我们知道，物体的包围盒可以展开为二维表面，因此可以用二维坐标来表示包围盒上任意一点，因此在光场背景下，我们只需要4个维度描述光线。</p><p>有了光场，我们可以从任何角度观察物体，通过光场获得对应的光照强度，从而进行渲染：</p><p><img src="46.png" width="30%"></p><p>此时，物体本身的形状并不是必须的，就像本节最开始举的例子一样，我们完全可以使用一个“幕布”，在上面复刻光场信息，这也就做到了用四维描述该物体的所有光照信息：</p><p><img src="47.png" width="30%"></p><p>此时我们使用坐标+方向的方式来定义光线，相当于使用了一个附加了角度的平面来定义光场：</p><p><img src="48.png" width="30%"></p><p>我们知道，方向其实是可以用两点来表示的，所以还可以用两个平面来定义光场：</p><p><img src="49.png" width="30%"></p><p>这样就把在平面上任意一点的任意方向，转化为了在两个平面上各取一点，因此次平时描述光场时，往往使用$(u,v)$加上$(s,t)$的方式：</p><p><img src="50.png" width="30%"></p><p>我们可以从两个角度来理解这种双平面的表达方式，如下所示：</p><p><img src="51.png" width="50%"></p><p>上半表示固定$(u,v)$，观察整个$st$平面，这样每个$(u,v)$坐标都相当于一个针孔相机，看见的是从不同角度观察到的完整场景。</p><p>下半表示固定$(s,t)$，从$uv$平面上任意点观察该点，这样其实是获得了从所有角度观察点$(s,t)$的情况，也就是该像素上不同角度的Radiance。</p><p>斯坦福大学就依据光场原理搭建了一个相机矩阵：</p><p><img src="52.png" width="30%"></p><p>通过该相机矩阵，可以大致还原一个场景的所有光照信息。</p><p>不过在生物界中，本身就有光场原理的完美应用——复眼：</p><p><img src="53.png" width="50%"></p><p>假设我们有来自三个方向的光，也就是图中的蓝绿红光（注意，这里不代表光的颜色，只是为了区分光的颜色）。在复眼的每个晶状体上，并没有简单地将三个方向上的光进行简单的叠加，而是将其“分”到了不同的位置上，这样就保留下了角度信息。</p><p>用我们之前的知识来说，就是此时，记录下的信息不再是Irradiance，而是Radiance。</p><h4 id="光场相机"><a href="#光场相机" class="headerlink" title="光场相机"></a>光场相机</h4><p>光场相机和复眼的原理非常像，由于它能记录下Radiance信息，所以可以实现<strong>先拍照、再调整</strong>的效果。</p><p>在课程PPT中给了一个例子，但由于图片数量有点多，不方便在博客中展示，这里就贴出链接：</p><p><a href="https://sites.cs.ucsb.edu/~lingqi/teaching/resources/GAMES101_Lecture_20.pdf">GAMES101_Lecture_20 (ucsb.edu)</a></p><p>（主要就是拍摄完后，可以调整聚焦平面的位置，达到自己想要的成像效果）</p><p>以下是光场相机的结构，不难发现和复眼真的非常类似：</p><p><img src="54.png" width="50%"></p><p>原先我们只在像素上存储光线强度的叠加，而在光场相机中，用微透镜替代像素，进行了分光操作，此时像素拓展为一个区域，区域内的各个像素记录了不同角度的Radiance。</p><p>当我们想要获得正常的相片时，只需要在每个区域内，获取特定方向的Radiance，每个Radiance占据一像素，重新组合为相片即可：</p><p><img src="55.png" width="20%"></p><p>由于光场相机本质上就是记录了光场，自然也可以实现重新聚焦的过程，不过这里就不详细展开了。</p><p>不过光场相机也有如下几个缺点：</p><ul><li>分辨率不足。由于用区域来记录原来一个像素的信息，使用分辨率相同的胶片，分辨率会较低。</li><li>高成本。一是由于分辨率问题，要采用分辨率更高的胶片才能达到原先的效果；二是微透镜的制作成本更高。</li></ul><p>这些问题其实和在编程时，我们遇到的空间和时间之间的抉择是类似，整个图形学其实就是一个trade-off的过程。</p><p>好了，本篇文章就此结束，真是一篇很好的摄影入门教程啊（雾）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（七）——Advanced Topics in Rendering</title>
      <link href="/2024/07/02/games101-ke-cheng-bi-ji-qi-advanced-topics-in-rendering/"/>
      <url>/2024/07/02/games101-ke-cheng-bi-ji-qi-advanced-topics-in-rendering/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（七）——Advanced-Topics-in-Rendering"><a href="#GAMES101课程笔记（七）——Advanced-Topics-in-Rendering" class="headerlink" title="GAMES101课程笔记（七）——Advanced Topics in Rendering"></a>GAMES101课程笔记（七）——Advanced Topics in Rendering</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>OK，这篇博客我们来介绍一些高级内容，课程PPT上的标题为“高级光线传播与复杂外观建模”。虽然听上去很难，但其实课程涉及到的部分都没有很深入的介绍，毕竟GAMES101还是属于入门级的课程，因此笔者认为这部分还是偏科普性的，相较于前面的部分（说的就是你，光线追踪），还是简单不少。</p><p>不过也因如此，本文大多数的内容都是纯文字，与之前的风格相比还是有点区别的。</p><p>随着博客的更新，这个系列也开始进入进入倒计时了，不管怎么样，希望自己的这些小小努力能够起到一些作用。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><p><a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a></p><p><a href="/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/">GAMES101课程笔记（四）——Geometry</a></p><p><a href="">GAMES101课程笔记（五）——Ray Tracing</a></p><p><a href="">GAMES101课程笔记（六）——Materials and Appearances</a></p><h2 id="高级光线传播"><a href="#高级光线传播" class="headerlink" title="高级光线传播"></a>高级光线传播</h2><h3 id="无偏-vs-有偏"><a href="#无偏-vs-有偏" class="headerlink" title="无偏 vs. 有偏"></a>无偏 vs. 有偏</h3><p>在计算光照的时候，我们经常使用蒙特卡洛积分法，而具体实施的蒙特卡洛积分法又可以分为无偏和有偏两种。</p><p>无偏，即指使用蒙特卡洛积分法时，结果的期望和实际值永远是一致的；相应地，其他的方法就被归类于有偏的。</p><p>值得一提的是，有偏中有一种特殊情况，就是在有限的样本下，得不到期望的结果，但在样本无穷多时，却又能达到正确的结果，这种方法被特殊地归类于<strong>一致</strong>的，不过它的本质还是一种无偏方法。</p><p>接下来，我们将分别去看看，哪些光线传播算法是无偏的，哪些是有偏的。</p><h3 id="无偏光线传播算法"><a href="#无偏光线传播算法" class="headerlink" title="无偏光线传播算法"></a>无偏光线传播算法</h3><h4 id="Bidirectional-Path-Tracing——双向路径追踪"><a href="#Bidirectional-Path-Tracing——双向路径追踪" class="headerlink" title="Bidirectional Path Tracing——双向路径追踪"></a>Bidirectional Path Tracing——双向路径追踪</h4><p>双向路径追踪（BDPT），顾名思义，是从两个方向开始生成路径。</p><p>在光线追踪一文中，我们介绍过路径追踪算法，当时，我们是从相机出发，寻找一条从相机到光源到光源的路径。而BDPT同时从光源和相机向外寻找路径，这种路径被称为半路径（下图中的实向量），然后将半路径的终点相连（下图中的虚线），就获得了一条路径。</p><p><img src="1.png" width="50%"></p><p>BDPT有其独特的优势，例如下图这个场景中，BDPT（右图）的效果远比路径追踪（左图）要好：</p><p><img src="2.png" width="50%"></p><p>在这个场景中，主要的光源集中在左上角的角落里，整个房间基本都是被间接光照亮的。</p><p>回忆光线追踪的过程，我们的第一次反射大概率是在漫反射表面上，光线很难被选择反射到光源处，所以使用路径追踪时，想要找到一条带有大量能量的路径是比较困难的。</p><p>而BDPT同时从光源引出半路径，因此漫反射的总会落到光源处，从而达到更好的效果。</p><p>但BDPT的缺点也非常明显，就是太难实现了（别看原理简单，真的很难），速度也非常慢</p><h4 id="Metropolis-Light-Transport——MLT"><a href="#Metropolis-Light-Transport——MLT" class="headerlink" title="Metropolis Light Transport——MLT"></a>Metropolis Light Transport——MLT</h4><p>这个算法是以Metropolis这个人的名字命名的，总之我们就直接称呼其简称MLT了，它同样是一种无偏算法。</p><p>MLT使用的原理是马尔科夫链，有过机器学习背景的读者应该会比较了解。马尔科夫链能够从当前样本，生成一个靠近的下一个样本，这与一般算法中的均匀选取或者随机选取有很大的差异。</p><p>蒙特卡洛方法中，我们可以用任意PDF来对目标函数进行积分，但各种PDF其实也有优劣之分，其中效果最好的的PDF其实是和目标函数形状一致时的PDF。而MLT引入马尔科夫链后，能够以任意形状的PDF来进行采样，这意味着它可以用更好的PDF来进行采样。</p><p><img src="3.png" width="50%"></p><p>上图反映了MLT的特点，即非常擅长局部探索困难的光路。MLT的主要思想就是在已有的光路（图中蓝线）上，增添一个扰动，从而形成一条新的光路（图中橙线），以此类推，找到所有的光路。</p><p><img src="4.png" width="50%"></p><p>上图中可以看出，在更复杂的场景下，MLT会有更好的表现。因为MLT只需要一条正确的光路作为种子，就可以源源不断地形成新光路。</p><p><img src="5.png" width="50%"></p><p>MLT的缺点在于难以估计其收敛的时间，而且由于其局部特性，从每个种子向外扩散，因此收敛不一定均匀，一定程度上会导致画面变”脏“（上图），所以MLT通常不会被用来渲染动画。</p><p>（因为帧与帧之间不均匀的收敛会产生明显的“抖动”）</p><h3 id="有偏光线传播算法"><a href="#有偏光线传播算法" class="headerlink" title="有偏光线传播算法"></a>有偏光线传播算法</h3><h4 id="Photon-Mapping——光子映射"><a href="#Photon-Mapping——光子映射" class="headerlink" title="Photon Mapping——光子映射"></a>Photon Mapping——光子映射</h4><p>光子映射是一种有偏的二阶段光线传播算法，非常适用于渲染含有caustics的场景：</p><p>（caustics在上一篇文章中有详细介绍）</p><p><img src="6.png" width="50%"></p><p>接下来我们介绍光子映射算法的两个阶段，这里只介绍光子映射的一种方法。</p><p>首先来看第一阶段，在这个阶段，我们从光源出发，向外射出光子，正常进行反射和折射。不过一旦接触到Diffuse表面，我们就记录这个位置，认为该地方留下了一颗光子，如下图所示：</p><p><img src="7.png" width="40%"></p><p>第二阶段，我们从相机出发，生成半路径，同样也是正常进行反射和折射，直到接触到Diffuse表面。</p><p>下图是光子映射的最后一步——局部密度估计，这一步的主要思路是：带有越多光子的地方，应该会更亮。</p><p><img src="8.png" width="50%"></p><p>具体来说，对于第二步我们找到的接触点，去找到离它最近的N个光子，这N个光子会占据一个区域（上图阴影部分），光子数量除以该区域的面积，就获得了该处的密度。</p><p><img src="9.png" width="25%"></p><p>显而易见的是，N的取值会大大影响最后的渲染效果，如果N的取值较小，会导致更多的噪声；反之若N取值过大，会导致模糊。</p><p>到这里其实就可以解释为什么光子映射是一种有偏算法，因为我们实质上是用了$\Delta N/\Delta A$来代替了$\mathrm{d}N/\mathrm{d}A$。</p><p>如果打出的光子够多，在场景中的密度更高，那么N个光子占据的面积就越小，从而$\Delta N/\Delta A$更逼近$\mathrm{d}N/\mathrm{d}A$，效果也就越真实。理论上说，只要光子是无限的，那么它就能呈现真实效果，所以说光子映射是一致的。</p><h4 id="Vertex-Connection-and-Merging"><a href="#Vertex-Connection-and-Merging" class="headerlink" title="Vertex Connection and Merging"></a>Vertex Connection and Merging</h4><p>这个方法直译为顶点连接与合并，简称为VCM，是一种将BDPT和光子映射结合起来的方法。</p><p><img src="10.png" width="50%"></p><p>上图给出了这个方法的大致示意图，上面那张表示BDPT的过程，在BDPT中，我们先生成半路径，再寻找连接点。</p><p>但BDPT连接时，实际上是将漫反射的光路给定向化了，假如出现了下面那张的情形，即两个半路径的终点几乎在同一个局部区域中时，那就不可能产生从$x^*_2$到$x_2$的漫反射，这两条半路径就相当于“作废“了。</p><p>而在VCM中，下图这种情况发生时，会将这个局部区域用光子映射的方式结合在一起。</p><p>VCM的实施有很多细节和困难，这里也是只介绍其大致思路。</p><h3 id="Instant-Radiosity——实时辐射度"><a href="#Instant-Radiosity——实时辐射度" class="headerlink" title="Instant Radiosity——实时辐射度"></a>Instant Radiosity——实时辐射度</h3><p>接下来介绍另一种算法——实时辐射度算法（IR），它的主要思路是这样的：如果某个表面已经被照亮了，那我们可以认为它们是光源，用它们来照亮其它物体。</p><p><img src="11.png" width="50%"></p><p>不难发现，这和“双向”的思路其实也是相通的。</p><p>IR算法能够快速高质量地生成漫反射表面的光照，但也存在缺点，比如下图：</p><p><img src="12.png" width="30%"></p><p>可以看见在边缘相接处出现了很多奇怪的亮点，这主要是因为该方法对面积采样，而不是对立体角采样，而且该算法也不适用于镜面。</p><h2 id="高级外观建模"><a href="#高级外观建模" class="headerlink" title="高级外观建模"></a>高级外观建模</h2><p>我们之前提到过，外观=材质=BRDF，但事实上远不止此，在这里，我们介绍一些其他的外观建模方法。</p><p>PS：这部分内容都比较偏向介绍，没有深入具体的细节。</p><h3 id="非表面模型"><a href="#非表面模型" class="headerlink" title="非表面模型"></a>非表面模型</h3><h4 id="Participating-Media——散射介质"><a href="#Participating-Media——散射介质" class="headerlink" title="Participating Media——散射介质"></a>Participating Media——散射介质</h4><p>散射介质指那些定义在空间中而非表面上的材质，例如云和雾这类材质。</p><p><img src="13.png" width="40%"></p><p>当光线穿过散射介质时，会发生以下几种情形：</p><p><img src="14.png" width="60%"></p><p>总的来说，其实就是吸收光线和放出光线，有些光线在穿过介质后被散射，有些光线穿过介质后被并入观测路径。</p><p>这里散射可就不是像漫反射一样的均匀散射了，为了定义该散射，引入了<strong>Phase Function（相位函数）</strong>来描述它，如下：</p><p><img src="15.png" width="60%"></p><p>这里就规定了三种相位函数，对应三种散射情形。</p><p>当渲染散射介质时，就和在物体表面应用BRDF差不多，只是将物体表面的反射替换为散射介质的散射，如下图所示：</p><p><img src="16.png" width="60%"></p><p>可以看见在示例的内部，我们同样生成路径，然后计算光照。</p><h4 id="Hair-Appearance——头发材质"><a href="#Hair-Appearance——头发材质" class="headerlink" title="Hair Appearance——头发材质"></a>Hair Appearance——头发材质</h4><p>现在来看另一种材质——头发，相较于我们之前讨论的“面”反射，头发材质关注光线和“线”之间的关系。</p><p><img src="17.png" width="40%"></p><p>我们可以看到，当光线照射到头发上时，同时产生了无色和有色的高光，为了分析原因，我们介绍Kajiya-Kay Model，这是自研究头发开始，人们就广泛使用的一种模型：</p><p><img src="18.png" width="40%"></p><p>图中的圆柱就是头发，我们认为光线照射到头发后，会在一个圆锥范围内进行散射，同时又有一部分光线朝四面八方散射（图中橘色部分），这部分类似漫反射。不过这个模型和真实的情况还是有出入的，下面是该模型的渲染效果：</p><p><img src="19.png" width="40%"></p><p>现在被广泛应用的模型是Marschner Model，如下所示：</p><p><img src="20.png" width="40%"></p><p>该模型中，光线会考虑TT和TRT两种情形，前者指的是光线进入头发，产生一次折射（T），再从头发传出，产生第二次折射（T）；后者指的是光线进入头发，产生折射（T），触碰到对侧头发壁厚，发生反射（R），最后再折射出去（T）。</p><p>下图是一个更详细的示意：</p><p><img src="21.png" width="40%"></p><p>该模型的渲染结果就非常好：</p><p><img src="22.png" width="40%"></p><h4 id="Fur-Appearance——毛发材质"><a href="#Fur-Appearance——毛发材质" class="headerlink" title="Fur Appearance——毛发材质"></a>Fur Appearance——毛发材质</h4><p>我们刚才讨论了有关头发的渲染问题，那么动物的毛发是否能用相同的方式渲染？</p><p>很可惜，答案是不可以，如下图所示，直接在动物毛发上应用Marschner Model的效果并不好：</p><p><img src="23.png" width="50%"></p><p>人的头发和动物的毛发在结构上是相似的，它们都包含有Cortex、Medulla和Cuticle三部分。</p><p><img src="24.png" width="50%"></p><p>但区别在于，头发中Medulla非常纤细，而毛发中的Medulla则要粗很多，这意味着光线在毛发中更容易发生散射。</p><p>之前的Marschner Model还没有考虑到这个问题，通过引入Medulla，毛发的渲染会更加真实：</p><p><img src="25.png" width="50%"></p><p>即使是对于头发，Medulla的引入也使得效果更加逼真：</p><p><img src="26.png" width="50%"></p><p>这种改进后的模型就是Double Cylinder Model（双重圆柱模型），如下所示：</p><p><img src="27.png" width="50%"></p><p>在该模型中，除了TT和TRT，还考虑了穿过medulla时的情况，也就是下图中的TTs和TRTs</p><p><img src="28.png" width="50%"></p><p>从而最终的结果由这五种情况叠加产生：</p><p><img src="29.png" width="50%"></p><p>（这个模型就是闫老师提出的）</p><h4 id="Granular-Material——颗粒材质"><a href="#Granular-Material——颗粒材质" class="headerlink" title="Granular Material——颗粒材质"></a>Granular Material——颗粒材质</h4><p>这里我们要研究的是由一堆颗粒堆积而成的材质，下图展示了很多颗粒材质，包括盐、米、面粉等等。</p><p><img src="30.png" width="50%"></p><p>这种材质还是非常难做的，一种思路是将模型想象为几种颗粒按一定比例的构成进行渲染：</p><p><img src="31.png" width="50%"></p><p>只是即使这样，也很难保证渲染的效率，这里也就不详细说了。</p><h3 id="表面模型"><a href="#表面模型" class="headerlink" title="表面模型"></a>表面模型</h3><h4 id="Translucent-Material——透射材质"><a href="#Translucent-Material——透射材质" class="headerlink" title="Translucent Material——透射材质"></a>Translucent Material——透射材质</h4><p>很多时候我们会混淆透射材质和半透明材质的概念，它们实际上是不同的，透射材质中光线会在物体内部产生散射，再向外出射，而半透明材质一般没有散射这一环节。</p><p>透射材质中的一个代表性材质就是玉石：</p><p><img src="32.png" width="40%"></p><p>这里牵涉到的物理模型是次表面散射模型，描述的就是刚才我们提到的过程：</p><p><img src="33.png" width="40%"></p><p>次表面散射模型使用BSSRDF（Bidirectional Subsurface Scattering Reflection Distribution Function）来进行描述，这其实是对BRDF的扩展。BRDF中，我们只考虑方向，因为我们默认入射点和出射点是一致的，而在BSSRDF中，还要考虑出射点的位置：</p><p><img src="34.png" width="70%"></p><p>所以计算光照时，不仅要对方向进行积分，还要对面积进行积分。</p><p>不过这种方法的计算量很大，我们可以用两个光源来模拟次表面散射：</p><p><img src="35.png" width="50%"></p><p>至于为什么可以这么替代，我们就不详细展开了，总之这么做的效果是非常好的：</p><p><img src="36.png" width="50%"></p><h4 id="Cloth——布料"><a href="#Cloth——布料" class="headerlink" title="Cloth——布料"></a>Cloth——布料</h4><p>接下来我们来看布料，为了知道如何渲染布料，我们得先知道布料是如何构成的，布料的构成可以分为下面两个层级：</p><p><img src="37.png" width="50%"></p><p>具体而言，就是Fiber（也就是最基础的纤维，例如羊毛）首先被缠绕成Ply（中文翻译应该是股？），然后Ply再被缠绕为Yarn，也就是一般我们所说的线。这些线经过编织，形成了我们看到的各色衣物：</p><p><img src="38.png" width="50%"></p><p>不难想象，计算这样复杂的布料肯定是很困难的。首先可以确定的是，最后的渲染结果肯定与编织的方式有关，因此可以根据编织的方式定义BRDF：</p><p><img src="39.png" width="30%"></p><p>不过这么做并不全面，因为不是所有布料的表面都是这种偏平整的表面，一些织物的表面的线会呈现出向外的特征，这时还使用BRDF就不太合适了。</p><p><img src="40.png" width="50%"></p><p>一种解决办法是把布料当做散射介质，假想对象由无数个小单元组成，每个单元用散射介质的方式来进行渲染，这种方式虽然结果准确，但计算量极大：</p><p><img src="41.png" width="50%"></p><p>另一种办法是逐Fiber进行渲染，缺点和刚才这一种是一致的，不过这么计算从理论上更加贴合实际的结果：</p><p><img src="42.png" width="50%"></p><p>布料解算到现在都还是一个很重要的课题，也一直是渲染的难点。</p><h4 id="Detailed-Appearance——细节外观"><a href="#Detailed-Appearance——细节外观" class="headerlink" title="Detailed Appearance——细节外观"></a>Detailed Appearance——细节外观</h4><p>我们已经聊了很多渲染理论和方法，但我们实际上手时，渲染出的图片却总感觉不真实：</p><p><img src="43.png" width="50%"></p><p>最大的原因其实还是渲染的结果太“真实”了，现实中根本不可能存在这么完美的赛车和鼠标，表面完全光滑，没有一丝划痕。</p><p>在实际生活中，它们大都是长这样的：</p><p><img src="44.png" width="50%"></p><p>之前我们提到过微表面模型的概念，这里重新贴一下该模型的示意图：</p><p><img src="45.png" width="40%"></p><p>为了获得表面细节，我们可以在NDF上做出修改，如下所示：</p><p><img src="46.png" width="50%"></p><p>一般我们统计获得的理想模型都是如上图左这样的，不过实际的NDF可能就更接近右边这种。</p><p>通过这种方式，我们可以为渲染对象增添不少的细节：</p><p><img src="47.png" width="35%"></p><p>上图使用了200K*200K的法线贴图进行渲染，在蜗牛壳上出现了非常好的效果。</p><p>不过还是那个老问题——太慢了，光是这张图的渲染就要耗费大概20天的时间。这里计算慢的原因主要是使用微表面模型后，表面上的镜面微元太多了，从相机引出的射线少有能反射到光源上的（反之亦然）：</p><p><img src="48.png" width="50%"></p><p>一种解决方案是不逐个计算镜面微元，而是把穿过单个像素的光线，视为照射到一个区域上，用该区域来计算反射：</p><p><img src="49.png" width="50%"></p><p>这个区域的大小会影响我们的最终结果（这句话好像是废话），具体来说，区域越小，就更加还原细节；区域越大，则效果跟接近统计结果：</p><p><img src="50.png" width="30%"></p><p>除此之外，法线贴图本身的样子也会影响P-NDF的样子：</p><p><img src="51.png" width="40%"></p><p>如果再深入的话，就会出现更麻烦的事情。一旦细节的规模小于光的波长，我们就不能用现在的光学模型来进行建模了，此时需要进入到波动光学的范畴，但波动光学的内容实在是太难了（至少对笔者这种非物理专业的人来说），GAMES101课程也就没再深入讲解了。</p><p>（说实话，感觉讲了笔者可能也理解不了）</p><h3 id="Procedural-Appearance——程序化生成表面"><a href="#Procedural-Appearance——程序化生成表面" class="headerlink" title="Procedural Appearance——程序化生成表面"></a>Procedural Appearance——程序化生成表面</h3><p>程序化生成表面的思想是这样的：当我需要渲染某一点时，我不进行真实的计算，而是采用预先定义好的某种函数（或者极其简单的计算），直接获取材质信息。</p><p><img src="52.png" width="40%"></p><p>这种函数被称之为<strong>Noise函数</strong>。注意，这种函数被定义在空间中，可以理解为是$f(x,y,z)$形式的，因此不论要渲染的对象形态是什么样的，都能通过该函数获取表面材质。</p><p>这种方式可以很方便地用于简单细节材质的创建，例如车辆表面的锈迹：</p><p><img src="53.png" width="30%"></p><p>（这种车的应用场景，大概是游戏中路边那些随处可见的车，玩家不会很认真地去纠结它的细节）</p><p>这种方式在生成山峰和木头纹理时的效果还是非常不错的，是一种很好的替代计算的方案：</p><p><img src="54.png" width="30%"></p><p>那么这篇文章的内容到此为止，我们下篇文章见！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（六）——Materials and Appearances</title>
      <link href="/2024/06/18/games101-ke-cheng-bi-ji-liu-materials-and-appearances/"/>
      <url>/2024/06/18/games101-ke-cheng-bi-ji-liu-materials-and-appearances/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（六）——Materials-and-Appearances"><a href="#GAMES101课程笔记（六）——Materials-and-Appearances" class="headerlink" title="GAMES101课程笔记（六）——Materials and Appearances"></a>GAMES101课程笔记（六）——Materials and Appearances</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>书接前文，我们结束了有关光线追踪的部分，这次文章我们来介绍相对轻松的一个部分——材质和外观（不如说光追之后的部分其实都挺轻松的）。</p><p>这个部分其实与光追中提到的BRDF息息相关，因此本篇中将会经常涉及到这一概念，对此不熟悉的读者可以参阅此前的光线追踪一文。经过本篇，相信各位读者一定会对光在散射时的细节有更深层次的了解，并在此基础上学习如何在计算机中对各种材质进行渲染，表现出不同的效果。</p><p>话不多说，我们直接进入正文。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><p><a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a></p><p><a href="/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/">GAMES101课程笔记（四）——Geometry</a></p><p><a href="">GAMES101课程笔记（五）——Ray Tracing</a></p><h2 id="Material——材质"><a href="#Material——材质" class="headerlink" title="Material——材质"></a>Material——材质</h2><p>虽然我们一直在说材质这个词语，但从来没有系统地分析过这到底是什么东西，首先来看下面这个例子：</p><p><img src="1.png" width="50%"></p><p>上图中的三杯咖啡使用的是同一个网格模型，当应用不同的材质后，便呈现出完全不同的效果，我们在光线追踪一文中涉及了很多公式，但到底是哪一部分决定了材质的样式？答案就是BRDF，应用什么样的材质，其实就是思考应用什么样的BRDF。</p><p>最简单的例子，下图表示的材质就是一个标准的漫反射材质：</p><p><img src="2.png" width="30%"></p><p>它的应用效果如下所示：</p><p><img src="3.png" width="50%"></p><p>接下来我们从BRDF的角度来理解漫反射材质，我们知道，只包含反射项的渲染方程为：</p><script type="math/tex; mode=display">L_o(\omega_o)=\int_{H^2}f_r L_i(\omega_i)\cos{\theta_i}\mathrm{d}\omega_i</script><p>漫反射模型中，$f_r$是一个常数，同时我们再假设入射光是均匀的，因此$L_i(\omega_i)$也是一个常数，如下所示：</p><p><img src="4.png" width="30%"></p><p>所以我们可以将渲染方程积分中的常数项提出并化简：</p><script type="math/tex; mode=display">\begin{align}L_o(\omega_o) &= f_r L_i\int_{H^2}\cos{\theta_i}\mathrm{d}\omega_i \\&= \pi f_r L_i\end{align}</script><p>假设能量守恒，我们就能得到$f_r=\frac{1}{\pi}$，不过考虑到颜色的问题，我们可以定义一个反射率$\rho$，从而有：</p><script type="math/tex; mode=display">f_r=\frac{\rho}{\pi}</script><p>这里的$\rho$可以是单通道的或者三通道（RGB）的，根据具体的实际问题进行选择。</p><p>下图展示了另外一种典型材质——Glossy：</p><p><img src="5.png" width="30%"></p><p>这种材质类似于金属抛光的效果，从其示意图中可以看出，它具有一定的镜面反射特点，但反射光线仍在一定的角度里扩散。</p><p>以下是该材质的效果图：</p><p><img src="6.png" width="50%"></p><p>当加入折射光后，就可以表现透明材质：</p><p><img src="7.png" width="30%"></p><p>例如水、玻璃等材质，都能用这种方式表达，如下所示：</p><p><img src="8.png" width="50%"></p><h2 id="反射与折射"><a href="#反射与折射" class="headerlink" title="反射与折射"></a>反射与折射</h2><p>反射与折射是光学中两个老生常谈的话题，图形学与它们间的关系也非常密切，这里我们重新介绍一下它们。</p><p>从之前的内容中也能看出，目前我们谈及光时，一般都只涉及几何光学，而不涉及波相关的性质，这里同样如此。</p><h3 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h3><p>反射是一种物理现象，指波阵面从一个介质进入另一个介质时，部分或全部的波在两介质界面处，传播方向发生改变且返回原介质的现象，这里只谈论光的反射。</p><p>光在反射时，一个最基本的性质就是入射角$\theta_i$等于反射角$\theta_o$，如下图所示：</p><p><img src="9.png" width="50%"></p><p>因此，我们可以简单地写出入射方向和出射方向之间的关系式：</p><script type="math/tex; mode=display">\omega_o+\omega_i=2\cos\theta \vec{n}=2(\omega_i·\vec{n})\vec{n}</script><p>（注意，这里的入射方向和出射方向起点都是反射点）</p><p>从而获得出射方向的计算式为：</p><script type="math/tex; mode=display">\omega_o=-\omega_i+2(\omega_i·\vec{n})\vec{n}</script><p>当我们俯视观看反射时，入射光和反射光的方向看上去是相反的（上图右）。</p><p>完美的反射BRDF应该会使模型表面呈现出极度光滑的镜面材质：</p><p><img src="10.png" width="40%"></p><h3 id="折射"><a href="#折射" class="headerlink" title="折射"></a>折射</h3><p>同样，该部分我们只讨论光的折射，折射是指光在穿越介质或经历介质的渐次变化时传播方向上的改变。</p><p>日常生活中常见的折射场景包括玻璃、海洋等，如下所示：</p><p><img src="11.png" width="40%"></p><p>这的一提的是，右下角这种现象有一个专门的名词——Caustics，中文译名为焦散。这种现象的出现是因为光线在晃动的水面产生折射后，刚好集中在了某些区域，形成了亮斑，这在图形学中是一个有点困难的问题，有兴趣的读者可以去深入了解下。</p><p>折射相较于反射，稍稍复杂一点，因为折射角的大小与光线穿越的介质有关，如下所示：</p><p><img src="12.png" width="40%"></p><p>假设上下两种介质的折射率分别是$\eta_i$和$\eta_t$，它们与入射角和折射角之间满足关系：</p><script type="math/tex; mode=display">\eta_i \sin{\theta_i}=\eta_t \sin{\theta_t}</script><p>（其实就是菲涅尔定律）</p><p>当我们俯视观看折射时，入射光和折射光的方向看上去同样是相反的（上图右，这里换了一种公式表达）。</p><p>我们更深入地了解一下折射，根据三角函数公式，我们有：</p><script type="math/tex; mode=display">\cos{\theta_t} = \sqrt{1-\sin^2{\theta_t}}</script><p>将刚才的折射公代入，有：</p><script type="math/tex; mode=display">\cos{\theta_t} = \sqrt{1-(\frac{\eta_i}{\eta_t})^2\sin^2{\theta_i}}</script><p>此时，如果出现：</p><script type="math/tex; mode=display">1-(\frac{\eta_i}{\eta_t})^2\sin^2{\theta_i}<0</script><p>那么上式就没意义，也就意味着不会发生折射，而我们知道$\sin^2{\theta_i}\leq 1$，因此只有当折射率满足：</p><script type="math/tex; mode=display">\frac{\eta_i}{\eta_t}>1</script><p>才有可能出现该式无意义的情况，所以我们可以得出一个结论：</p><p><strong>当光线从一种介质射向另一种介质时，若当前介质的折射率大于另一介质的折射率，则可能不出现折射现象。</strong></p><p>若不考虑光线衰减和物体吸收能量，此时介质表面只发生全反射。</p><p>现实生活中有一个例子，就是当潜水时，如果人看向水面，只能看到一个锥形部分的光线：</p><p><img src="13.png" width="50%"></p><p>在这里折射率的比值没有发生改变，由于水的折射率大于空气的折射率，水面上方180°的光线被折射为约90°的视角（图左黑色光线）。</p><p>而对于更大角度上的观察，根据刚才的公式，这部分的光线全部来自于水底的全反射（图左红色光线），多数情况下，这部分光线都衰减到十分微弱，因此看上去是暗的。</p><p>事实上，在光线和水深合适的情况下，周围其他区域也可以呈现出对应的颜色，如下图，锥形外的区域反射了水底的蓝绿色：</p><p><img src="14.png" width="40%"></p><p>这种现象称之为Snell’s Window，在很多影视作品中都有出现。</p><h3 id="BRDF、BTDF与BSDF"><a href="#BRDF、BTDF与BSDF" class="headerlink" title="BRDF、BTDF与BSDF"></a>BRDF、BTDF与BSDF</h3><p>值得一提的是，我们一直在讨论BRDF，这里的R指的其实只有反射（Reflectance），并不包含折射（其实英语原文是Transmittance，一般叫透射），所以当我们描述折射时使用的应该是BTDF，二者统称为BSDF，S指Scattered，中文为散射。</p><p>不过一般提到BRDF时，也会一并把折射考虑进来，这个就属于是称呼习惯了，具体语境中再说，这里只是做一个严谨的科普。</p><p>刚才我们介绍反射和折射时，我们都涉及了两个视角：</p><ol><li>从侧面看，此时视线垂直于入射光和出射光所在的平面。</li><li>从上方看，此时视线为竖直方向。</li></ol><p>以反射的这张图为例：</p><p><img src="9.png" width="50%"></p><p>第一种视角对应左图，这里的$\theta_i$和$\theta_o$称之为入射角和出射角；第二种对应右图，这里的$\phi_i$和$\phi_o$称之为入射天顶角和出射天顶角。</p><p>BSDF描述光在一个表面上的入射和出射方向上的情况，因此该函数是一个四维函数，如下所示：</p><script type="math/tex; mode=display">\mathrm{BSDF}(\theta_i,\theta_o,\phi_i,\phi_o)</script><h3 id="Fresnel-Reflection——菲涅尔项"><a href="#Fresnel-Reflection——菲涅尔项" class="headerlink" title="Fresnel Reflection——菲涅尔项"></a>Fresnel Reflection——菲涅尔项</h3><p>观察下图桌面：</p><p><img src="15.png" width="50%"></p><p>不难发现，当视线的入射角增大时，桌面上书本的倒影更加明显，这意味着该方向上反射的能量更多，这说明一个问题：</p><p><strong>光线的反射与入射角的角度有关。</strong></p><p>（事实上折射也相关）</p><p>菲涅尔项就用于描述这一相关关系，下图是折射率为1.5的绝缘体的菲涅尔项曲线：</p><p><img src="16.png" width="40%"></p><p>这里的蓝绿两条曲线代表光在S和P方向上的偏振光，这属于波动光学的范畴，这里不详细展开，有空的话可以开篇文章聊聊（坑*n）。</p><p>我们只关注红色曲线，它在数值上等于蓝绿两条曲线的均值，可以看出反射随着入射角的增大变得更加强烈，与之前桌面上的倒影情况一致。</p><p>注意，并不是所有介质的菲涅尔项都是这样的单调递增函数，例如对于某金属而言，其菲涅尔项如下：</p><p><img src="17.png" width="40%"></p><p>（导体的折射率为复数）</p><p>如果要计算菲涅尔项，就得先计算S偏振光和P偏振光，计算公式为：</p><script type="math/tex; mode=display">R_s=\left|\frac{n_1\cos\theta_i-n_2\cos\theta_t}{n_1\cos\theta_i+n_2\cos\theta_t}\right|^2 \\R_p=\left|\frac{n_1\cos\theta_t-n_2\cos\theta_i}{n_1\cos\theta_t+n_2\cos\theta_i}\right|^2</script><p>这里的$n_1$和$n_2$代表入射介质和透射介质的折射率，$\theta_i$和$\theta_t$代表入射角和折射角。</p><p>取均值，获得菲涅尔项：</p><script type="math/tex; mode=display">R=\frac{R_s+R_p}{2}</script><p>不过这种计算方法比较繁琐，为了计算的方便，我们假设反射在0°时有一个基准反射$R_0$，在入射角为90°时达到1，用该函数来拟合：</p><script type="math/tex; mode=display">R(\theta)=R_0+(1-R_0)(1-\cos\theta)^5 \\R_0=(\frac{n_1-n_2}{n_1+n_2})^2</script><p>这个函数就是Schlick’s approximation，在一般情况下都是一个非常良好的近似。</p><h2 id="Microfacet-Material——微表面材质"><a href="#Microfacet-Material——微表面材质" class="headerlink" title="Microfacet Material——微表面材质"></a>Microfacet Material——微表面材质</h2><p>首先来看课程中的一张图：</p><p><img src="18.png" width="40%"></p><p>可以看到图中渲染的是我们的地球，不过假如我们仔细推敲这张图的话，似乎有一点问题：地表上应该有很多地形，在图中却呈现出类似镜面反射的效果。</p><p>但其实是因为我们的观测距离足够远，远到我们可以忽略掉这些“粗糙表面”，微表面材质正是基于这一思想，即：</p><p><strong>当观测距离足够远，我们就无法看到表面上的微小细节，只能看到整个表面对光的总体效应。</strong></p><p>微表面模型的示意图如下：</p><p><img src="19.png" width="50%"></p><p>它的特点如下：</p><ul><li>在Macroscale下（从远处看），表面是一个粗糙的平面</li><li>在Microscale下（从近处看），表面包含凹凸不平的微元，每个微元视为一个微小镜面</li></ul><p>（其实漫反射也是这样一个模型，每个微元反射光线，从宏观上看就是向所有方向反射）</p><p>其中这个微元称之为Microfacet，我们现在可以从Microfacet的角度，重新去理解光滑表面和漫反射表面。</p><p>假如我们的Microfacet法线基本朝向一个方向，那么表面看上去就是光滑的，如下所示：</p><p><img src="20.png" width="50%"></p><p>反之，如果各个Microfacet的法线散布非常混乱，朝向各个方向，那么整个表面看上去就是漫反射的：</p><p><img src="21.png" width="50%"></p><p>也就是说，通过微表面模型，我们可以用表面Microfacet的法线分布来表达材质。</p><p>下图展示的就是这一方法的具体过程：</p><p><img src="22.png" width="50%"></p><p>$f(i,o)$代表BRDF，它的计算式中，$F(i,h)$是表面的菲涅尔项，前文已经介绍过。</p><p>我们先重点来看$D(h)$这一项，$D(h)$代表表面的Microfacet中，法线朝向为$h$的分布，$h$是$w_i$和$w_o$的半程向量。这并不难理解，因为只有朝向为$h$的Microfacet，才能将光线从$w_i$反射到$w_o$。</p><p>然后是项$G(i,o,h)$，这是阴影遮挡项，由于表面存在凹凸不平的Microfacet，某些方向的光会因为其他Microfacet的遮挡，无法照射到特定Microfacet上，尤其是在光线与平面几乎平行时，这种情况更容易发生，这一项的引入正是为了处理这一问题。</p><p>这种与平面几乎平行的角度称之为Grazing angle，它经常会出现在一些物体的边缘上，例如渲染一个球时，对于其边缘的表面，我们的观察角度其实就是一个Grazing angle，此时$G(i,o,h)$就会起作用，以正确渲染边缘。</p><p>以下是使用微表面模型的渲染结果：</p><p><img src="23.png" width="50%"></p><p>可以看出，微表面模型非常强大不论金属、皮革还是木材，都有非常不错的渲染效果。</p><h2 id="Isotropic-Anisotropic-Materials——各向同性-各向异性材质"><a href="#Isotropic-Anisotropic-Materials——各向同性-各向异性材质" class="headerlink" title="Isotropic/Anisotropic Materials——各向同性/各向异性材质"></a>Isotropic/Anisotropic Materials——各向同性/各向异性材质</h2><p>在坐电梯时，我们时常会看到如下的情况：</p><p><img src="24.png" width="50%"></p><p>按照我们的渲染知识，光在照射到电梯内壁时形成的高光，理应是椭圆形的，但在现实中却呈现出图中的条状，这是因为该材质并非简单的镜面反射，而是一种各向异性材质。</p><p>在Shading一节中，我们曾介绍过各向异性过滤，两个各向异性的含义是相同的，都是指在不同方向上有所不同。</p><p>对于各向异性材质，指的就是该材质对于不同方向上的光照，呈现出不同的效果。</p><p>此前我们都假设，材质是没有方向性的，即各向同性，如下所示：</p><p><img src="25.png" width="50%"></p><p>这就是刚才我们所假想的，椭圆形高光的由来，各向同性材质上的Microfacet法线分布非常不规则，因而在宏观上呈现为镜面。</p><p>而各向异性材质表面的Microfacet法线分布，会因为其排列方式，让光在不同方向上的反射不同，如下图中的例子：</p><p><img src="26.png" width="50%"></p><p>该材质中，法线的分布集中于左右，几乎没有上下的法线，因此同样被光照射后，左右的反射更强，故而出现横条状的结果。</p><p>如果从BRDF的角度来定义各向同性/各向异性材质，就需要看在把表面转过任意角度$\phi$后（从俯视角看），BRDF是否改变，即判断：</p><script type="math/tex; mode=display">\mathrm{BRDF}(\theta_i,\theta_o,\phi_i,\phi_o)=\mathrm{BRDF}(\theta_i,\theta_o,\phi_i-\phi,\phi_o-\phi)</script><p>该等式是否恒成立，若是，则该材质为各向同性材质；反之，则为各向异性材质。</p><p>这里还有一个各向异性材质的实例，就是我们日常使用的厨具：</p><p><img src="27.png" width="50%"></p><p>从视觉效果上，我们其实也能或多或少推断出其表面的法线分布。</p><h2 id="BRDF性质"><a href="#BRDF性质" class="headerlink" title="BRDF性质"></a>BRDF性质</h2><p>接触了这么多BRDF相关的知识后，我们就可以来总结一下BRDF的性质了。</p><h3 id="非负性"><a href="#非负性" class="headerlink" title="非负性"></a>非负性</h3><script type="math/tex; mode=display">f_r(\omega_i \rightarrow \omega_r) \geq 0</script><p>这个很好理解，因为反射出去的能量肯定是非负的，不可能出现负能量的情况。</p><h3 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h3><script type="math/tex; mode=display">L_r(\mathbf{p}, \omega_r) = \int_{H^2} f_r(\mathbf{p}, \omega_i \rightarrow \omega_r) L_i(\mathbf{p}, \omega_i) \cos \theta_i \, \mathrm{d}\omega_i</script><p>我们之前介绍Blinn-phong模型时就使用过这一性质，当时我们分别计算了漫反射、高光和环境光，最后再相加起来。</p><p>其实这一方法可以推广到各种BRDF上，如下图：</p><p><img src="28.png" width="50%"></p><p>我们可以分别计算一部分BRDF的结果，最后再相加起来，其效果等同于计算总BRDF的结果。</p><h3 id="可逆性"><a href="#可逆性" class="headerlink" title="可逆性"></a>可逆性</h3><script type="math/tex; mode=display">f_r(\omega_r \rightarrow \omega_i) = f_r(\omega_i \rightarrow \omega_r)</script><p>由于光路可逆，BRDF自然也具有可逆性，交换入射方向和出射方向，BRDF值不变。</p><p><img src="29.png" width="50%"></p><h3 id="能量守恒"><a href="#能量守恒" class="headerlink" title="能量守恒"></a>能量守恒</h3><script type="math/tex; mode=display">\forall \omega_r \int_{H^2} f_r(\omega_i \rightarrow \omega_r) \cos \theta_i \, \mathrm{d}\omega_i \leq 1</script><p>上式假设入射的所有能量为1，无论如何反射，反射出的能量绝对不可能超过入射能量。</p><h3 id="各向同性材质"><a href="#各向同性材质" class="headerlink" title="各向同性材质"></a>各向同性材质</h3><p>前文提到过，如果把表面转过任意角度$\phi$后（从俯视角看），BRDF没发生改变，那么该表面材质就是各向同性的。</p><p>原来的BRDF需要四个参数：$\theta_i$、$\theta_o$、$\phi_i$和$\phi_o$，对于各向同性材质来说，就不需要特别指明$\phi_i$和$\phi_o$，只需要知道天顶角的夹角即可，即：</p><script type="math/tex; mode=display">f_r(\theta_i, \phi_i; \theta_r, \phi_r) = f_r(\theta_i, \theta_r, \phi_r - \phi_i)</script><p>从而使得BRDF降维到了三维，依据可逆性，等式右边可以推广为：</p><script type="math/tex; mode=display">f_r(\theta_i, \theta_r, \phi_r - \phi_i) = f_r(\theta_r, \theta_i, \phi_i - \phi_r) = f_r(\theta_i, \theta_r, |\phi_r - \phi_i|)</script><p><img src="30.png" width="50%"></p><h2 id="BRDF测量"><a href="#BRDF测量" class="headerlink" title="BRDF测量"></a>BRDF测量</h2><p>说了这么多，我们的BRDF仍然都只是在理论层面上，而理论模型与实际之间是可能存在很大差异的，例如下图：</p><p><img src="31.png" width="30%"></p><p>这是一个菲涅尔项的曲线，其中蓝色的是前文我们提到的近似模型，而绿线红线是两次测量值，可以看见存在非常大的差异。</p><p>因此，面对理论模型难以解决的情况，我们可以直接测量现实材质的BRDF，并直接利用测量数据，从而达到真实的渲染效果。</p><p>一种最简单的办法就是遍历所有的入射出射方向对，逐个进行测量，如下所示：</p><p><img src="32.png" width="40%"></p><p>现实中就有这种测量工具的实例，如图：</p><p><img src="33.png" width="40%"></p><p>该机器利用两个机械臂，尽可能地测量所有入射出射方向对上的反射情况，获得BRDF。</p><p>可以使用一点技巧来提升BRDF测量的效率，例如：</p><ul><li>假定材质是各向同性的，减少BRDF维度</li><li>利用可逆性，减少一半的测量量</li><li>使用预测技术，只测量部分BRDF，其余部分使用预测值</li></ul><p>那么有关材质和外观的内容就到此为止了，我们下一篇文章见！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Diffusion Model入门</title>
      <link href="/2024/04/21/diffusion-model-ru-men/"/>
      <url>/2024/04/21/diffusion-model-ru-men/</url>
      
        <content type="html"><![CDATA[<h1 id="Diffusion-Model——扩散模型"><a href="#Diffusion-Model——扩散模型" class="headerlink" title="Diffusion Model——扩散模型"></a>Diffusion Model——扩散模型</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文主要依据引文[1]撰写，文中提到“论文”等名词时，若无特殊指明，均默认代指引文[1]。</p><p>文中的图片来自于互联网和论文，来源列举于参考资料中。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>扩散模型用以进行图像生成，它的过程主要分为两步：前向过程和反向过程。</p><p>前向过程是先经过一系列的步骤，为输入图像添加噪声。</p><p>反向过程则是通过训练神经网络，将含噪声图片还原回原始数据，从而我们可以利用它来生成新的图片。</p><h2 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h2><p>扩散模型中，前向过程的噪声添加建模为一个马尔科夫链：</p><p><img src="1.png" width="50%"></p><p>初始状态$x<em>0$代表原始图片，在马尔科夫链的状态$x</em>{t-1}$处，我们添加一个高斯噪声，从而使其转变为状态$x_t$。</p><p>假设添加的高斯函数方差为$\beta<em>t$，条件概率$q(x_t|x</em>{t-1})$应是一个高斯分布概率密度函数：</p><script type="math/tex; mode=display">q(x_t|x_{t-1}) = N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)</script><p>该分布均值为$\sqrt{1-\beta<em>t}x</em>{t-1}$，由于$\sqrt{1-\beta_t}&lt;1$，因此每一步都会渐弱上一步中图片的信息，让原始图片光滑地过渡到噪声；其方差为$\beta_tI$，意味着添加噪声的方差在各个通道上是相互独立的。</p><p>而在整个时间步上的后验概率为：</p><script type="math/tex; mode=display">q(x_{1:T}|x_0)= \prod_{t=1}^{T}q(x_t|x_{t-1})</script><p>由于$q(x<em>t|x</em>{t-1})$的采样涉及上一个状态，因此计算该后验概率时需要采样$T$次，为了方便采样，可以进行重参数化。</p><p>通过引入随机性节点序列$\epsilon<em>{0},…,\epsilon</em>{t-2},\epsilon_{t-1} \sim N(0,I)$，加上定义：</p><script type="math/tex; mode=display">\alpha_t = 1-\beta_t \\\overline{\alpha_t} = \prod_{s=0}^{t}\epsilon_{s}</script><p>利用高斯分布的性质，得到：</p><script type="math/tex; mode=display">\begin{align*}x_t &= \sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}\epsilon_{t-1} \\&= \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_{t-1} \\\end{align*}</script><p>逐步递推，最终获得：</p><script type="math/tex; mode=display">x_t = \sqrt{\overline{\alpha}_t}x_{0}+\sqrt{1-\overline{\alpha}_t}\epsilon_{0}</script><p>也就是说$x_t$满足这样一个高斯分布：</p><script type="math/tex; mode=display">x_t \sim N(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)</script><p>在这个分布中，所有的参数都可以预先计算，从而只需一次采样就可以得到任何一个时间步上的$x_t$。</p><h2 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h2><p><img src="2.png" width="50%"></p><p>反向过程中，由于我们的目的是还原图片，因此需要得知反向的分布$p<em>{\theta}(x</em>{t-1}|x_t)$，直接计算难以解决，不过可以使用神经网络来学习（近似）该分布。</p><p>对于从$x<em>t$还原到$x</em>{t-1}$的过程，它仍然是一个高斯分布，因此只需参数化该分布的均值和方差：</p><script type="math/tex; mode=display">p_{\theta}(x_{t-1}|x_t)=N(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))</script><p>从而可以得到整个序列的分布：</p><script type="math/tex; mode=display">p_{\theta}(x_{0:T})=p_{\theta}(x_T)\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_t)</script><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>扩散模型的训练目标是最大化似然对数，即$L’=E<em>{q(x_0)}(\log[p</em>{\theta}(x_0)])$，类似于交叉熵，论文中使用了变分下限来进行优化。</p><p>模型的$x_0$概率分布应是：</p><script type="math/tex; mode=display">\begin{align*}p_{\theta}(x_0) &= \int p_{\theta}(x_{0:T})dx_{1:T}\end{align*}</script><p>由于它并不好计算，因此在这个等式右边乘以一个值为1的项，并利用前向过程和反向过程中得到的等式，可以将其变形为：</p><script type="math/tex; mode=display">\begin{align*}p_{\theta}(x_0) &= \int p_{\theta}(x_{0:T}) \frac{q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)}dx_{1:T} \\&= \int q(x_{1:T}|x_0) \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}dx_{1:T} \\&= \int q(x_{1:T}|x_0) \frac{p_{\theta}(x_T)\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_t)}{\prod_{t=1}^{T}q(x_t|x_{t-1})}dx_{1:T} \\&= \int q(x_{1:T}|x_0)p_{\theta}(x_T)\prod_{t=1}^{T} \frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}dx_{1:T}\end{align*}</script><p>从而：</p><script type="math/tex; mode=display">\begin{align*}L' &= \int q(x_0)\log{[p_{\theta}(x_0)]}dx_0 \\&= \int q(x_0)\log{[\int q(x_{1:T}|x_0)p_{\theta}(x_T)\prod_{t=1}^{T} \frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}dx_{1:T}]}dx_0\end{align*}</script><p>由Jensen不等式，又有：</p><script type="math/tex; mode=display">\begin{align*}L' &\geq \int q(x_{0:T})\log{[p_{\theta}(x_T)\prod_{t=1}^{T} \frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}dx_{1:T}]}dx_{0:T} \\&= E_{q(x_{0:T})}\{\log [p_{\theta}(x_T)\prod_{t=1}^{T} \frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}]\} \\&= E_{q(x_{0:T})}[\log p_{\theta}(x_T)+\sum_{t=1}^{T}\log{\frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}} \\&= E_{q(x_{0:T})}[\log p_{\theta}(x_T)+\sum_{t=2}^{T}\log{\frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}} + \log {\frac{p_{\theta}(x_{0}|x_1)}{q(x_1|x_{0})}} \\&= E_{q(x_{0:T})}[\log p_{\theta}(x_T)+\sum_{t=2}^{T}\log{\frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1}, x_0)}}·\frac{q(x_{t-1}|x_0)}{q(x_{t}|x_0)} + \log {\frac{p_{\theta}(x_{0}|x_1)}{q(x_1|x_{0})}} \\&= E_{q(x_{0:T})}[\log \frac{p_{\theta}(x_T)}{q(x_T|x_0)}+\sum_{t=2}^{T}\log{\frac{p_{\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1}, x_0)}} + \log {p_{\theta}(x_{0}|x_1)} \\&= -E_{q(x_{0:T})}[D_{KL}(q(x_T|x_0)||p(x_T))+\sum_{t=2}^{T}D_{KL}(q(x_{t-1}|x_t,x_0)||p(x_{t-1}|x_t))-\log{p_{\theta}(x_0|x_1)}]\end{align*}</script><p>为了和损失函数的形式保持一致，使用负似然对数，令：</p><script type="math/tex; mode=display">L = E_{q(x_{0:T})}[D_{KL}(q(x_T|x_0)||p(x_T))+\sum_{t=2}^{T}D_{KL}(q(x_{t-1}|x_t,x_0)||p(x_{t-1}|x_t))-\log{p_{\theta}(x_0|x_1)}]</script><p>从而我们的目标转变为最小化$L$，论文规定：</p><script type="math/tex; mode=display">L_T = D_{KL}(q(x_T|x_0)||p(x_T)) \\L_{t-1} = D_{KL}(q(x_{t-1}|x_t,x_0)||p(x_{t-1}|x_t)) \\L_0 = -\log{p_{\theta}(x_0|x_1)}</script><h3 id="L-T"><a href="#L-T" class="headerlink" title="$L_T$"></a>$L_T$</h3><p>由于论文中$\beta _t$固定为常数，因此$L_T$中并没有需要学习的参数，可以忽略。</p><h3 id="L-t"><a href="#L-t" class="headerlink" title="$L_{t}$"></a>$L_{t}$</h3><p>可以证明：</p><script type="math/tex; mode=display">q(x_{t-1}|x_t,x_0) = N(x_{t-1};\tilde{\mu}(x_t,x_0),\tilde{\beta_t}I) \\\tilde{\beta_t} = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_{t}}·\beta_t \\\tilde{\mu}(x_t,x_0) = \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_{t}}x_0+\frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t})}{1-\overline{\alpha}_{t}} x_t</script><p>由之前的重参数化技巧：</p><script type="math/tex; mode=display">x_0 = \frac{1}{\sqrt{\alpha_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\epsilon)</script><p>代入$\tilde{\mu}(x_t,x_0)$的表达式，整理可得：</p><script type="math/tex; mode=display">\tilde{\mu}(x_t,x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon) = \tilde{\mu}(x_t)</script><p>这么做能够将参数$x<em>0$消除，使得均值只与$x_t$相关，现在只需要用一个神经网络$\epsilon</em>{\theta}(x_t,t)$来近似$\epsilon$即可，即：</p><script type="math/tex; mode=display">\tilde{\mu}(x_t) = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_{\theta}(x_t,t))</script><p>因此$L_T$可以表达为：</p><script type="math/tex; mode=display">\begin{align*}L_t &= E_{x_0,t,\epsilon}[\frac{1}{2\sigma_t^2}||\tilde{\mu}(x_t)-\mu_{\theta}(x_t,t)||^2] \\&= E_{x_0,t,\epsilon}[\frac{\beta_t^2}{2\alpha_{t}(1-\overline{\alpha}_t)\sigma_{t}^2}||\epsilon-\epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_{0}+\sqrt{1-\overline{\alpha}_t}\epsilon,t)||^2]\end{align*}</script><p>论文中忽略了加权项，并说明这么做会优于目前的公式，即：</p><script type="math/tex; mode=display">L_t^{simple} = E_{x_0,t,\epsilon}[||\epsilon-\epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_{0}+\sqrt{1-\overline{\alpha}_t}\epsilon,t)||^2]</script><p>其实到这里，损失函数的目标已经变成了预测噪声。</p><h3 id="L-0"><a href="#L-0" class="headerlink" title="$L_0$"></a>$L_0$</h3><p>$L_0$其实就是$x_1$对$x_0$的极大似然估计，论文中对每个像素都运用极大似然估计，即：</p><script type="math/tex; mode=display">p_{\theta}(x_0|x_1)=\prod_{i=1}^{D}p_{\theta}(x_0^i,x_1^i)</script><p>$i$代表图像中的某个像素位置，$D$代表所有维度。</p><p>对于某个像素$i$，它的分布应为：</p><script type="math/tex; mode=display">N(x;\mu_{\theta}^i(x_1,1),\sigma_1^2)</script><p>由于$x_1$的高斯分布方差为对角阵，因此将其分解：</p><script type="math/tex; mode=display">N(x;\mu_{\theta}(x_1,1),\sigma_1^2I) = \prod_{i=1}^{D}N(x;\mu_{\theta}^i(x_1,1),\sigma_1^2)</script><p>假设图像的通道值范围为$[0,255]$，经过归一化后到$[-1,1]$，那么有：</p><script type="math/tex; mode=display">p_{\theta}(x_0|x_1) = \prod_{i=1}^{D}\int_{\delta_-(x_0^i)}^{\delta_+(x_0^i)}N(x;\mu_{\theta}^i(x_1,1),\sigma_1^2)dx \\\delta_+(x_0^i) = \begin{cases} \infty & \text{if } x = 1 \\x+\frac{1}{255} & \text{if } x < 1\end{cases} \\\delta_-(x_0^i) = \begin{cases} -\infty & \text{if } x = -1 \\x-\frac{1}{255} & \text{if } x > -1\end{cases}</script><p>真实像素值是离散的，把离散值转换为连续值时，需要把每个离散值映射到一个区间，$\delta<em>+(x_0^i)$和$\delta</em>-(x_0^i)$对应的就是这一步。</p><p>在论文中，$L_0$使用一个单独的解码器进行学习。</p><h2 id="训练与采样"><a href="#训练与采样" class="headerlink" title="训练与采样"></a>训练与采样</h2><p>论文中使用了一个基于Wide ResNet的U-Net来训练$L_t$，包含组归一化、自注意力模块。</p><p>其具体的训练和采样过程如下所示：</p><p><img src="3.png" width="50%"></p><p>训练过程的步骤为：</p><ul><li>从数据中随机抽取一个原始图片$x_0$</li><li>从时间步中随机抽取一个时间$t$</li><li>采样一个随机噪声$\epsilon$叠加到$x_0$，生成$x_t$，将$x_t$和$t$输入U-Net预测该噪声</li><li>利用梯度下降法更新权重</li><li>重复上述步骤直至收敛</li></ul><p>采样过程的步骤为：</p><ul><li>从标准正态分布采样$x_T$</li><li>从$t=T$到$t=1$，进行以下步骤：<ul><li>从正态分布采样$z$（重参数化）</li><li>使用模型计算$x_{t-1}$</li></ul></li><li>得到$x_0$</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models. Advances in neural information processing systems, 33, 6840-6851.</p><p>[2] Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., &amp; Ganguli, S. (2015, June). Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning (pp. 2256-2265). PMLR.</p><p>[3] 扩散模型是如何工作的：从零开始的数学原理. HK-SHAO. <a href="https://shao.fun/blog/w/how-diffusion-models-work.html">https://shao.fun/blog/w/how-diffusion-models-work.html</a>.</p><p>[4] Diffusion model(二): 训练推导详解. CSDN. <a href="https://blog.csdn.net/weixin_41978699/article/details/128604001">https://blog.csdn.net/weixin_41978699/article/details/128604001</a></p><p>[5] DDPM扩散模型公式推理——损失函数. CSDN. <a href="https://blog.csdn.net/weixin_45453121/article/details/131223653">https://blog.csdn.net/weixin_45453121/article/details/131223653</a>.</p>]]></content>
      
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（五）——Ray Tracing</title>
      <link href="/2024/03/12/games101-ke-cheng-bi-ji-wu-ray-tracing/"/>
      <url>/2024/03/12/games101-ke-cheng-bi-ji-wu-ray-tracing/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（五）——Ray-Tracing"><a href="#GAMES101课程笔记（五）——Ray-Tracing" class="headerlink" title="GAMES101课程笔记（五）——Ray Tracing"></a>GAMES101课程笔记（五）——Ray Tracing</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>上篇笔记的发布已经是年前的事了，寒假忙着做自己的项目demo，疏于博客的撰写，拖得确实有点太长了，毕竟撰写一篇文章和单纯记笔记的区别还是挺大的，需要投入很大的精力。</p><p>（其实是笔者沉迷于游戏的世界一去不返）</p><p>本文将进入光线追踪的部分，这是笔者本科阶段非常感兴趣的一部分内容。现实世界的光照系统极其复杂，如何在虚拟世界中呈现出真实的光照效果是图形学中的一个重大问题，本篇文章篇幅较长，并且涉及较多的物理知识，希望读者耐心观看。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><p><a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a></p><p><a href="/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/">GAMES101课程笔记（四）——Geometry</a></p><h2 id="Shadow-Mapping——阴影映射"><a href="#Shadow-Mapping——阴影映射" class="headerlink" title="Shadow Mapping——阴影映射"></a>Shadow Mapping——阴影映射</h2><p>在Shading一节中，我们介绍过为物体着色的过程，但我们考虑的是一个非常理想化的场景，即场景中仅有光源和该物体本身。</p><p>当我们引入一个比较复杂的场景后，之前的着色过程就不够用。当物体和光源间存在遮挡物后，物体上势必会留下阴影，但该着色过程无法计算阴影。</p><p><img src="1.png" width="40%"></p><p>阴影对真实感的影响非常强烈，很多时候它能影响人对对象位置的判断。例如上图中，人物脚底的影子让我们觉得人物是真的“站”在地面上的。</p><p>阴影映射是一种在图像空间中的阴影计算方法，即该方法不需要获取场景中的几何信息。</p><p>阴影映射的核心思想是：若一个点不在阴影中，那它一定同时被<strong>光源</strong>和<strong>相机</strong>观测到。</p><h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h3><p>因此阴影映射的步骤就分为两步，先从光源进行观测，再从相机进行观测。</p><p>第一步的示意图如下：</p><p><img src="2.png" width="20%"></p><p>我们从光源出发，找到所有能看到的点，但不先着色，而是记录下它们的深度，这里会用到我们之前提过的Z-Buffer。</p><p>第二步中，我们从眼睛出发，如下所示：</p><p><img src="3.png" width="20%"></p><p>此时，我们将看到的点投影回光源的视角，并比较这些点的深度是否与之前记录的深度一致，如果一致，则表明该点不在阴影中（如图中橙色线标注的点），反之则在阴影中（如图中眼睛看到的另一点）。</p><p>课件中提供了一个具体的例子，考虑下面这个场景：</p><p><img src="4.png" width="40%"></p><p>我们先从光源位置看向物体，得到深度图：</p><p><img src="5.png" width="40%"></p><p>将其与相机视角的结果进行比较，就能获得阴影的位置：</p><p><img src="6.png" width="30%"></p><p>上图中的非绿色部分就是阴影，我们进行对应的渲染，就可以获得最开始的那张图片。</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>阴影映射广泛应用于现在的游戏和早期的动画中，但它存有一定的缺点。</p><p>首先是该方法基于点光源，获得的阴影是硬阴影，即每个点要么在阴影中，要么不在，因此阴影的边缘会非常清晰。</p><p>这里我们插入介绍一下软硬阴影的概念，我们以太阳、月亮和地球构成的系统为例进行说明。</p><p><img src="7.png" width="30%"></p><p>我们知道月亮会遮挡住部分太阳光，但其实遮挡存在两种情形。</p><p>一种是图中深色的锥形部分，这部分里太阳光被月亮完全遮蔽，我们称之为本影（Umbra）。</p><p>另一种是其余的部分，由于太阳并非是一个点光源，因此会有些区域只接收到一部分阳光，我们称之为半影（Penumbra）。</p><p>硬阴影其实就是只渲染本影的情况，而软阴影附加上了半影，由于现实中的多数光源都非点光源，所以一般都会存在半影。</p><p>其次其渲染质量依赖于阴影图的分辨率，分辨率过低就会出现明显的锯齿现象。</p><h2 id="光线追踪简介"><a href="#光线追踪简介" class="headerlink" title="光线追踪简介"></a>光线追踪简介</h2><p>现在我们正式进入光线追踪部分，我们使用光线追踪，主要是为了解决光栅化下一些无法处理的全局效果。</p><p><img src="8.png" width="50%"></p><p>上图中展示了几个典型的光栅化难以处理的效果，其中就包括了我们前文中提到的软阴影。</p><p>光栅化还有一个特点是速度快但效果相对较差，例如PUBG里的场景，仔细看可以发现还是非常粗糙的。</p><p><img src="9.png" width="40%"></p><p>光线追踪的特点恰好与之相反，它拥有极度准确的效果，但需要较多的时间来渲染，因此我们在实时场景下会更多选用光栅化，而在离线场景下使用光线追踪。</p><h2 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h2><p>介绍光线追踪算法前，我们先明确一下“光线”这个概念。</p><p>主要是以下这三点：</p><ul><li>光沿直线传播</li><li>光线之间不会发生碰撞现象，它们只会穿过然后沿原来的方向前进</li><li>光线从光源传播到我们眼中，该光路是可逆的，即如果我从眼睛位置放射光线，也能传播到光源</li></ul><h3 id="Ray-Casting——光线投射"><a href="#Ray-Casting——光线投射" class="headerlink" title="Ray Casting——光线投射"></a>Ray Casting——光线投射</h3><p><img src="10.png" width="40%"></p><p>光线投射的基本思路是从眼睛放出射线，穿过屏幕上的每一个像素，然后在触碰点上向光源放出射线，从而判断该点是否在阴影中。</p><p>接下来我们对该算法进行具体的阐释，下图是一个典型的小孔相机模型（将相机/眼睛视为一个点）。</p><p><img src="11.png" width="50%"></p><p>我们从相机出发，向成像平面上的像素点放出射线，并找到最近的触碰点，图中该射线穿过了三个碰撞点，我们选取最近的那个，这对应光栅化中的深度测试。</p><p><img src="12.png" width="40%"></p><p>然后我们从该点向光源引一条射线，获知了光源和法线信息后，就可以用之前提到过的各种方法（如Bling-Pong模型）来进行渲染。</p><p>不过光线投射算法只考虑到了单次反射的光线，现实中光线可以反射无数次，因此该方法的效果并不出众。</p><h3 id="Recursive-Ray-Tracing——递归光追"><a href="#Recursive-Ray-Tracing——递归光追" class="headerlink" title="Recursive Ray Tracing——递归光追"></a>Recursive Ray Tracing——递归光追</h3><p>递归光追算法（也是Whitted-Style光追）在光线投射的基础上，允许光线进行多次反射和折射，同样以上述场景为例，在找到第一个触碰点之后，我们让射线按真实的物理法则进行反射和折射。</p><p><img src="13.png" width="40%"></p><p>从相机出发的这条射线我们称之为primary ray，经过折射和反射形成的新射线则是secondary ray，secondary ray也会找到自己的触碰点，最后我们从所有的触碰点向光源引一条射线（shadow ray），计算出所有触碰点的颜色后，叠加到原像素上，就获得了最终的渲染结果。</p><p><img src="14.png" width="40%"></p><p>值得一提的是，为了防止触碰点太多出现类似过曝光的效果，通常会限制光线的反射/折射次数，或者为光线附加一个能量，在每次反射/折射时能量就会衰减。</p><p><img src="15.png" width="30%"></p><h3 id="碰撞点"><a href="#碰撞点" class="headerlink" title="碰撞点"></a>碰撞点</h3><p>了解了光追算法的大致流程后，我们就可以探讨一些更细节的东西，例如碰撞点该如何计算。</p><h4 id="基本计算"><a href="#基本计算" class="headerlink" title="基本计算"></a>基本计算</h4><p>接下来就要涉及很多数学公式了，在此之前，我们先对光线做一个数学定义。</p><p>光线由其起点$o$和方向$d$定义，如下图所示：</p><p><img src="16.png" width="30%"></p><p>从而，我们得到光线的表达式为：</p><script type="math/tex; mode=display">r(t)=o+td \\0\leq t<\infin</script><p>好的，那假设我们现在有一条光线和一个球体，我们该如何计算触碰点呢？</p><p><img src="17.png" width="40%"></p><p>其实很简单，用高中数学知识就知道，联立方程求解就行了，也就是解下述方程：</p><script type="math/tex; mode=display">(o+td-c)^2-R^2=0</script><p>这是一个一元二次方程，在满足物理意义的前提下，其解个数反映了光线与球体的相交情况。</p><p>（其实就是满足$0\leq t&lt;\infin$，下文中就不再特地注明这一点了）</p><p><img src="18.png" width="25%"></p><p>从这个特殊例子出发，我们可以得到一个更普遍的过程：</p><ul><li><p>已知光线方程：$r(t)=o+td$</p></li><li><p>已知几何体表面方程：$f(p)=0$</p></li></ul><p>我们可以通过求解方程$f(o+td)=0$的形式来求得碰撞点。</p><h4 id="三角面模型的碰撞点"><a href="#三角面模型的碰撞点" class="headerlink" title="三角面模型的碰撞点"></a>三角面模型的碰撞点</h4><p>现在我们考虑如何计算光线与一个三角面模型的碰撞点，因为这类模型通常只给出每个三角面的信息，所以我们没法用一个统一的方程来表示其表面，故而我们需要想一些其它方法。</p><p><img src="19.png" width="25%"></p><p>最简单的方法就是把所有三角面都算一遍，看是否与光线相交。</p><p>至于如何计算光线和单个三角面的交点，我们会将这个问题拆为两个步骤解决：</p><ol><li>计算光线与三角面所在平面的交点</li><li>判断交点是否在三角面内</li></ol><p><img src="20.png" width="25%"></p><p>平面可以由其上一点$p’$加上其法向量$N$来定义，其数学表达式为：</p><script type="math/tex; mode=display">(p-p')·N=0</script><p><img src="21.png" width="25%"></p><p>这与高数中我们初次接触到的平面方程$ax+by+c+d=0$其实是一致的。</p><p>知道了表达式，我们就可以用之前的步骤代入求解，我们的解为：</p><script type="math/tex; mode=display">t=\frac{(p'-o)·N}{d·N}</script><p>（其实这里有可能出现光线与平面平行的情况，即$d·N=0$，但我们这里不列入讨论）</p><h4 id="Moller–Trumbore算法"><a href="#Moller–Trumbore算法" class="headerlink" title="Möller–Trumbore算法"></a>Möller–Trumbore算法</h4><p>上面提到的方法还是比较麻烦的，Möller–Trumbore算法可以直接通过三角面的顶点坐标来计算交点坐标，该算法认为交点应满足方程：</p><script type="math/tex; mode=display">o+td=(1-b_1-b_2)P_0+b_1P_1+b_2P_2</script><p>这里的$P_i$是三角面的顶点，等式右边用到了我们之前提到过的重心坐标，只要解出来系数满足重心坐标要求，就认为有交点，其解为：</p><script type="math/tex; mode=display">\begin{bmatrix}t \\b_1 \\b_2 \\\end{bmatrix} =\frac{1}{S_1·E_1} \begin{bmatrix}S_2·E_3 \\S_1·S \\S_2·D \\\end{bmatrix}</script><p>其中：</p><script type="math/tex; mode=display">E_1 = P_1-P_0 \\E_2 = P_2-P_0 \\S = o-P_0 \\S_1 = d×E_2 \\S_2 = S×E_1</script><p>该算法就可以快速计算光线与三角面的交点。</p><h3 id="包围盒"><a href="#包围盒" class="headerlink" title="包围盒"></a>包围盒</h3><p>为了加速对碰撞点的判断，我们可以引入包围盒。</p><p><img src="22.png" width="40%"></p><p>如上所示，包围盒是将物体完全包围在内的一种几何体，虽然其名为“盒”，但可以依据实际情况来选取不同形状的包围盒。</p><p>包围盒的加速逻辑很简单：如果光线与包围盒都没有碰撞点，那它和物体也一定没有碰撞点。</p><p>我们这里就讲长方体形的包围盒是如何起作用的。</p><p>这里我们将长方体进行全新的理解，认为长方体是三组对面的交集。</p><p><img src="23.png" width="20%"></p><p>上图就是长方体的一组对面，三组对面刚好对应长方体的六个面。</p><p>这么理解是因为我们常常会使用一种叫轴对齐包围盒（Axis-Aligned Bounding Box）的包围盒，简称AABB包围盒，它的对面全部与坐标轴平行或垂直。也就是说，AABB包围盒可以用三个轴上的三个区间来表达。</p><p>我们以二维情况为例来解释AABB包围盒是如何计算碰撞点的。</p><p><img src="24.png" width="50%"></p><p>二维情况下，长方形包围盒由两个对面（其实应该叫对线）的交集构成，分别对应$x$方向与$y$方向。</p><p>我们先求$x$方向上的对面与光线的交点，可以获得光线在这两个对面间的为$[t<em>{ {x}</em>{min} },t<em>{ {x}</em>{max} }]$对应的部分。</p><p>而$y$方向上，我们虽然求得结果是$[t<em>{ {y}</em>{min} },t<em>{ {y}</em>{max} }]$，但为了保证$t\ge 0$，因此其区间为$[0,t<em>{ {y}</em>{max} }]$。</p><p>最后，我们对这两个区间求交集，就获得了最终的区间为$[t<em>{ {x}</em>{min} },t<em>{ {y}</em>{max} }]$，而这就是光线在整个包围盒内部的部分，三维情况下同理。</p><p><img src="25.png" width="25%"></p><p>对平面求交点是一件比较简单的事情，上图中所示的情形，我们可以写出其解为：</p><script type="math/tex; mode=display">t=\frac{p'_x-o_x}{d_x}</script><p>只需要一次减法一次除法，相比于对任意面的求解，减少了不少计算量。</p><p>我们继续通过二维情况下的一个例子来说明包围盒是如何加速光线追踪的。</p><p><img src="26.png" width="25%"></p><p>考虑上图中的情况，我们已经找到了待渲染物体的一个包围盒，接下来我们要将该包围盒划分为数个网格（Grid）：</p><p><img src="27.png" width="25%"></p><p>之后我们将所有带有物体表面的网格标记出来：</p><p><img src="28.png" width="25%"></p><p>这样当我们计算光线追踪时，可以先判断光线穿过的网格是否被标记，只有被标记的网格才进行具体的计算：</p><p><img src="29.png" width="25%"></p><p>至于光线穿过的格子如何进行计算，那就是另一个话题了，其实本质上就是光栅化一条线的过程。</p><p>网格的划分数量会影响加速的效果，极端情况下，只有一个网格时，就相当于没有划分，也就没有加速效果；而网格划分过于密集的话，又会因为要判断的网格太多，导致加速效果不明显，甚至起到反作用。</p><p><img src="30.png" width="40%"></p><p>一个普遍的结论是网格数与场景中的物体数相关，在三维情况下理想的数量应该是27倍的物体数，不过还是要具体问题具体分析。</p><p>网格划分有一个问题，那就是适用于那些几何体均匀分布的场景，一旦面临分布不均匀的场景，会出现大量空白网格。</p><h3 id="空间划分"><a href="#空间划分" class="headerlink" title="空间划分"></a>空间划分</h3><p>为了更好地应对几何体分布不均匀的场景，我们还会使用空间划分的方法，以下是几种典型的空间划分数据结构：</p><p><img src="31.png" width="40%"></p><p>图左是八叉树，就是将空间按直角坐标系划分为等大的八块区域，对新的小区域也能进一步进行划分（图中是2维情形，此时应该称为四叉树更恰当），我们可以为其指定一个划分终止条件，例如如果一次划分后的区域内只有一个区域内存在表面，则不进行该次划分，从而减少空白区域的出现。</p><p>图中是KD树，它每次划分也按照直角坐标系方向，但只取一个方向将区域划分为两个部分，不过不要求这两个部分大小一致，一般来说通常会交替使用不同的坐标轴方向来划分，例如图中就是$x$方向和$y$方向交替划分，这样可以保证划分基本上是均匀的。</p><p>图右是BSP树，它在KD树的基础上，允许划分朝任何方向，这带来了极高的划分自由度，但同时也带来了难以计算的难题。</p><p>这里我们就详细介绍一下KD树，正如其名，它用树的形式保存了空间划分的信息，如下所示：</p><p><img src="32.png" width="40%"></p><p>其中的$ABCD$节点表示了几次划分，例如$B$是在$A$划分的右半区域上进行的，因此它就是$A$的右孩子，叶子节点则表示了最终划分完的所有区域，因此，非叶子节点和叶子节点要存储的信息是不同的。</p><p>非叶子节点表达划分，因此要存储的信息包括：</p><ul><li>划分方向</li><li>划分坐标</li><li>孩子指针</li></ul><p>叶子节点要存储的信息有：</p><ul><li>几何体列表</li></ul><p>注意，<strong>非叶子节点中不存储任何几何体信息</strong>。</p><p>KD树对光线追踪的加速，是通过逐个判断光线与划分是否相交来实现的，例如下图中的光线：</p><p><img src="33.png" width="40%"></p><p>我们首先明确一个事实：当光线穿过一个划分时，也必然穿过其划分出的两个区域。</p><p>于是，我们就可以从根节点出发，逐个判断，在这个例子中，我们发现光线穿过了划分$A$，因此，对于$A$的左孩子区域1，我们需要进行进一步的计算；而对于其右孩子划分$B$，我们要再次进行判断：</p><p><img src="34.png" width="40%"></p><p>对于那些没有相交的划分，例如划分$D$，我们就可以不再遍历其子树，如下所示：</p><p><img src="35.png" width="40%"></p><p>从而能只计算那些可能有交点的区域。</p><p>KD树存在下述问题：</p><ul><li>很难判断一个形状是否在一个区域内，也就是划分的位置不好确定</li><li>划分无法保证物体只存在于一个区域内（例如上例中右下角的圆，同时出现在了三个区域中）</li></ul><p>因此KD树的使用也越来越少。</p><h3 id="物体划分——层次包围体"><a href="#物体划分——层次包围体" class="headerlink" title="物体划分——层次包围体"></a>物体划分——层次包围体</h3><p>KD树的问题也是多数空间划分方法的共性问题，物体划分方法则能规避这些问题。</p><p>物体划分从场景中的物体角度出发进行划分，这里介绍其中一种方法——层次包围体（Bounding Volume Hierarchy，简称BVH）。</p><p>BVH也通过树形结构保存信息，这里介绍如何构建一棵BVH树。</p><p><img src="36.png" width="40%"></p><p>如上图中的这个场景，里面分布着许多的三角形，我们将原始的场景作为根节点。</p><p>然后，我们将所有的三角形分为两部分，并求出它们的包围盒，分别作为根节点的左右孩子：</p><p><img src="37.png" width="40%"></p><p>反复重复上述步骤，直到满足实际要求，最终结果如下所示：</p><p><img src="38.png" width="40%"></p><p>关于划分方向和位置的确定，有一个简单的方法：</p><ol><li>每次划分把最长的那一维分割，例如矩形就垂直于长的那条边划分</li><li>位置选取为中间的那个物体，注意这里并不是包围盒中间，而是次序中间</li></ol><p>同样，这里列出BVH树中存储的信息：</p><p>非叶子节点表达划分，不同于KD树，只要保存包围盒信息就可以：</p><ul><li>包围盒</li><li>孩子指针</li></ul><p>叶子节点要存储的信息有：</p><ul><li><p>包围盒</p></li><li><p>几何体列表</p></li></ul><p>至于加速光线追踪的部分，其实和KD树是类似的，也是从根节点出发进行判断，这里给出伪代码：</p><p><img src="39.png" width="40%"></p><p>BHV的优点就在于一个物体只会存在于一个包围盒中，但是各个包围盒之间会出现重叠的现象，但相比于空间划分方法，BHV的实现更为简单，效率也更高，因此得到了广泛的应用。</p><h2 id="基础辐射度量学"><a href="#基础辐射度量学" class="headerlink" title="基础辐射度量学"></a>基础辐射度量学</h2><p>在进一步深入前，为了能更准确地描述光的信息，我们需要一些辐射度量学的知识，这里仅介绍一些基础知识。</p><h3 id="辐射能量与功率（通量）"><a href="#辐射能量与功率（通量）" class="headerlink" title="辐射能量与功率（通量）"></a>辐射能量与功率（通量）</h3><p>辐射的能量通常用符号$Q$表示，单位为焦耳（$J$）。</p><p>功率代表着单位时间内放射、反射、传递等过程中的辐射能量，其定义式为：</p><script type="math/tex; mode=display">\Phi=\frac{\mathrm{d}Q}{\mathrm{d}t}</script><p>单位为瓦特（$W$），在照明场景下，还有一个类似的概念称为光通量，其单位为流明（$lm$）。</p><p><img src="40.png" width="25%"></p><p>我们能在上图中看见有关通量的一个形象示例，在单位时间内通过右侧平面的光辐的数量就是光通量。</p><h3 id="重要光照物理量"><a href="#重要光照物理量" class="headerlink" title="重要光照物理量"></a>重要光照物理量</h3><p><img src="41.png" width="35%"></p><p>在了解了基础的能量与通量后，我们就能来关注以上几个重要的物理量，分别是发光强度、辐照度和辐射率，它们对应了上面三个典型的辐射场景。</p><h4 id="Intensity——发光强度"><a href="#Intensity——发光强度" class="headerlink" title="Intensity——发光强度"></a>Intensity——发光强度</h4><p>当有一个在向外放射光线的点时，我们引入发光强度的概念来描述它。</p><p>发光强度被定义为是点光源在单位立体角上放射出的功率，其数学表达式为：</p><script type="math/tex; mode=display">I(\omega)=\frac{\mathrm{d}\Phi}{\mathrm{d}\omega}</script><p>其单位为坎德拉，简称坎（cd）。</p><p>立体角的概念类似于角，角的定义是弧长比上半径，而立体角的定义是表面积比上半径，如下所示。</p><p><img src="42.png" width="35%"></p><p>单位立体角的计算如下：</p><p><img src="43.png" width="35%"></p><p>主要思路是先取单位表面积，然后求出单位立体角，其推导过程类似于高数中球坐标系下的三重积分，这里就不再详细深入。</p><p><img src="44.png" width="25%"></p><p>通常我们就用向量$\omega$来代表方向。</p><p>特殊地，对于一个均匀放射光线的光源：</p><p><img src="45.png" width="20%"></p><p>如果我们将发光强度在整个表面上进行积分，那么就应该有：</p><script type="math/tex; mode=display">\Phi=\int_{S^2}Id\omega=4\pi I</script><p>从而我们获得：</p><script type="math/tex; mode=display">I=\frac{\Phi}{4\pi}</script><p>就能够轻松得到表面上任意点的发光强度。</p><h4 id="Irradiance——辐照度"><a href="#Irradiance——辐照度" class="headerlink" title="Irradiance——辐照度"></a>Irradiance——辐照度</h4><p>辐照度用以描述一个区域吸收光照的情况，它被定义为是物体表面单位面积上所吸收的功率，其定义式为：</p><script type="math/tex; mode=display">E(x)=\frac{\mathrm{d}\Phi}{\mathrm{d}A}</script><p>其单位为勒克斯（lx）。</p><p>在Shading一文的Blin-Phong模型部分，我们其实已接触过辐照度的相关性质，我们得出过结论：</p><ul><li>着色点接收到的能量与入射角$\theta$的余弦值成正比。</li><li>某一点接收到的能量，与它到光源距离的平方成反比</li></ul><p>即：</p><script type="math/tex; mode=display">I\propto \cos\theta=\vec{n}·\vec{l} \\I\propto \frac{1}{r^2}</script><p>当时所说的能量，其实就是这里的辐照度（着色点就是单位面积）。</p><p><img src="46.png" width="40%"></p><p><img src="47.png" width="35%"></p><h4 id="Radiance——辐射率"><a href="#Radiance——辐射率" class="headerlink" title="Radiance——辐射率"></a>Radiance——辐射率</h4><p>当我们要 描述一条光线在传播过程中的属性时，我们引入辐射率的概念。</p><p>辐射率被定义为：指定方向上的单位立体角和垂直此方向的单位面积上的辐射通量。</p><p>其定义式为：</p><script type="math/tex; mode=display">L(p,\omega)=\frac{\mathrm{d}^2\Phi(p,\omega)}{\mathrm{d}\omega dAcos\theta}</script><p><img src="48.png" width="35%"></p><p>其单位为尼特（nit）。</p><p>从辐射率定义中的<strong>单位立体角</strong>和<strong>单位面积</strong>出发，我们可以将辐射率从另外两个角度理解：</p><ul><li>辐射率是单位立体角上的辐射度</li><li>辐射率是单位面积上的发光强度</li></ul><h4 id="辐照度与辐射率"><a href="#辐照度与辐射率" class="headerlink" title="辐照度与辐射率"></a>辐照度与辐射率</h4><p>辐照度与辐射率在图形学中的使用非常广泛，我们着重讨论一下它们之间的关系。</p><p>辐照度和辐射率之间的区别在于，辐照度描述一个区域吸收光照的情况，而辐射率描述该区域在<strong>特定方向</strong>上吸收光照的情况。</p><p><img src="49.png" width="30%"></p><p>如上图中，辐照度关注整个半球面吸收的所有光照，而辐射率仅关注$d\omega$方向上的光照，从而我们得出：只要把整个半球面上的辐射率积分，就能获得辐照度。</p><p>即：</p><script type="math/tex; mode=display">E(p)=\int_{H^2}L_i(p,\omega)cos\theta \mathrm{d}\omega \\dE(p)=L_i(p,\omega)cos\theta \mathrm{d}\omega</script><h2 id="双向反射分布函数——BRDF"><a href="#双向反射分布函数——BRDF" class="headerlink" title="双向反射分布函数——BRDF"></a>双向反射分布函数——BRDF</h2><p>双向反射分布函数（Bidirectional Reflection Distribution Function，简称BRDF）使用了我们提到的辐照度与辐射率之间的关系，是一个非常好的光照模型。</p><p>我们现在来重新审视光的反射，在反射场景下，一束光会被反射到四面八方（漫反射与镜面反射）。</p><p><img src="50.png" width="30%"></p><p>在上图中，假设有一束光从$\omega_i$方向射向区域$dA$，进而发生反射，我们可以将这过程拆分为两步。</p><p>首先，区域吸收入射光线的能量，我们有表达式：</p><script type="math/tex; mode=display">dE(\omega_i)=L(\omega_i)cos\theta_i\mathrm{d}\omega_i</script><p>其次，从该区域朝某个特定方向放射出去的能量，我们设为$dL_r(x,\omega_r)$。</p><p>那么我们只需要找到它们之间的比例，就能构建出漫反射的光照模型，具体而言就是找到函数：</p><script type="math/tex; mode=display">f_r(\omega_i \rightarrow \omega_r)=\frac{dL_r(x,\omega_r)}{dE(\omega_i)}=\frac{dL_r(x,\omega_r)}{L(\omega_i)cos\theta_id\omega_i}</script><p>经过变形，我们可以获得：</p><script type="math/tex; mode=display">L_r(x,\omega_r)=\int_{H^2}f_r(\omega_i \rightarrow \omega_r)L(\omega_i)cos\theta_i\mathrm{d}\omega_i</script><p>这个表达式告诉了我们，只要将所有入射光的能量全部加起来，就能获得某个出射方向上的总能量。</p><p>不难发现，这个表达式的计算是递归的，因为等式左边的结果是辐射率，而其计算所需的也是辐射率，这和真实光照环境有着良好的对应关系：对于一个物体，照亮它的不仅是光源直射的光，还有其它物体反射的光。</p><p>在这个表达式中，我们可以计算出物体的反射辐射率，并用该辐射率递归地参与其它物体的计算。</p><p>该方程只描述了反射场景，而某些物体除了反射光线外，自身也会发出光线，于是我们为该式加上一个自发光项：</p><script type="math/tex; mode=display">L_r(x,\omega_r)=L_e(x,\omega_r)+\int_{H^2}f_r(\omega_i \rightarrow \omega_r)L(\omega_i)cos\theta_i\mathrm{d}\omega_i</script><p>这个方程称为<strong>渲染方程</strong>。</p><p><img src="51.png" width="40%"></p><p>在渲染方程中，有些部分我们是已知的，包括自发光项、BRDF和余弦值，需要计算的其实只有两端的辐射率。</p><p>从而我们能将其简写为：</p><p><img src="52.png" width="40%"></p><p>如果我们再引入算子，我们可以更进一步简写该式：</p><p><img src="53.png" width="20%"></p><p>解该方程，我们获得：</p><script type="math/tex; mode=display">L=(I-K)^{-1}E=(I+K+K^2+...)E=E+KE+KE^2+...</script><p>这个式子实际上是按照反射次数对光线进行分解，如下所示：</p><p><img src="54.png" width="40%"></p><p>我们之前提到的的光栅化可以很快地计算前两项（也就是自发光和直射光），但难以涉及到后面几项。</p><h2 id="蒙特卡洛积分"><a href="#蒙特卡洛积分" class="headerlink" title="蒙特卡洛积分"></a>蒙特卡洛积分</h2><p>计算光照的过程中，我们会有很多的积分计算，但不是所有的积分都能够直接计算，所以我们介绍蒙特卡洛积分法。</p><p>（这里我们只讨论定积分）</p><p>对于一般的积分问题，被积函数可能较为复杂，难以直接写出其定积分公式，如下所示：</p><p><img src="55.png" width="40%"></p><p>传统的黎曼积分利用$dx$对应的矩形面积来计算，而蒙特卡洛积分则基于随机采样来进行计算。</p><p>具体而言，假设我们现在要求的积分为：</p><script type="math/tex; mode=display">\int^b_a{f(x)}\mathrm{d}x</script><p>我们可以任取一种分布的随机变量（分布在积分域间）：</p><script type="math/tex; mode=display">X_i \sim p(x)</script><p>用该变量对$f(x)$进行采样，可获得定积分的近似值：</p><script type="math/tex; mode=display">F_N=\frac{1}{N}\sum_{i=1}^{N}\frac{f(X_i)}{p(X_i)}</script><p>其中$N$为采样次数，一般而言，采样次数越多，结果会越精确。</p><p>更具体的理论知识这里就不展开了，这里只简单介绍该方法。</p><h2 id="Path-Tracing——路径追踪"><a href="#Path-Tracing——路径追踪" class="headerlink" title="Path Tracing——路径追踪"></a>Path Tracing——路径追踪</h2><p>之前我们介绍过递归光追算法，它其实存在一些问题。</p><p>主要的问题在反射上，该算法只考虑了镜面反射的情形，而忽略了漫反射情形，在面对下面两种材质时：</p><p><img src="56.png" width="40%"></p><p>递归光追可以计算左侧茶壶的光照，但右边的就不行。</p><p>引申出来的另一个问题就是会丢失漫反射物体之间相互反射的光线，如下图中：</p><p><img src="57.png" width="40%"></p><p>由于只考虑直接光照，递归光追算法会计算出很多暗区（左图的天花板等），而事实上，经过多次漫反射后，这些暗区其实是能够被点亮的（右图）。</p><p>更细节的地方是，这些暗区不仅是是否点亮的问题，可以看见右图中的两个长方体，都被照上了墙壁的颜色，而连照亮都没法考虑到的递归算法，自然也没法计算这部分着色。</p><p>为了解决这些问题，我们引入路径追踪算法，该算法基于渲染方程，这里我们再写一遍渲染方程：</p><script type="math/tex; mode=display">L_r(p,\omega_o)=L_e(p,\omega_o)+\int_{\Omega^+}L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)(n·\omega_i)\mathrm{d}\omega_i</script><p>现在我们介绍如何解该渲染方程。</p><p>这里我们先忽略自发光项，仅考虑反射项，即只计算：</p><script type="math/tex; mode=display">L_0(p,\omega_o)=\int_{\Omega^+}L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)(n·\omega_i)\mathrm{d}\omega_i</script><p><img src="58.png" width="25%"></p><p>这是一个积分域为半球面的积分，我们使用蒙特卡洛积分来计算。</p><p>这里我们的被积函数为：</p><script type="math/tex; mode=display">L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)(n·\omega_i)</script><p>采样的概率密度函数（PDF）有很多种取法，最简单的一种取法为均匀采样：</p><script type="math/tex; mode=display">f(\omega_i)=\frac{1}{2\pi}</script><p>从而依据蒙特卡洛积分法，我们有：</p><script type="math/tex; mode=display">L_0(p,\omega_o)\approx \frac{1}{N}\sum_{i=1}^{N}\frac{L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)(n·\omega_i)}{f(\omega_i)}</script><p>这个形式就可以用计算机来进行计算了，我们只需要多取几个入射方向$\omega _i$然后将结果求和就可以，其伪代码形式为：</p><pre class="line-numbers language-none"><code class="language-none">shade(p, wo)Randomly choose N directions wi~pdfLo = 0.0For each wi\\ 对于每个入射方向Trace a ray r(p, wi)\\ 向该方向放出射线If ray r hit the light\\ 如果射线触碰到光源Lo += (1 / N) * L_i * f_r * cosine / pdf(wi)\\ 积分累加Return Lo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来我们需要完善另一种情形，就是入射光是由其它物体反射过来的，如下图所示：</p><p><img src="59.png" width="50%"></p><p>这种情况其实相当于我们从$P$点观测$Q$点，因此我们可以递归地计算，伪代码修改起来很简单，只要在入射方向中增加一个判断：</p><pre class="line-numbers language-none"><code class="language-none">shade(p, wo)Randomly choose N directions wi~pdfLo = 0.0For each wi// 对于每个入射方向Trace a ray r(p, wi)// 向该方向放出射线If ray r hit the light// 如果射线触碰到光源Lo += (1 / N) * L_i * f_r * cosine / pdf(wi)// 积分累加       Else If ray r hit an object at q       // 如果射线触碰到其它物体Lo += (1 / N) * shade(q, -wi) * f_r * cosine / pdf(wi)// 递归计算Return Lo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是，该方法仍然存在一些问题。</p><p>第一个问题，光线的数量会随着反射次数的增加指数级增长。</p><p><img src="60.png" width="50%"></p><p>例如上图，假设我们每个反射采样100次，那么三次反射后，采样数会变为1000000，这还仅是一个初始反射点。</p><p>为了避免这种问题，我们将采样次数限定为1次（1的任何次幂都是1），从而伪代码修改为：</p><pre class="line-numbers language-none"><code class="language-none">shade(p, wo)Randomly choose ONE directions wi~pdf// 只选择一个方向Lo = 0.0   Trace a ray r(p, wi)   // 向该方向放出射线   If ray r hit the light   // 如果射线触碰到光源       Return L_i * f_r * cosine / pdf(wi)       // 直接计算   Else If ray r hit an object at q   // 如果射线触碰到其它物体       Return* shade(q, -wi) * f_r * cosine / pdf(wi)       // 递归计算<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种只有1次采样的方法，就是我们所说的路径追踪。</p><p>（因为这相当于只有一条射线在反射，故称为路径）</p><p>不过大家很容易就会想到，这样的结果肯定会非常不准确，那这又该如何解决？</p><p>很简单，虽然我们的反射退化为路径，但我们可以计算多条路径，如下图：</p><p><img src="61.png" width="40%"></p><p>由于像素存在大小，因此对于每个像素，我们可以引出很多条路径，只要路径数目足够，我们就能消除退化带来的不准确。</p><p>（事实上，即使像素是一个点，我们也可以在同一个方向上计算多次路径）</p><p>这个过程的伪代码为：</p><pre class="line-numbers language-none"><code class="language-none">ray_generation(camPos, pixel)Uniformly choose N sample positions within the pixel// 在一个像素上选择多个采样方向pixel_radiance = 0.0For each sample in the pixel// 对于每个方向Shoot a ray r(camPos, cam_to_sample)// 向该方向放出射线If ray r hit the scene at p// 如果射线触碰到物体pixel_radiance += 1 / N * shade(p, sample_to_cam)// 累加计算Return pixel_radiance<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第二个问题就是shading函数的中止条件，在该函数中，我们还没有设置递归的出口，如果有射线进行了无限（足够多）次反射，同样会引发计算问题。</p><p>我们不能简单地使用反射次数来判断中止，因为截断反射意味着截断能量，导致光照失真。</p><p>我们有一个3次反射截断的渲染场景：</p><p><img src="62.png" width="40%"></p><p>相同的场景，我们如果在17次截断，效果是这样的：</p><p><img src="63.png" width="40%"></p><p>不难发现，上方的灯盒左侧墙壁都变得更加真实，而我们其实还不知道，17次反射是否已经足够。</p><p>解决的方案是使用俄罗斯轮盘赌（Russian Roulette，简称PR）。</p><p>简单来说就是限制一个概率$P$，对于每次shading函数，我们增加一个判断：</p><ul><li>在$P$的概率下，我们返回$L_o/P$</li><li>在$1-P$的概率下，我们返回0</li></ul><p>这么做可以让函数在某个递归时结束计算的同时，保证期望仍然准确，因为其期望为：</p><script type="math/tex; mode=display">E=P*(L_o/P)+(1-P)*0=L_o</script><p>我们只需要在原先的伪代码前加上一段，并在结果上除以对应的概率即可：</p><pre class="line-numbers language-none"><code class="language-none">shade(p, wo)    Manually specify a probability P_RR    // 定义概率    Randomly select ksi in a uniform dist. in [0, 1]    If (ksi &gt; P_RR) return 0.0;    // 概率截断        Randomly choose ONE direction wi~pdf(w)    Trace a ray r(p, wi)   // 向该方向放出射线   If ray r hit the light   // 如果射线触碰到光源       Return L_i * f_r * cosine / pdf(wi) / P_RR       // 直接计算（除以概率）   Else If ray r hit an object at q   // 如果射线触碰到其它物体       Return* shade(q, -wi) * f_r * cosine / pdf(wi) / P_RR       // 递归计算（除以概率）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>到此，我们就获得了一个完全正确的路径追踪算法。</p><p>不过它仍旧不够高效，我们看下图中的对比：</p><p><img src="64.png" width="50%"></p><p>左图是单个像素引出路径较少时的情形，可以看见噪点非常多，只有当路径数很多时，才能有右图这样的效果。</p><p>这是因为每条路径是否能够触碰到光源是一个比较“随缘”的过程，如下图：</p><p><img src="65.png" width="40%"></p><p>对于光源比较大的情形（左图），我们可能几条路径都能触碰到光源，从而计算较快，但如果光源比较小（右图），那就可能在放出很多条路径的情况下也没几条能够触碰到光源，从而进行无效计算。</p><p> 因此如果我们能只采样光源，那么就可以避免这些无效的计算。</p><p>我们假设现在是这样一个场景：</p><p><img src="66.png" width="30%"></p><p>假设光源面积为$A$，由于我们的目标是采样光源，那么PDF应该是：</p><script type="math/tex; mode=display">pdf=1/A</script><p>不过在渲染方中，我们的积分项是$d \omega$，因此我们知道它们之间的关系，这个关系其实并不难计算：</p><script type="math/tex; mode=display">d \omega = \frac{dA \cos{\theta'}}{||x'-x||^2}</script><p>简单来说就是先计算$dA$在$d \omega$上的投影，然后利用相似缩放的性质获得结果。</p><p>（微分弧面近似于微分平面）</p><p>从而渲染方程改写为：</p><script type="math/tex; mode=display">L_0(p,\omega_o)=\int_{\Omega^+}L_i(p,\omega_i)f_r(p,\omega_i,\omega_o)\frac{\cos{\theta} \cos{\theta'}}{||x'-x||^2}dA</script><p>从而我们将光照拆分为两个部分：</p><p><img src="67.png" width="40%"></p><p>蓝色的是直接光照部分，使用改写的渲染方程；橙色的是其它光照部分，使用原始渲染方程。</p><p>同时我们考虑下遮挡的情况：</p><p><img src="68.png" width="30%"></p><p>于是，我们修改伪代码为：</p><pre class="line-numbers language-none"><code class="language-none">shade(p, wo)    # 直接光照部分    Uniformly sample the light at x’ (pdf_light = 1 / A)    Shoot a ray from p to x’    If the ray is not blocked in the middle    L_dir = L_i * f_r * cos θ * cos θ’ / |x’ - p|^2 / pdf_light         # 其它反射部分    L_indir = 0.0    Test Russian Roulette with probability P_RR    Uniformly sample the hemisphere toward wi (pdf_hemi = 1 / 2pi)    Trace a ray r(p, wi)    If ray r hit a non-emitting object at q    L_indir = shade(q, -wi) * f_r * cos θ / pdf_hemi / P_RR        Return L_dir + L_indir<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但对于路径追踪来说，点光源非常难处理，这里就不介绍了。</p><p>至此，光线追踪章节正式结束，这应该是本系列最长的的一篇文章，笔者在撰写时也受益良多，学无止境啊。</p><p>好的，那我们下篇文章见。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（四）——Geometry</title>
      <link href="/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/"/>
      <url>/2024/01/16/games101-ke-cheng-bi-ji-si-geometry/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（四）——Geometry"><a href="#GAMES101课程笔记（四）——Geometry" class="headerlink" title="GAMES101课程笔记（四）——Geometry"></a>GAMES101课程笔记（四）——Geometry</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>没想到第四篇内容的更新直接拖到了今年，最近几个月确实是挺忙的。</p><p>现在我们的主题来到了几何，这块内容主要有关于如何在计算机中表示和操作几何形体，并且会牵涉到不少数学知识，笔者也是希望这篇文章能够深入浅出地为各位读者解释清原课程中的内容，欢迎各位的阅读和批评指正。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><p><a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a></p><h2 id="几何表示方式"><a href="#几何表示方式" class="headerlink" title="几何表示方式"></a>几何表示方式</h2><p>现实生活中有很多几何物体，例如下图中各种形状的玻璃杯。</p><p><img src="1.png" width="60%"></p><p>事实上，还有很多的几何形体，小到一滴水激起的涟漪，大到能够驶向宇宙的火箭，更复杂的还包括我们身着的衣物布料，肉眼所不能见的病毒，等等。</p><p>在图形学中，我们就需要研究如何使用计算机来表示这些几何形体，大体上我们可以将表示方式分为两类——隐式（Implicit）和显式（Explicit）。</p><p><img src="2.png" width="40%"></p><h3 id="隐式表示"><a href="#隐式表示" class="headerlink" title="隐式表示"></a>隐式表示</h3><p>隐式表示中，我们通过给出点所满足的关系来定义几何形体，例如我们知道，球面的一种表达是：</p><script type="math/tex; mode=display">x^2+y^2+z^2=1</script><p>这其实就是一种隐式表示，即满足该等式的点就在球面上，反之就不在，可以看做是一种分类的思想。</p><p>在更一般的情况下，隐式表示通常能以下述形式给出：</p><script type="math/tex; mode=display">f(x,y,z)=0</script><p>隐式表示的好处显而易见，即给出空间中任意一点，我们可以很容易地判断它是否在面上（在形体内外）。</p><p>如下图中的示例，我们只要代入对应的参数，就能进行判断。</p><p><img src="3.png" width="40%"></p><p>其坏处在于，有时我们很难从方程式看出它所表示的形状，例如下面的这个例子：</p><p><img src="4.png" width="40%"></p><p>即当我们想要去找到在平面上的点时，会比较困难。</p><h3 id="显式表示"><a href="#显式表示" class="headerlink" title="显式表示"></a>显式表示</h3><p>与隐式表示相对，我们还有显式表示的方法，就是想办法表示出几何形状本身（例如顶点），例如我们之前所用的三角形面就是一种显示表示。</p><p>这里介绍另外一种显式表示的方法——参数映射。</p><p><img src="5.png" width="40%"></p><p>参数映射给出一个从$(u,v)$坐标到$(x,y,z)$坐标的函数，我们只需要遍历$(u,v)$坐标，再结合映射函数，就能得到三维空间中的几何形状。</p><p>（这里的$(u,v)$坐标系为$[0,1]×[0,1]$）</p><p>显式表示的好处与坏处恰好与隐式表示相反，其优势在于容易找到所有在面上的点，例如：</p><p><img src="6.png" width="40%"></p><p>因为$(u,v)$坐标系的范围固定，所以我们只要将所有的$(u,v)$坐标代入该式子，就能获得所有点，</p><p>反之，在判断某一点是否在面上时，由于我们不知道其对应的$(u,v)$坐标，就很难判断了：</p><p><img src="7.png" width="40%"></p><p>目前并没有一个完美的几何表示方法，我们只能依据实际情况来选择表示方法。</p><h3 id="更多隐式表示方式"><a href="#更多隐式表示方式" class="headerlink" title="更多隐式表示方式"></a>更多隐式表示方式</h3><h4 id="CSG——构造几何实体"><a href="#CSG——构造几何实体" class="headerlink" title="CSG——构造几何实体"></a>CSG——构造几何实体</h4><p>CSG是通过一些基本几何体的交并运算来表示其它的几何体，下图展示了CSG的三种基本运算：</p><p><img src="8.png" width="50%"></p><p>通过对简单几何体的多次交并运算，我们可以获得我们想要的复杂几何体。</p><h4 id="距离函数"><a href="#距离函数" class="headerlink" title="距离函数"></a>距离函数</h4><p>该表示方法有点类似于求“中间状态”，但求的是我们定义的一个“距离函数”的中间状态。</p><p>为什么需要定义距离函数？我们可以通过下述例子来理解。</p><p><img src="9.png" width="50%"></p><p>如上图，假设现在有两张图A和B，左边黑色的部分表示几何体，几何体A占据了左边1/3，几何体B占据了左边2/3的部分。</p><p>现在考虑如何求几何体A和几何体B的一个中间几何体，可以想象是几何体A像橡皮泥一样逐渐变为几何体B的过程中，某一个时刻的状态。</p><p>因此在结果图中，也应该是黑色占据了左边一部分，其余为白色。</p><p>但如果我们只是对A和B两张图进行线性插值，我们获得的结果是图右的样子，即左边1/3是黑色，中间1/3是灰色，右边1/3是白色，不符合我们的预期。</p><p>这是因为这么做差值求的是“图片”的融合，而不是图中几何体的融合，为了实现我们的目的，我们可以先定义距离函数，如下所示：</p><p><img src="10.png" width="50%"></p><p>距离函数为空间中所有点定义一个到几何体表面的距离，在该例子中，我们就使用欧氏距离，同时在物体外为正距离，在物体内为负距离。</p><p>例如上图左，定义了图A空间的距离函数，黑色部分中的点距离全部为负，越靠左值越小；白色部分的点距离全为正，越靠右越大。</p><p>同理定义图B空间的距离函数后，我们将两个距离函数做线性插值，获得了一个全新的距离函数，然后我们再将该距离函数还原回几何体（在这个例子中，就是将负的部分涂黑，正的部分涂白），就实现了对几何体的融合（在该例子中，结果应是左边一半是黑的，右边一半是白的）。</p><p>总而言之，其具体步骤就是：</p><ol><li>为几何体A和几何体B定义距离函数</li><li>对距离函数进行blend运算，获得新距离函数</li><li>将新距离函数还原为几何体</li></ol><p>距离函数方法可以用于表达几何体之间的平滑过渡，下图中展示了一个方形和圆形在不同距离下融合的结果：</p><p><img src="11.png" width="60%"></p><p>这里贴一个距离函数方法做的场景图：</p><p><img src="12.png" width="60%"></p><h4 id="水平集"><a href="#水平集" class="headerlink" title="水平集"></a>水平集</h4><p>这个方法其实和距离函数方法的思想完全一致，只是水平集方法不使用方程来表达函数，而是直接将距离存储在对应的网格中，如下所示。</p><p><img src="13.png" width="40%"></p><p>原理其实是一样，只是在融合时，我们直接对每个网格做Blend运算，而不是对函数。</p><p>在结果中，我们可以找到那些邻接为一正一负的边缘，将它们视为距离为0的部分，从而还原出几何体。</p><p>其实敏感的读者可以发现，这与用纹理存储其他信息的方法如出一辙，这部分内容在<a href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/">GAMES101课程笔记（三）——Shading</a>中有详细阐述，因而</p><p>我们也可以像纹理一样拓展该方法，比如定义三维的水平集等等。</p><p><img src="14.png" width="30%"></p><p>以我们在前篇中提到过的医学CT场景为例，如果把扫描得到的密度存储为水平集（纹理），再取距离等于某个密度的点作为表面，就能看到不同密度组织的几何形状。</p><p>在物理模拟中，水平集方法也有很大的发挥空间，尤其是在气体和液体的模拟中：</p><p><img src="15.png" width="50%"></p><h4 id="分形"><a href="#分形" class="headerlink" title="分形"></a>分形</h4><p>分形指的是那些，自己的一部分与自己的整体一样的几何体，也就是具有自相似性的几何体，如下所示：</p><p><img src="16.png" width="40%"></p><p>分形可以用于描述很多自然界中的物体，由于自相似性的存在，它在各尺度下都具有相同的复杂程度，因此不会因缩放而丢失信息，不过也很难控制它成为自己想要的形状。</p><p>有关分形的内容其实挺复杂的，目前GAMES101也没详细涉及，看看以后有没有空写一篇博客吧（挖坑）。</p><h3 id="更多显示表示方式"><a href="#更多显示表示方式" class="headerlink" title="更多显示表示方式"></a>更多显示表示方式</h3><h4 id="点云"><a href="#点云" class="headerlink" title="点云"></a>点云</h4><p>点云用一系列的点$(x,y,z)$来表示几何模型，其原始形式类似于由点构成的一团云朵，故而得名（下图左）。</p><p><img src="17.png" width="40%"></p><p>其最大的优势就是灵活，几乎任何几何模型都能用点云来进行表示，但如果点云的密度比较低的话，还是会丢失很多细节信息。</p><p>不过很多时候我们不会直接使用点云模型，而是先将点云转换为多边形面。</p><h4 id="多边形面"><a href="#多边形面" class="headerlink" title="多边形面"></a>多边形面</h4><p>多边形面应该是现在应用最广泛的一种显示表示方式，它存储几何体顶点和面（通常是三角形或四边形）的信息。</p><p><img src="18.png" width="40%"></p><p>多边形面虽然要求更复杂的数据结构来进行存储，但比较容易进行处理，拥有非常广泛的适用性。</p><p>Wavefront Object File是一种常见的多边形面表示法的文件存储格式，文件扩展名为.obj，它用文本形式存储各种信息，如下所示。</p><p><img src="19.png" width="50%"></p><p>这些信息包含顶点、法线、纹理坐标和它们之间的连接情况。</p><p>上图的例子表示了一个立方体，我们逐个介绍其含义。</p><p>可以看见其中有8个$v$项，记录了立方体8个顶点的坐标。</p><p>$vt$项代表纹理坐标，对于每个面，需要定义其4个顶点的纹理坐标，理论上最多有24个$vt$项，不过由于顶点会有共用纹理坐标的情况，这里就不足24个。</p><p>8个$vn$项表示的是立方体6个面的法向量，这里有8个是因为使用了自动建模，其实里面有重复的法向量，理论上6个就足够。</p><p>最后的$f$项说明了它们之间的连接关系，以5/1/1为例，这一项说明的是有这么一个顶点，它的坐标是$v[5]$，纹理坐标是$vt[1]$，法线坐标是$vn[1]$。而每一个$f$项中包含三个顶点，这三个顶点构成一个三角面。</p><h2 id="Bezier-Curve——贝塞尔曲线"><a href="#Bezier-Curve——贝塞尔曲线" class="headerlink" title="Bezier Curve——贝塞尔曲线"></a>Bezier Curve——贝塞尔曲线</h2><p>曲线是几何中的重要元素，而在图形学中，贝塞尔曲线是非常常见的一种曲线，它由一系列的控制点来控制曲线形状。</p><p><img src="20.png" width="40%"></p><p>例如上图中的贝塞尔曲线，它的起始方向由控制点$p_0$和$p_1$决定，结束方向由控制点$p_2$和$p_3$决定，至于中间部分是如何画出来的，接下来将详细介绍。</p><h3 id="de-Casteljau-Algorithm——德卡斯特里奥算法"><a href="#de-Casteljau-Algorithm——德卡斯特里奥算法" class="headerlink" title="de Casteljau Algorithm——德卡斯特里奥算法"></a>de Casteljau Algorithm——德卡斯特里奥算法</h3><p>德卡斯特里奥算法是计算贝塞尔的曲线的常见方法，我们考虑用三个控制点来绘制贝塞尔曲线的情况：</p><p>（三个点的情况被称为二阶贝塞尔曲线）</p><p><img src="21.png" width="30%"></p><p>我们的目标是这样的：这条曲线应从$b_0$出发，到$b_2$结束，然后$b_1$能影响这条曲线的形状。</p><p>我们可以假想这样的一个情况，我们从时刻0开始绘制，一直绘制到时刻1，只要知道当中每个时刻$t$时，我们该绘制的点在哪，那这条曲线就绘制完成了。</p><p>假设我们给定时间$t$，我们分别在线段$b_0b_1$和线段$b_1b_2$上，找到比例为$t$的两个点$b_0^1$和$b_1^1$，如下所示：</p><p><img src="22.png" width="30%"></p><p>然后我们在线段$b_0^1b_1^1$上取比例为$t$的点$b_0^2$，该点就是$t$时刻时我们要绘制的点：</p><p><img src="23.png" width="30%"></p><p>任何一个时刻的点都依此法进行计算，就获得了我们最终的贝塞尔曲线。</p><p><img src="24.png" width="40%"></p><p>控制点数量更多的情况下，我们多次进行上述步骤，例如对于上图中四个点的情况，我们进行一次取点可以取到三个点（$b_0^1$，$b_1^1$和$b_2^1$），多次取点后就能取到最后的唯一点，从而构造出贝塞尔曲线。</p><h3 id="代数形式"><a href="#代数形式" class="headerlink" title="代数形式"></a>代数形式</h3><p>我们已经用直观的方式理解了贝塞尔曲线的构造方式，接下来我们从代数角度来理解贝塞尔曲线。</p><p>以四个控制点的贝塞尔曲线为例，我们刚才的绘制过程可以用下图来表示：</p><p><img src="25.png" width="40%"></p><p>由于结果至于控制点和参数$t$有关，因此我们可以用这些参数写出曲线的完整表达式。</p><p>由于每次操作其实都是一次线性插值，因此我们可以很快写出一系列方程：</p><p><img src="26.png" width="40%"></p><p>这就是二阶贝塞尔曲线的标准方程，对于更一般的情形，当贝塞尔曲线的阶数为$n$（控制点数目为$n+1$）时，其表达式为：</p><script type="math/tex; mode=display">b^n(t) = b_0^n(t) = \sum^n_{j=0}b_jB_j^n(t) \\B_j^n(t) = \begin{bmatrix}i \\n \end{bmatrix}t(1-t)^{n-i}</script><p>这就是Bernstein方程，不难看出这里的Bernstein多项式$B_j^n(t)$其实就是二次项系数，这从构造过程中就可以看出。</p><p>（毕竟这过程看着就像杨辉三角。。）</p><p>值得注意的是，这个表达式中的点$b_j$不一定限制在二维平面上，我们完全可以使用$R^3$中的点，用相同的公式来计算曲线。</p><p><img src="27.png" width="30%"></p><p>Bernstein多项式也有一些特性，我们可以将它看作是1的二次项展开，因此对于任意时刻$t$，所有$B_j^n(t)$的和总是1，并具有对称性。</p><h3 id="曲线性质"><a href="#曲线性质" class="headerlink" title="曲线性质"></a>曲线性质</h3><p>这里我们对贝塞尔曲线的性质做一个总结。</p><ul><li>曲线一定过起始控制点和结束控制点（一般情况下中间的控制点都不在曲线上）</li><li>起始点和结束点的斜率容易计算（例如三阶贝塞尔曲线，起点斜率$b’(0)=3(b_1-b_0)$）</li><li>对曲线本身做<strong>仿射变换</strong>和对控制点做<strong>仿射变换</strong>是等效的</li><li>曲线一定在控制点形成的凸包中</li></ul><p>凸包指的是能包围所有给定点的<strong>最小</strong>凸多边形，如下图中的蓝色部分：</p><p><img src="28.png" width="30%"></p><p>注意<strong>最小</strong>这一条件，我们可以想象有一根很小的橡皮筋，用它保住所有的点后形成的形状就是凸包。</p><p>（话说每次听别人讲凸包说的都是这个例子，确实是直观形象）</p><h3 id="逐段贝塞尔曲线"><a href="#逐段贝塞尔曲线" class="headerlink" title="逐段贝塞尔曲线"></a>逐段贝塞尔曲线</h3><p>根据我们刚才介绍的方法，无论多少阶的贝塞尔曲线我们都能绘制出来，但当阶数高时，会有一些别的问题出现。</p><p><img src="29.png" width="25%"></p><p>考虑上图中的10阶贝塞尔曲线，虽然我们绘制出来了，但这条曲线并不是很直观，比如中间的控制点是左右弯曲的，最终曲线却趋近于直线，难以控制。</p><p>因此就有了逐段贝塞尔曲线的概念，就是我们不将整条曲线看作是一个高阶整体，而是由多段低阶贝塞尔曲线连接而成。</p><p>最常用的就是用三阶贝塞尔曲线来进行拼接，如下所示：</p><p><img src="30.png" width="40%"></p><p>这里只绘制了第一段曲线的四个控制点，为了方便观察，将曲线的起始和结束斜率也绘制了出来。</p><p>（Photoshop的钢笔工具也是这样的）</p><p>由于是逐段拼接，因此在曲线连接处可能会出现不平滑的情况，因此我们有一系列的连续规范。</p><p>最简单的连续性要求就是$C^0$连续，就是我们理解的“连在一起”，如下所示：</p><p><img src="31.png" width="40%"></p><p>用数学语言描述就是$a_n=b_0$，即每条曲线首尾相连。</p><p>再高要求一点，我们可以使用$C^1$连续，这要求连接点必须是两侧控制点的中点，如下所示：</p><p><img src="32.png" width="40%"></p><p>对应的数学等式为$a<em>n=b_0=\frac{1}{2}(a</em>{n-1}+b_1)$，这能保证连接处的一阶导数连续，从而让曲线看上去更光滑。</p><p>按照这一思路，我们可以定义更高阶的连续性要求，也可以自行拓展要求，这就是使用控制点的灵活之处。</p><h3 id="样条"><a href="#样条" class="headerlink" title="样条"></a>样条</h3><p>虽然贝塞尔曲线很常用，但它并不是图形学中唯一常用的曲线，这里简单介绍一个概念——样条（spline）。</p><p>样条由一系列控制点控制，并且每一点都满足一定的连续性，可以说是贝塞尔曲线的父集。</p><p><img src="33.png" width="40%"></p><p>上图展示了一种直观理解，我们在桌子上摆放好卡扣，然后用一根树枝穿过它们，树枝的形状就是一根样条，这些卡扣就是它的控制点。</p><p>有一种特殊的样条——B样条，是贝塞尔曲线的扩展形式，它相比贝塞尔曲线有更好的局部性。在贝塞尔曲线中，我们移动控制点会导致一部分的曲线发生变化，有些环境下我们希望更精细的操作，即控制点影响的范围更小的一点，这就是局部性。</p><p>不过B样条的内容非常复杂，本课程就暂不涉及更详细的介绍了，有机会就单独开篇博客吧。</p><p>（挖坑×2）</p><h2 id="贝塞尔曲面"><a href="#贝塞尔曲面" class="headerlink" title="贝塞尔曲面"></a>贝塞尔曲面</h2><p>聊完了曲线，接下来就到曲面了，事实上贝塞尔曲线的思路可以沿用到曲面中，下图就是用贝塞尔曲面绘制的几何体：</p><p><img src="34.png" width="50%"></p><p>贝塞尔曲面的控制点分布是二维的，例如我们可以像下图一样，用4×4个控制点来控制一块曲面：</p><p><img src="35.png" width="30%"></p><p>贝塞尔曲面的输入是这4×4个控制点，而输出其实是一个[0,1]*[0,1]的矩阵，每个元素指明了曲面上点的位置，有点类似纹理。</p><p><img src="36.png" width="40%"></p><p>下图展示了一个具体的求曲面过程：</p><p><img src="37.png" width="40%"></p><p>当我们要求$(u,v)$处的点时，我们可以先求出4条$u$方向上的贝塞尔曲线，如图中的四条灰线。</p><p>然后我们再取这4条曲线在$u$处的点，将这4个点作为控制点，用参数$v$再求一次贝塞尔曲线，如图中的蓝线，这条曲线上$v$处的点，就是我们要求的点。</p><p>这里给出贝塞尔曲面计算过程的示意图：</p><p><img src="38.png" width="40%"></p><p>在<a href="https://acko.net/tv/wdcode/">Making Things With Maths — Acko.net</a>这个视频中，有关于这段绘制的具体描述，有兴趣的读者可以去看看。</p><h2 id="网格操作"><a href="#网格操作" class="headerlink" title="网格操作"></a>网格操作</h2><p>我们很多时候会使用网格模型（Mesh），针对于我们要使用的场景，需要对网格模型进行一些操作，下图展示了一系列的操作：</p><p><img src="39.png" width="60%"></p><p>网格操作主要有三种：</p><ul><li>Mesh Subdivision——网格细分</li><li>Mesh Simplification——网格简化</li><li>Mesh Regularization——网格正则</li></ul><p>接下来我们分别对他们进行解释。</p><h3 id="Mesh-Subdivision"><a href="#Mesh-Subdivision" class="headerlink" title="Mesh Subdivision"></a>Mesh Subdivision</h3><p>有时候我们希望使用的模型更加精细，这时就可以使用网格细分技术，增多模型的面数，如下所示：</p><p><img src="40.png" width="40%"></p><p>网格的细分并不是简单地将原本的面分解为小面，它同时还要改变小面的位置和角度，让模型更加光滑。</p><p><img src="41.png" width="40%"></p><h4 id="Loop-Subdivision"><a href="#Loop-Subdivision" class="headerlink" title="Loop Subdivision"></a>Loop Subdivision</h4><p>这里插一嘴，Loop细分法的名字并不是因为该算法和循环有关系，只是提出者的家族姓氏就是Loop。。</p><p>Loop细分法沿用了我们刚才提到的两步思路，它做了以下操作：</p><ul><li><p>将每个三角面分解为四个新的小三角面</p><p><img src="42.png" width="40%"></p></li><li><p>依据权重为新的顶点调整位置</p><p><img src="43.png" width="40%"></p></li></ul><p>在调整位置的时候，Loop细分法对于原本存在的旧顶点和因细化的新顶点，采取不同的调整策略。</p><p>我们先讨论新顶点，从分解的过程中我们可以看出，新的顶点一定是某个三角面一条边的中点。</p><p>对于一般情况，这条边肯定是由两个三角面所共享的（边界情况我们这里就不考虑了），也就是应该是下图这种情况，图中的白点是新顶点。</p><p><img src="44.png" width="20%"></p><p>那么该新顶点的位置应被调整为：</p><script type="math/tex; mode=display">p'=\frac{3}{8}(A+B)+\frac{1}{8}(C+D)</script><p>注意$A$和$B$是该新顶点所在边的端点，这里实际上是做了一个加权平均，至于系数为什么这么取，这里就不展开了。</p><p>旧顶点的位置更新稍稍复杂一点，在Loop细分法中，旧顶点的位置更新被认为与相邻旧顶点和自已的原位置有关系。</p><p>计算前我们需要引入两个参数，首先是顶点度数$n$，它指的是与该顶点连接的边的数目，例如下图中，中心顶点的度数就是6.</p><p><img src="45.png" width="20%"></p><p>其次是权值$u$，其表达式为：</p><script type="math/tex; mode=display">u=\begin{cases} \frac{3}{16} & n=3\\ \frac{3}{8n} & otherwise\end{cases}</script><p>不过我在网上找到的表达式似乎是这样的：</p><script type="math/tex; mode=display">u=\frac{1}{n}(\frac{5}{8}-(\frac{3}{8}+\frac{1}{4}\cos\frac{2\pi}{n})^2)</script><p>可能闫老师介绍的方法略有不同吧，总之我们旧顶点的位置就调整为：</p><script type="math/tex; mode=display">p'=(1-nu)p+u\sum{p_i}</script><p>这里$p$指的是该顶点的旧位置，$\sum p_i$指的是与其邻接的所有顶点位置求和，从而获得我们的新位置。</p><p>实际应用中，Loop细分可以取得非常不错的效果。</p><p><img src="46.png" width="40%"></p><h4 id="Catmull-Clark-Subdivision"><a href="#Catmull-Clark-Subdivision" class="headerlink" title="Catmull-Clark Subdivision"></a>Catmull-Clark Subdivision</h4><p>Loop细分法非常好用，但其缺点也很明显，它只适用于三角面，一旦模型中包含其它种类的面就无能为力。</p><p>Catmull-Clark细分法能够处理各种形状的面，能够应对更加多的情况。</p><p>在具体介绍该算法前，我们需要先介绍几个概念，首先请看一张示例图：</p><p><img src="47.png" width="30%"></p><p>图中画出了几个模型面，我们首先定义“非四边形面”，顾名思义，只要不是四边形面，就属于该类，如图中三角符号标识的两个面。</p><p>另外就是“奇异点”，指度数不为4的顶点，例如图中紫色所标示的两个顶点。（我们仍不考虑边界情况）</p><p>Catmull-Clark细分法增加顶点的方式是取中点，参见下图，这是上面这个例子细分后的样子。</p><p><img src="48.png" width="30%"></p><p>具体而言，对于每个面，取面的中点和各条边的中点，再将面中点与各边中点相连（注意边中点之间不相连）。</p><p>例如原本的正方形面，都被重新划分为了四个面，三角面都划分为了三个新四边形面。</p><p>（这里已经经过了位置的调整，因此会出现弯曲，我们暂且不考虑新位置是如何计算出来的，只关注相对位置）</p><p>注意到进行一次细分后，奇异点数目增加至4，其中2个为新增奇异点，是原非四边形面的中点。</p><p>稍稍思考我们就能得到一个显而易见的结论：<strong>非四边形面划分后的中点一定是奇异点。</strong>因为其度数等于原面边数。</p><p>在不考虑边界情况的前提下，这个结论还能扩展为<strong>仅有这些点是新增的奇异点</strong>。</p><p>其实我们还能得到另一个结论：<strong>非四边形面划分后的新面一定全是四边形面。</strong>这意味着如果我们再做一次细分，奇异点数不会再增加，如下图所示：</p><p><img src="49.png" width="30%"></p><p>接下来我们介绍点的位置更新方式，Catmull-Clark细分法更新位置时，更新以下三类点的位置。</p><p>第一类是面点，即四边形面的中心点，示意图如下：</p><p><img src="50.png" width="20%"></p><p>对应的位置更新公式为：</p><script type="math/tex; mode=display">f=\frac{v_1+v_2+v_3+v_4}{4}</script><p>第二类是边点，即四边形面的边中点，示意图如下：</p><p><img src="51.png" width="20%"></p><p>对应的位置更新公式为：</p><script type="math/tex; mode=display">e=\frac{v_1+v_2+f_1+f_2}{4}</script><p>第三类是旧顶点，示意图如下：</p><p><img src="52.png" width="20%"></p><p>对应的位置更新公式为：</p><script type="math/tex; mode=display">v=\frac{f_1+f_2+f_3+f_4+2(m_1+m_2+m_3+m_4)+4p}{16}</script><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Loop细分法只适用于三角面，而Catmull-Clark细分法可以用于更多类型的面，还是要根据实际情况进行选择。</p><p>这里贴上两种方法的效果图：</p><p><img src="53.png" width="50%"></p><h3 id="Mesh-Simplification"><a href="#Mesh-Simplification" class="headerlink" title="Mesh Simplification"></a>Mesh Simplification</h3><p>假如我们的模型过于细致，为了减轻运算负担等目的，我么可以使用网格简化技术，减少模型面数，如下所示：</p><p><img src="54.png" width="40%"></p><p>这里给个更具体的例子，下图展示了一个骷髅模型在拥有不同数量三角面时的情况：</p><p><img src="55.png" width="40%"></p><p>如果单从显示效果来说，那无疑是越多三角面越好，但在现实中，有时为了提高渲染效率，我们会舍弃掉一部分模型精度。</p><p>考虑这个骷髅在使用时，实际大小不大的情况，就像图中的第二行所示，30,000和3,000个面的模型其实看不出什么区别，甚至300个面也并非不可接受，这就是网格简化技术的一个适用场景。</p><p>有关网格简化，我们只介绍一种方法——边坍缩（Edge Collapsing）。</p><p>边坍缩法的想法就是找到一条边，然后把它的两端聚合为一个点，就像下图展示的那样：</p><p><img src="56.png" width="40%"></p><p>因此该方法的重点问题就是，该选择哪些边来进行坍缩。为此我们所采用的方法是二次误差度量（Quadric Error Metrics）。</p><p><img src="57.png" width="40%"></p><p>考虑上图所示的情况，我们想要把这5个点降为3个点，两侧的点与原先重合，在选取中间那个点的位置时，我们就可以使用二次误差度量。</p><p>具体而言，我们计算这个点到原先四条边所在的直线的距离，也就是图右中蓝点到4条虚线的距离，然后求这些距离的平方和，这个平方和就是二次误差度量，我们最后确定的点应该尽可能地使这个值小。</p><p>二次误差度量和机器学习中的L2距离概念比较相似，如果有过相关经验的读者应该能马上理解。</p><p>回到我们的网格模型上，针对于每一条边，我们都可以通过二次误差度量，去计算它坍缩后的最优位置在哪，借此来选取要坍缩的边。</p><p>具体算法流程是这样的：</p><ol><li>对每条边，计算二次误差度量，获得其小二次误差度量$m_i$。</li><li>迭代地从集合${m_i}$中取最小值对应的边，将其坍缩。</li><li>重复步骤2，直到模型符合要求。</li></ol><p>这个算法中有两个细节需要注意。</p><p>首先是在步骤2中，当我们坍缩一条边时，其实会引起其它边的变动（可以参考前文中的坍缩例子），也就是说集合${m_i}$其实会在算法过程中变化，为了能够实时地更新该集合，同时满足取最小值的需求，我们可以用堆来维护该信息。</p><p>其次，我们的最终目的是简化整个模型的面数，但该算法其实是用局部最优来近似全局最优，也就是用了贪心策略，二者其实并不等价。不过在大多数情况下，该算法能取得很好的效果，所以我们就认为这么做是对的。</p><p>（图形学中流传着这么一句话，看起来是对的就是对的）</p><p>这里再看一下实际的效果图：</p><p><img src="58.png" width="40%"></p><p>可以看到对于第一行中的牛，即使面数降到很低，该算法依然能维持模型的基本形状。</p><p>而第二行的小奶牛模型则验证了该算法更细节的一些特点：在面部形状本来就比较平坦的情况下，坍缩的边数也相对较多；在凹凸变化明显的连接处，坍缩的边就较少。</p><h3 id="Mesh-Regularization"><a href="#Mesh-Regularization" class="headerlink" title="Mesh Regularization"></a>Mesh Regularization</h3><p>网格正则指的是将原模型中的“奇怪”面变得更加规范化，例如下图中，将各种三角形面组成的模型转化为近似于正三角面组成的形状：</p><p><img src="59.png" width="40%"></p><p>网格正则的内容课程中并没有详细涉及，这里也就不展开了。</p><p>那几何部分到这里也就告一段落，下次见！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（三）——Shading</title>
      <link href="/2023/11/13/games101-ke-cheng-bi-ji-san-shading/"/>
      <url>/2023/11/13/games101-ke-cheng-bi-ji-san-shading/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（三）——Shading"><a href="#GAMES101课程笔记（三）——Shading" class="headerlink" title="GAMES101课程笔记（三）——Shading"></a>GAMES101课程笔记（三）——Shading</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>最近事情好多啊，笔记好久没有更新过了。</p><p>在上次的笔记中，我们学会了光栅化的过程，也就是如何使用像素绘制出我们想要的图像。</p><p>但光有这些是不够的，为了呈现更加真实的效果，我们还需要进行着色，在图形学中，着色本质是指将材质应用到物体上。</p><p>本文会涉及到光在图形学中的建模，各种着色法以及和纹理相关的各种内容，也是笔者认为非常有趣的一节。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><p><a href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/">GAMES101课程笔记（二）——Rasterization</a></p><h2 id="基础光照概念"><a href="#基础光照概念" class="headerlink" title="基础光照概念"></a>基础光照概念</h2><p>在这里我们先介绍一下该部分的一些基础概念。</p><p><img src="1.png" width="60%"></p><p>上图展示了一个简单的光照场景，我们可以看到几个叠放在一起的杯子，而杯子上呈现出了几种不同的光照表现。</p><p>首先是光线通过光滑表面直接反射进入人眼的部分，会呈现出镜面高光（Specular highlights）的效果；与之相对应的是漫反射（Diffuse reflection），这部分由于是通过无规则反射进入到人眼的光线，远不及直接反射的光照强度，所以会呈现出较弱的光亮效果；另外还有一种光，单从光源角度来说，图中所指的这部分没被照射到，理应呈现出黑色，但事实上，光线会通过在其他表面（例如墙壁）的反射 ，照射到这一部分，这种光就称之为环境光照（Ambient lighting）。</p><p>那只要我们能够表达出这三种光照表现，就可以做出一种材质。不过在具体阐释之前，我们需要进行一些定义。</p><p>首先对于一个简单的光线反射模型：</p><p><img src="2.png" alt=""></p><p>光线照射到表面的点我们称之<strong>着色点</strong>（Shading point），我们需要以下参数，来进行着色：</p><ul><li>观测方向：$\vec{v}$</li><li>表面法向量：$\vec{n}$</li><li>光照方向：$\vec{l}$</li><li>表面参数</li></ul><p>（这里的向量都取单位向量） </p><p>在现在这个阶段，我们只考虑着色而不考虑阴影，具体来说，就是不考虑光线被其他物体遮挡的情况。</p><h2 id="Blinn-Phong光照模型"><a href="#Blinn-Phong光照模型" class="headerlink" title="Blinn-Phong光照模型"></a>Blinn-Phong光照模型</h2><h3 id="光的能量"><a href="#光的能量" class="headerlink" title="光的能量"></a>光的能量</h3><p>我们现在需要思考一个问题，着色点上到底接收到了多少光？</p><p>当我们探讨“多少光”时，其实是在讨论光的能量，因此我们先来说说如何研究这个问题。</p><h4 id="能量与入射方向"><a href="#能量与入射方向" class="headerlink" title="能量与入射方向"></a>能量与入射方向</h4><p>首先一个区域能接收到的能量与入射方向是有关系的，下图用一种比较直观的方式分析了这一点，：</p><p><img src="3.png" width="60%"></p><p>我们假设在一个小平面上接收到了六条光线，此时如果我们将该平面转过60°，就将只能接收到三条光线。</p><p>从数学的角度上说，是因为旋转过60°后，该平面在水平方向上的投影变为原来的一半，因此我们可以将结论推广：</p><ul><li>着色点接收到的能量与入射角$\theta$的余弦值成正比。</li></ul><p>即：$I\propto \cos\theta=\vec{n}·\vec{l}$</p><h4 id="能量与距离——光照衰减"><a href="#能量与距离——光照衰减" class="headerlink" title="能量与距离——光照衰减"></a>能量与距离——光照衰减</h4><p>假设有一个点光源，向所有方向放射光线，那我们可以把它放出的能量假想为一层球壳，这个球壳会随着时间的推移逐渐变大，对应能量向外传播过程，如下图所示。</p><p><img src="4.png" width="40%"></p><p>由能量守恒定律，每一层球壳的能量理应是相同的，由于球表面积的计算公式为$4\pi r^2$，我们可以得出这样一个结论：</p><ul><li>某一点接收到的能量，与它到光源距离的平方成反比</li></ul><p>即：$I\propto \frac{1}{r^2}$</p><h3 id="漫反射项"><a href="#漫反射项" class="headerlink" title="漫反射项"></a>漫反射项</h3><p>当一条光线照射到物体表面时，光线会被均匀反射到各个方向上去，这种现象就是漫反射。</p><p><img src="5.png" width="40%"></p><p>基于前面有关光的能量的讨论，我们可以写出漫反射的表达式：</p><script type="math/tex; mode=display">L_d=k_d·\frac{I}{r^2}·\max{(0,\vec{n}·\vec{l})}</script><p>在课程ppt中给出了其中参数的详细解释：</p><p><img src="6.png" width="70%"></p><ul><li><p>$L_d$：表示漫反射向周围反射的光线</p></li><li><p>$k_d$：漫反射系数，表示着色点对能量的吸收能力，如果使用三维向量，就能表示颜色</p></li><li>$\frac{I}{r^2}$：参考前文光照衰减</li><li>$\max{(0,\vec{n}·\vec{l})}$：参考前文能量与入射方向的关系，这里$\max$的作用在于排除余弦值为负的情况（这种情况没有任何意义）</li></ul><p>在这个公式中并没有出现$\vec{v}$，因为漫反射的反射光均匀散布，与观测方向无关。</p><p>我们在一个球体上运用上述公式，可以得到这样的结果：</p><p><img src="7.png" width="70%"></p><p>这里的$k_d$取为标量，因此着色完的图像仅有明暗上的差异。</p><h3 id="高光项"><a href="#高光项" class="headerlink" title="高光项"></a>高光项</h3><p>当光照射到一个比较光滑的平面时，大部分的光线会向镜面方向反射，此时如果我们从该方向进行观察，就能看到高光的出现，如下图所示：</p><p><img src="8.png" alt=""></p><p>在Blinn-Phong模型中，它做了一个巧妙的的转化，它引入了<strong>半程向量</strong>来计算高光项。</p><p>半程向量指的是$\vec{l}$和$\vec{v}$角平分线向量，其计算式为：</p><script type="math/tex; mode=display">\vec{h}=\frac{\vec{v}+\vec{l}}{||\vec{v}+\vec{l}||}</script><p>那么原始问题中的“从镜面方向进行观察”，就转换为了“半程向量$\vec{h}$与法向量$\vec{n}$接近”。</p><p>运用半程向量的目的是为了简化计算，否则就要使用镜面向量，计算会比较繁琐。</p><p>我们就可以给出高光项的表达式为：</p><script type="math/tex; mode=display">L_s=k_s·\frac{I}{r^2}·\max{(0,\vec{n}·\vec{h})}^p</script><p>下图是课程ppt中的详细解释：</p><p><img src="9.png" width="70%"></p><ul><li>$L_s$：沿观测方向的高光光线</li><li>$k_s$​：镜面反射系数，表示着色点对能量的吸收能力</li><li>$\frac{I}{r^2}$：参考前文光照衰减</li><li>$\max{(0,\vec{n}·\vec{h})}^p$：<strong>这里不是光照衰减项！！！</strong>，这里是观测方向与镜面方向的重合程度</li></ul><p>Blinn-Phong模型中的高光项并没有光照衰减项，它只关心有没有高光。</p><p>（Phong模型用的就是镜面向量）</p><p>指数$p$的引入是为了<strong>降低对高光的容忍度</strong>。</p><p>参考下图，我们会发现用余弦函数衡量重合程度存在问题，例如我们的半程向量与法向量偏差达到45°时，其余弦值仍旧较大，但实际上此时高光应该已经几乎不存在了。</p><p><img src="10.png" width="70%"></p><p>为此我们引入指数$p$，加快其衰减，让高光只集中在偏差角度很小的那一部分。</p><p>我们同样在球体上应用上述公式，得到如下的结果：</p><p><img src="11.png" width="70%"></p><p>可以看到随$p$的增大，高光区域逐渐减小。</p><h3 id="环境光项"><a href="#环境光项" class="headerlink" title="环境光项"></a>环境光项</h3><p>之前提到过，一些不会被光源直射的部分，仍会因周围物体的反射而被照亮，这种光照我们称之为环境光。</p><p>在这里，我们认为环境光是一个常量，附加在场景中所有的物体之上，也就说<strong>这里的环境光是一种假想光</strong>。</p><p>也因此，环境光项的公式非常简单：</p><script type="math/tex; mode=display">La_=k_aI_a</script><p>下图是课程ppt中的解释：</p><p><img src="12.png" width="60%"></p><ul><li>$L_a$：物体反射的环境光</li><li>$k_a$：环境光系数，表示着色点对环境光的吸收能力</li><li>$I_a$：环境光常数，表示附加的环境光</li></ul><h3 id="完整模型"><a href="#完整模型" class="headerlink" title="完整模型"></a>完整模型</h3><p>当我们将上述三项累加起来，就获得了一个完整的Blinn-Phong模型，下图给出了一个示例：</p><p><img src="13.png" width="80%"></p><h2 id="着色频率"><a href="#着色频率" class="headerlink" title="着色频率"></a>着色频率</h2><p>观察下面这三个模型，它们有什么区别呢？</p><p><img src="14.png" width="70%"></p><p>从左至右，我们发现它似乎看上去更“光滑了”，但其实它们是三个完全相同的模型，着色频率的不同导致了渲染结果的不同。</p><p>之前我们的Blinn-Phong模型公式应用于着色点上，那么自然而然就会引出这样一个问题：我们要对多少点应用该公式？而这就是着色频率的问题。</p><p>上图左的圆球在每个小平面上对整个面应用了着色，也就是说同一个面上的颜色都是相同的；图中的球对于更多的顶点着色，然后使用插值计算剩余的部分，因此看上去更加细腻 ；图右对每个像素都进行着色，自然最为真实。</p><p>显然，着色点越多，效果越逼真，但效率会更低。</p><p>以下介绍两种常用的着色方式。</p><h3 id="Flat-shading"><a href="#Flat-shading" class="headerlink" title="Flat shading"></a>Flat shading</h3><p>Flat shading，即平面着色，只对每个三角面进行一次着色（依据其法向量），因此在同一个三角面上的颜色都是一致的，如下图所示：</p><p><img src="15.png" alt=""></p><p>这种方法比较节省运算资源，但不是很适合应用在光滑表面上。</p><h3 id="Gouraud-shading"><a href="#Gouraud-shading" class="headerlink" title="Gouraud shading"></a>Gouraud shading</h3><p>Gouraud shading是依据顶点来进行着色的方法，它对于每个三角面的顶点进行着色，区域部分使用插值的方法来进行计算，如下图所示：</p><p><img src="16.png" alt=""></p><p>这种方法要求每个顶点都要有一个法向量（后续会提及）。</p><h3 id="Phong-shading"><a href="#Phong-shading" class="headerlink" title="Phong shading"></a>Phong shading</h3><p>Phong shading是另一种着色法，在获得所有顶点的法向量后，它先为平面上所有的点插值计算法向量，再为每个像素进行着色，如下图所示：</p><p><img src="17.png" alt=""></p><p>需要注意的是，虽然它的名字中含有Phong，但这不代表它使用的一定是Blinn-Phong模型。</p><h3 id="着色频率的选择"><a href="#着色频率的选择" class="headerlink" title="着色频率的选择"></a>着色频率的选择</h3><p>着色频率的选择需要考虑多方面的因素，下图展示了一个选择场景：</p><p><img src="18.png" width="60%"></p><p>上图中同一行所用的模型都是相同的，不过越是靠下的模型面数会越多。</p><p>我们可以看到，在模型面数比较少的时候，我们可以选择逐像素的着色频率，这能让图像呈现不错的效果。</p><p>而在模型面数增多后，平面着色法与逐像素的表现非常接近，那此时我们自然会去考虑开销更小的平面着色法。</p><h3 id="顶点法线"><a href="#顶点法线" class="headerlink" title="顶点法线"></a>顶点法线</h3><p>之前我们已经提到过了好几次顶点法线（顶点法向量），这里我们谈谈它是如何获得的。</p><p>假设我们的顶点都在一个球体上，如下图所示，那法向量就由球心指向该顶点。</p><p><img src="19.png" width="40%"></p><p>但在现实中，大多数的顶点都满足不了这种理想情况，为此，我们使用取均值的方法来计算。</p><p><img src="20.png" width="40%"></p><p>如上图，我们假设顶点$v$与四个平面相接，那我们就能用这四个平面的法向量求均值来计算其法向量，具体的公式为：</p><script type="math/tex; mode=display">N_v=\frac{\sum_i{N_i}}{||\sum_i{N_i}||}</script><p>当然，还有一种方法是利用三角形的面积进行加权平均的计算，增大大面积三角元的影响。</p><h3 id="逐像素法线"><a href="#逐像素法线" class="headerlink" title="逐像素法线"></a>逐像素法线</h3><p>接下来我们对逐像素法线进行定义。</p><p>我们的问题是：如果我们已知顶点的法向量，我们该如何为顶点之间的每个像素确定法向量？</p><p><img src="21.png" width="40%"></p><p>事实上，我们使用Barrycentric （重心坐标插值法）来进行计算，后续我们会详细介绍。</p><p>请牢记，这里计算的所有法向量，最后都应化为单位向量。</p><h2 id="实时渲染管线"><a href="#实时渲染管线" class="headerlink" title="实时渲染管线"></a>实时渲染管线</h2><p>至此，我们其实已经有了一套完整的绘制图像的管线，如下图所示：<br><img src="22.png" width="60%"></p><p>注意的是在整个过程中，我们是先定义顶点，再定义哪三个顶点构成一个三角面，通过这种方式来定义整个图形。</p><p>在管线的最初，我们先使用MVP变换将顶点变换到屏幕坐标：</p><p><img src="23.png" width="60%"></p><p>在Triangle Processing这一步，我们定义完了三角面，然后为其进行采样（也就是光栅化）操作：</p><p><img src="24.png" width="60%"></p><p>接着，我们使用深度测试判断哪些像素是可见的：</p><p><img src="25.png" width="60%"></p><p>至于我们刚刚提到的着色步骤，它会在顶点和片元处理两个部分都发生：</p><p><img src="26.png" width="60%"></p><p>考虑我们刚刚提到的几种着色频率，如果我们使用Gouraud shading，它自然在顶点处理处发生；如果使用Phong shading，那便会在片元处理处发生。</p><p>另外这里我们先提及一个概念——纹理映射，下图中的三角行使用了木板纹理，在管线中就需要计算片元与纹理的对应关系，这会在后续详细提及。</p><p><img src="27.png" width="60%"></p><h3 id="Shader"><a href="#Shader" class="headerlink" title="Shader"></a>Shader</h3><p>为了告诉计算机如何进行着色，我们可以编写Shader（着色器），Shader分为Vertex Shader（顶点着色器）和Fragment Shader（片元着色器），分别应用于顶点与片元。</p><p>需要注意的是，<strong>着色器会对所有对象使用其计算过程</strong>。</p><p>以顶点着色器为例，在编写顶点着色器的过程中，我们好像是在为某一个特定的顶点进行编程，但其实当我们应用该顶点着色器时，它会对所有的顶点生效。</p><p>这里提一嘴，片元着色器也叫作像素着色器，它对每个像素进行计算，得出其应显示的颜色。</p><p>GLSL是OpenGL用于编写着色器的语言，以下给出一段GLSL的片元着色器样例代码：</p><pre class="line-numbers language-glsl" data-language="glsl"><code class="language-glsl"><span class="token keyword">uniform</span> <span class="token keyword">sampler2D</span> myTexture<span class="token punctuation">;</span> <span class="token comment">// 纹理</span><span class="token keyword">uniform</span> <span class="token keyword">vec3</span> lightDir<span class="token punctuation">;</span>       <span class="token comment">// 光照方向</span><span class="token keyword">varying</span> <span class="token keyword">vec2</span> uv<span class="token punctuation">;</span> <span class="token comment">// 纹理坐标</span><span class="token keyword">varying</span> <span class="token keyword">vec3</span> norm<span class="token punctuation">;</span>           <span class="token comment">// 像素法线</span><span class="token keyword">void</span> <span class="token function">diffuseShader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token keyword">vec3</span> kd<span class="token punctuation">;</span>kd <span class="token operator">=</span> <span class="token function">texture2d</span><span class="token punctuation">(</span>myTexture<span class="token punctuation">,</span>uv<span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token comment">// 纹理颜色</span>kd <span class="token operator">*=</span> <span class="token function">clamp</span><span class="token punctuation">(</span><span class="token function">dot</span><span class="token punctuation">(</span><span class="token operator">-</span>lightDir<span class="token punctuation">,</span>norm<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">// 光照模型</span>    gl_FragColor <span class="token operator">=</span> <span class="token keyword">vec4</span><span class="token punctuation">(</span>kd<span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                  <span class="token comment">// 输出颜色</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>uniform关键字指的是全局变量，这里是一个纹理和光照方向。</p><p>varying关键字是指该变量用作顶点着色器和片元着色器的传递数据，对于片元着色器来说，就是从顶点着色器传来的变量，这里包括纹理坐标和像素法线，这两个数据需要顶点着色器来计算。</p><p>（这里不用在意纹理坐标是什么）</p><p>然后通过diffuseShader方法中计算过程，就能获得所有像素的颜色。</p><h2 id="Texture-Mapping——纹理映射"><a href="#Texture-Mapping——纹理映射" class="headerlink" title="Texture Mapping——纹理映射"></a>Texture Mapping——纹理映射</h2><p>之前我们提到过纹理映射的概念，这里我们来具体介绍它。</p><p>考虑下面这张图中的场景：</p><p><img src="28.png" width="60%"></p><p>我们可以使用Blinn-Phong模型为场景中的小球计算光照，不过在小球上还有独特的图案，让小球的各个部分呈现出不同的颜色。</p><p>换言之，虽然整个小球共用同一个光照模型，但其不同部分的漫反射系数并不相同，这就引申出了纹理映射要解决的问题：如何定义物体不同位置上的属性？</p><h3 id="纹理"><a href="#纹理" class="headerlink" title="纹理"></a>纹理</h3><p>用通俗的话来说，纹理就是物体上的花纹。</p><p>我们可以用地球仪来举一个例子：</p><p><img src="29.png" width="70%"></p><p>我们将三维的地球仪表面展开，就能获得一张二维的世界地图，这张世界地图就是纹理。</p><h3 id="纹理坐标"><a href="#纹理坐标" class="headerlink" title="纹理坐标"></a>纹理坐标</h3><p>同样考虑地球仪的场景，我们可以反过来思考这一过程。</p><p>如果我们又一张二维的世界地图，并将其包裹在一个球体上，就能获得一个地球仪，而这其实就是纹理映射的过程。</p><p>从更严谨的角度来分析，这一过程实际上是将球体表面的位置，与二维纹理的坐标，建立起对应关系，从而能够进行相应计算。</p><p><img src="30.png" width="70%"></p><p>上图是一个纹理映射的典型场景，左上角我们是单纯使用光照模型渲染的结果，当我们想要为该模型附上纹理时，我们去考虑每个顶点对应的纹理坐标，再从纹理上获取该位置的属性，从而计算出每个像素的最终颜色。</p><p>在本课程中，我们默认对应关系是已知的，也就是对于每一个顶点，我们都知道其纹理坐标。</p><p>一般来说，我们都用$uv$来代表纹理坐标系，如下图所示：</p><p><img src="31.png" width="70%"></p><p>为了方便处理，$u$和$v$的取值都在[0,1]区间中，这也是一个约定俗成的规则。</p><p>另外，并不是说对于一个物体，我们只能使用一次纹理，比如对于下面的场景，我们可以将一个纹理重复拼接多次。</p><p><img src="32.png" width="70%"></p><p>现在用的纹理很容易看出拼接的边缘，不过我们可以设计一种上下与左右拼接起来后，能够“严丝合缝”的材质，例如下面这样：</p><p><img src="33.png" width="40%"></p><p>这种纹理被称之为tile，只需一小块纹理的循环拼接，就能覆盖较大的物体。</p><p>在具体应用纹理时，我们可以将纹理上对应点的值赋给漫反射系数，从而达成目的。</p><h2 id="重心坐标插值"><a href="#重心坐标插值" class="headerlink" title="重心坐标插值"></a>重心坐标插值</h2><p>插值运算的目的是为了获得平滑的过渡值。</p><p>在我们的问题中，只需要得到每个顶点的属性，就可以通过插值来计算三角面上的属性值。这些属性可以包括纹理坐标、颜色、法向量等等，故而插值有非常广泛的运用。</p><p>这里我们介绍一种插值法：重心坐标插值。</p><p>首先我们需要介绍三角形的重心定理，假设已知一个三角形的三个顶点——$A$、$B$和$C$的坐标，那么对于三角形<strong>平面</strong>上的任意一点$(x,y)$，我们可以将其表示为：</p><script type="math/tex; mode=display">(x,y)=\alpha A+\beta B+\gamma C</script><p> 其中$\alpha$、$\beta$和$\gamma$满足：</p><script type="math/tex; mode=display">\alpha+\beta+\gamma=1</script><p>下图说明的就是该定理：</p><p><img src="34.png" width="60%"></p><p>如果我们限定点在三角形内，那么$\alpha$、$\beta$和$\gamma$还会是非负的。</p><p>$(\alpha,\beta,\gamma)$就被称为该点的<strong>重心坐标</strong>。</p><p><img src="35.png" width="60%"></p><p>例如点$A$，其重心坐标就是$(1,0,0)$，上图中列出了具体的计算过程。</p><p>对于任意点，我们可以用面积来求得其重心坐标，公式参见下图：</p><p><img src="36.png" width="60%"></p><p>我们将顶点与该点连线，将整个三角形分割为三个小三角形，其中与点$A$不相邻的三角形面积定义为$A_A$，并同样定义$A_B$与$A_C$，接着就可以使用该公式。</p><p>不过使用面积还是不太方便的，我们使用坐标形式的公式来计算：</p><p><img src="37.png" width="60%"></p><p>对于三角形内任一点$(x,y)$，其重心坐标为：</p><script type="math/tex; mode=display">\alpha=\frac{-(x-x_B)(y_C-y_B)+(y-y_B)(x_C-x_B)}{-(x_A-x_B)(y_C-y_B)+(y_A-y_B)(x_C-x_B)} \\\beta=\frac{-(x-x_C)(y_A-y_C)+(y-y_C)(x_A-x_C)}{-(x_B-x_C)(y_A-y_C)+(y_B-y_C)(x_A-x_C)} \\\gamma = 1-\alpha - \beta</script><p>这个公式的推导有多种方式，上面所说的面积就是一种思路，这里碍于篇幅不再展开。</p><p><img src="38.png" width="60%"></p><p> 现在我们将坐标值替换为我们要的属性值，就可以对任何属性进行插值，就像上图中所做的这样。</p><p>要注意的是，重心坐标插值在投影变换下<strong>无法保证重心不变</strong>，所以当我们插值高维空间的属性时，我们要先在三维空间中完成插值，再投影到二维平面。</p><h2 id="纹理问题"><a href="#纹理问题" class="headerlink" title="纹理问题"></a>纹理问题</h2><p>如果我们只是单纯地用纹理坐标对应来进行纹理映射，那会出现一些问题。</p><h3 id="Texture-Magnification——纹理放大"><a href="#Texture-Magnification——纹理放大" class="headerlink" title="Texture Magnification——纹理放大"></a>Texture Magnification——纹理放大</h3><h4 id="问题解释"><a href="#问题解释" class="headerlink" title="问题解释"></a>问题解释</h4><p>纹理也是由一个个小像素组成的，为了与屏幕像素区分，我们将其成为<strong>纹素</strong>。</p><p>当纹理过小时，会出现纹素过少的问题，这样会导致有些坐标没有对应的纹素</p><p><img src="39.png" width="60%"></p><p>应对这种问题，最简单的做法是，每个像素使用其最靠近的纹素来进行绘制，这就是上图左的效果，但这么做会导致图像中有很多粗粒度的方块，也就是所谓的看上去“很模糊”。</p><p>为了使图像看上去更正常一点，也就是达到右边两张图的效果，我们有一些其他的做法，例如这里要介绍的。</p><h4 id="Bilinear——双线性插值"><a href="#Bilinear——双线性插值" class="headerlink" title="Bilinear——双线性插值"></a>Bilinear——双线性插值</h4><p><img src="40.png" width="60%"></p><p>假设有一个像素点的纹理坐标落在了图中红点处，我们该如何处理它呢？</p><p>上文中提到一种最简单的做法就是取其最近的纹素，也就是其右上角的那个点作为纹理。但为了避免模糊的出现，我们可以使用另一种做法——双线性插值。</p><p><img src="41.png" width="35%"></p><p>对于一个像素点，我们可以取它临近的四个点，构成一个正方形，再计算出该像素点到左和下两条边的距离$s$与$t$。</p><p>由于我们认为两个纹素中心的距离为1，所以$s$和$t$都应是在$[0,1]$中的值。</p><p>在这里我们要使用线性插值公式：</p><script type="math/tex; mode=display">lerp(x,v_0,v_1)=v_0+x(v_1-v_0)</script><p>我们先在水平方向进行一次插值，如下所示：</p><p><img src="42.png" width="35%"></p><p>其中：</p><script type="math/tex; mode=display">u_0=lerp(s,u_{00},u_{10}) \\u_1=lerp(s,u_{01},u_{11})</script><p>再在竖直方向进行一次插值：</p><script type="math/tex; mode=display">f(x,y)=lerp(t,u_0,u_1)</script><p>$f(x,y)$就是我们最终要使用的颜色。</p><p>正因为使用了两次插值，该方法被称为双线性插值。</p><h3 id="Texture-Minification——纹理缩小"><a href="#Texture-Minification——纹理缩小" class="headerlink" title="Texture Minification——纹理缩小"></a>Texture Minification——纹理缩小</h3><h4 id="问题解释-1"><a href="#问题解释-1" class="headerlink" title="问题解释"></a>问题解释</h4><p>当纹理过大时，也会出现很多问题。</p><p>当我们将一个很大的纹理应用到模型上时，可能会出现下图中展示的问题：远处的直线变成了混乱的纹路，近处的直线出现了严重的锯齿。</p><p><img src="43.png" width="60%"></p><p>在光栅化的笔记，有关走样的部分中，我们曾探讨过这两种问题。那在材质映射这里，这两个问题是如何产生的呢？</p><p>原因在于，对于远近不同的物体，一个像素所代表的实际大小不同。对于距离较近的部分，一个像素覆盖的区域可能远小于一个纹素的区域，反之，对于远处的部分，一个像素就可能覆盖很多个纹素，下图就说明了这一过程。</p><p><img src="44.png" width="60%"></p><p>在之前的笔记中提到过，使用超采样技术可以解决这些问题，下图就是使用了超采样的结果：</p><p><img src="45.png" width="60%"></p><p>虽然行之有效，但在这里使用超采样技术的开销太大了，因此我们需要找到其他方法。</p><h4 id="Mipmap"><a href="#Mipmap" class="headerlink" title="Mipmap"></a>Mipmap</h4><p>我们知道，出现走样的根本原因在于采样率太低，超采样技术是从采样率的角度入手来思考，但现在我们使用一个新的思路——范围查询。</p><p>具体而言，就是要找到一个方法，能够立刻得知一片区域内纹素的平均值，这就是<strong>范围查询</strong>的概念。</p><p>（事实上区域查询所指的范围更为广泛，也可以是查询区域内最大值等问题。与之相对的还有<strong>点查询</strong>问题，就是获得某个点的具体值，我们之前介绍的双线性插值等方法都属于这一范畴）</p><p>为此，我们使用<strong>Mipmap</strong>技术，它可以进行快速、近似、方形的范围查询。</p><p>Mipmap为一张纹理生成不同大小的各种版本，如下图所示：</p><p><img src="46.png" width="40%"></p><p>在Mipmap中，我们用Level来表示各种尺寸的纹理，Level 0通常表示原始纹理，Level每高一级，纹理的尺寸就会缩小一倍（面积缩小为1/4）。</p><p>如果把各个Level的纹理叠加起来，就会像下图一样呈现出类似金字塔的形状：</p><p><img src="47.png" width="40%"></p><p>由无穷等比数列的求和公式，我们知道：</p><script type="math/tex; mode=display">1+\frac{1}{4}+(\frac{1}{4})^2+(\frac{1}{4})^3+...=\frac{1}{1-\frac{1}{4}}=\frac{4}{3}</script><p>所以当我们对一张纹理使用Mipmap时，生成的额外存储空间不会超过原纹理的1/3，不会造成太大的存储负担。</p><p>现在我们来介绍Mipmap的工作原理，即如何计算要使用哪个Level的纹理。</p><p>假设在屏幕坐标系下有一个像素（图左，左下角红点所在的像素），现在要求它对应的Mipmap层级。</p><p><strong>这里为了更好的理解，部分变量的含义与视频中不同。</strong></p><p>我们可以取该像素中心点，以及周围的几个像素中心点，把它们一起映射到纹理空间中，如下图右所示：</p><p><img src="48.png" width="50%"></p><p>我们知道在屏幕空间中，相邻像素中心点的距离为与每个像素的边长是一样的，因此在纹理空间中，我们也使用两个点之间的距离$L$来<strong>近似</strong>像素边长。</p><p>下图中表示红色像素在纹理空间下实际覆盖的区域，下图右表示我们用距离来近似的区域，可以看见它们大体上是一致的。</p><p><img src="49.png" width="70%"></p><p>假设横向两点在屏幕坐标下的横向距离为$dx$（纵向距离为0），在纹理坐标中的的横向距离为$du$，纵向坐标为$dv$，缩放比例为<em>R</em>。</p><p>那我们有：</p><script type="math/tex; mode=display">L=\sqrt{(du)^2+{dv}^2} \\R = \frac{L}{dx}=\sqrt{(\frac{du}{dx})^2+{(\frac{dv}{dx})}^2}</script><p>在示例中我们还取了纵向的点，因此我们可以分别计算横向与纵向的缩放比例，选取其中较大的那个：</p><script type="math/tex; mode=display">R=\max{(\sqrt{(\frac{du}{dx})^2+{(\frac{dv}{dx})}^2},\sqrt{(\frac{du}{dy})^2+{(\frac{dv}{dy})}^2})}</script><p>由于Level每高一级，纹理的边长都缩小1/2，所以该像素对应的层级$D$为：</p><script type="math/tex; mode=display">D=\log_2{R}</script><p>这里的$D$可能为非整数，我们取每个像素最靠近的Mipmap层级做一个可视化：</p><p><img src="50.png" width="40%"></p><p>图中每种颜色代表一个Mipmap层级，其中红色表示较低的Mipmap层级，蓝色表示较高的Mipmap层级，可以看到较近的物体都使用了低层级，远处则使用了高层级。</p><p>但现在不同颜色之间的边缘过于生硬，这是因为我们的层级定义本就是离散的，例如从0级直接跳跃到1级，而没有0.5级的概念。</p><p>不过我们现在已经有解决这类问题的办法了，那就是之前屡屡提到的插值计算。对于计算出层级为非整数的情况，我们可以一并计算其上下两个层级，再进行一次线性插值，如下图所示：</p><p><img src="51.png" width="40%"></p><p>这么做是在双线性插值上又做了一次插值，所以该方法被称为<strong>三线性插值</strong>。</p><p>在使用了插值后，Mipmap的过渡就会变得更加平滑：</p><p><img src="52.png" width="40%"></p><h4 id="Anisotropic-Filtering——各向异性过滤"><a href="#Anisotropic-Filtering——各向异性过滤" class="headerlink" title="Anisotropic Filtering——各向异性过滤"></a>Anisotropic Filtering——各向异性过滤</h4><p>但Mipmap有一定的局限性，那就是只能查询方形区域的值，所以在某些场合下，使用Mipmap的效果也不尽人意。例如之前的场景，会出现过模糊的问题：</p><p><img src="53.png" width="40%"></p><p>这是因为在这张图中，很多像素在纹理坐标下并不再是方形的，而是呈现长条状，如下图所示：</p><p><img src="55.png" width="60%"></p><p>为了解决这一问题，我们可以使用一种更泛用的范围查询——各向异性过滤，相比Mipmap，这种方法会生成更多生成不同尺寸的纹理。</p><p><img src="56.png" width="35%"></p><p>上图就是一个经典的各向异性过滤示例，其对角线上的纹理全是正方形，与Mipmap生成的各层级一致。除此此外，还有各种长宽比例的纹理，使用时根据纹理空间中的形状选用对应的纹理即可。</p><p>（当然其存储空间也相应变大，需要额外三倍于原纹理的空间）</p><p>原教程中还简要提到了EWA过滤，这里就不做详细展开了。</p><h2 id="纹理应用"><a href="#纹理应用" class="headerlink" title="纹理应用"></a>纹理应用</h2><p>除了单纯地给模型赋上花纹，纹理还有很多其他的应用。</p><h3 id="环境贴图——Environment-Mapping"><a href="#环境贴图——Environment-Mapping" class="headerlink" title="环境贴图——Environment Mapping"></a>环境贴图——Environment Mapping</h3><p>下图展示的例子是一个经典模型——犹他茶壶，左图的纹理上记录了周围的环境光照，当把这张纹理渲染到茶壶上后，就营造出了光线照射到茶壶表面，形成反射的效果。</p><p><img src="57.png" width="50%"></p><p>一个简单的记录环境光的方法是使用球体，如下图所示：</p><p><img src="58.png" width="50%"></p><p>具体而言，就是想象有一个镜面球体放在环境中央，这个球体上呈现出来的内容就能够看作是一个环境贴图，这种方法就是Spherical Environment Map。</p><p>这种方法有一个很大的问题，就是它的描述并不均匀。</p><p><img src="59.png" width="50%"></p><p>上图是把一个球状纹理展开成矩形的例子，不难发现它出现了扭曲的现象，尤其是上下两个区域，对应到球体就是其两个极点区域。</p><p>这个问题的解决方法倒是很简单，就是把我们的球体换成一个立方体。</p><p>（说得更专业一点，就是用该球体的包围盒来代替）</p><p><img src="60.png" width="50%"></p><p>像图中示意的一样，原本落在球面上的点回到了立方体的规则平面上，这样扭曲现象就会大大减少。</p><p><img src="61.png" width="50%"></p><h3 id="凹凸贴图——Bump-Mapping"><a href="#凹凸贴图——Bump-Mapping" class="headerlink" title="凹凸贴图——Bump Mapping"></a>凹凸贴图——Bump Mapping</h3><p>环境贴图的本质其实还是在进行上色，但纹理的作用不止于此。</p><p>纹理存储的每个纹素，其本质其实就是单纯的数字，只是我们此前一直将其用以表示颜色，换言之，我们可以用它来表示其他信息。</p><p>一个常用用途就是用它来表示物体表面的相对高度或者法向量，用以表示一些复杂的表面细节。</p><p>（平时我们用的法线贴图就是保存法向量）</p><p><img src="62.png" width="50%"></p><p>上图中我们对一个球体使用左边的相对高度贴图。注意，是一个<strong>球体</strong>，其表面是光滑的曲面，但通过相对高度贴图，我们能让它看上去像是拥有了极粗糙的表面。</p><p>所以我们可以使用凹凸贴图，在不增加模型复杂度的情况下，模拟出一些逼真的细节。</p><p>凹凸贴图的具体做法是这样的，我们先从二维的情况进行理解：</p><p><img src="63.png" width="50%"></p><p>图中的黑线表示我们的实际表面（如前例中球体中的光滑表面），黄线表示我们想要模拟的表面，存储在凹凸贴图中。</p><p>在实际计算前我们要先明确几个点：</p><ul><li>模拟表面的存储是离散的，因为存储在纹素中</li><li>每个点的原始法向量为(0, 1)，因为相对高度的方向是沿着原表面的法向量方向</li></ul><p>（对于第二点，可以假想把上图中的黑线拉成一条直线）</p><p>为求法向量，我们先求切线向量，但由于存储的是离散值，我们没法直接通过求导获得切线向量，因此使用差分法。</p><p><img src="64.png" width="50%"></p><p>如上图所示，我们有：</p><script type="math/tex; mode=display">dp=c*[h(p+1)-h(p)]</script><p>其中$c$是一个常量，于是我们获得了其法向量应为：</p><script type="math/tex; mode=display">n(p)=(-dp,1).normalized()</script><p>而在真实的三维情况下，我们也是用类似的计算方法，只是计算差分时，要在两个方向上计算，即：</p><script type="math/tex; mode=display">\frac{dp}{du}=c_1*[h(u+1)-h(u)] \\\frac{dp}{dv}=c_1*[h(v+1)-h(v)</script><p>于是得到其法向量：</p><script type="math/tex; mode=display">n(p)=(-\frac{dp}{du},-\frac{dp}{dv},1).normalized()</script><p>在计算具体的光照信息时，我们就可以引入每个点的模拟法向量，实现凹凸效果。</p><h3 id="位移贴图——Displacement-Mapping"><a href="#位移贴图——Displacement-Mapping" class="headerlink" title="位移贴图——Displacement Mapping"></a>位移贴图——Displacement Mapping</h3><p>位移贴图使用的贴图数据和凹凸贴图是一样的，区别在于其应用贴图的方式。</p><p>具体而言，就是位移贴图是重新排布了原模型的顶点，让其符合贴图中的高度数据。</p><p>下面这个例子展现出了两者的不同：</p><p><img src="65.png" width="40%"></p><p>可以看到，使用凹凸贴图虽然可以模拟粗糙表面，但在边缘上会出现违和感，因为它并没有真的改变物体本身的形状，我们看到的仍然是一个规则圆形，这显然不符合其粗糙表面的特征。</p><p>此外，当模拟表面本身会引起一些阴影时，也会出现失真感，例如整个球体投下的阴影边缘非常光滑，表面处的阴影不够丰富等。</p><p>使用位移贴图可以解决上述缺点，如右图所示，模型形状变成了正常的样子，表面阴影也更为真实。</p><p>但使用位移贴图要求物体本身的顶点密度足够高，不然就没法对表面进行调节，这会变相增加三角片元的数量，从而增加运算负担。</p><h3 id="其他应用"><a href="#其他应用" class="headerlink" title="其他应用"></a>其他应用</h3><h4 id="三维噪声"><a href="#三维噪声" class="headerlink" title="三维噪声"></a>三维噪声</h4><p>此前我们的纹理存储的都是物体表面的信息，但我们也可以表示空间中任意一点的纹理。</p><p><img src="66.png" width="40%"></p><p>我们可以想象左图中的球是一个实心的球，然后将其雕琢为了右图中的壶，左边这个球其实就可以看作是一个三维纹理。</p><p>不过在实际应用中，不会真的存储这个球体中每一点的信息，而是通过噪声函数方式来进行计算。</p><h4 id="预渲染"><a href="#预渲染" class="headerlink" title="预渲染"></a>预渲染</h4><p>对于一些复杂的细节，实时渲染的效率会比较低，例如下图中人性的各种皱纹。</p><p><img src="67.png" width="40%"></p><p>此时我们可以提前将这些部分渲染好，然后将渲染结果保存在一张贴图中，这样在进行实时渲染时，就可以省略掉复杂的计算步骤。</p><h4 id="三维纹理与体渲染"><a href="#三维纹理与体渲染" class="headerlink" title="三维纹理与体渲染"></a>三维纹理与体渲染</h4><p>三维噪声中我们提到过三维纹理，它存储空间中每一点的纹理信息。</p><p><img src="68.png" width="40%"></p><p>比如医学上，使用核磁共振扫描人体时，我们可以将检测结果（例如密度）存储起来，这个存储结果就可以看作是一个三维纹理，我们也可以通过该纹理，重建出我们要的模型。</p><p>总之到这里，纹理这一概念就不再是单纯的存储颜色了，它可以存储各种能用数表示的信息。</p><p>那么Shading部分，完美结束！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（二）——Rasterization</title>
      <link href="/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/"/>
      <url>/2023/10/01/games101-ke-cheng-bi-ji-er-rasterization/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（二）——Rasterization"><a href="#GAMES101课程笔记（二）——Rasterization" class="headerlink" title="GAMES101课程笔记（二）——Rasterization"></a>GAMES101课程笔记（二）——Rasterization</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>书接上文，经过了MVP矩阵的变换后，我们已经将三维世界的物体变换到了$[-1,1]^3$的标准立方体中，那接下来我们该如何将它绘制到我们的屏幕上呢？本文的主题光栅化（Rasterization）就是解决这一问题的钥匙。</p><p>光栅化的背后是一系列复杂的数学和计算过程，它们将三维世界转化为我们计算机屏幕上的二维图像。这个过程包括了顶点转换、三角形裁剪、光栅化和像素渲染等关键步骤，每一个步骤都需要高效地执行，以实现流畅的图形渲染和动画展示。</p><p>前文指路：</p><p><a href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/">GAMES101课程笔记（一）——Transformation</a></p><h2 id="Pixel——像素"><a href="#Pixel——像素" class="headerlink" title="Pixel——像素"></a>Pixel——像素</h2><p>为了解计算机如何显示图像，我们要先从屏幕开始说起，更具体一点，是从<strong>像素</strong>开始说起。</p><p>在屏幕上，像素是组成图像的最基本单位，每个像素有红绿蓝三个颜色组成，它们像点阵一样分布在屏幕上。</p><p><img src="1.png" width="60%"></p><p>借由三原色的特性，每一个像素都可以展现出任何颜色，从而能够显示出任意图像。</p><p>根据像素的排布特点，我们能联想到使用数组来对当前显示图像进行表达，数组中的每个元素包含有红（R）绿（G）蓝（B）三个颜色。</p><p>我们使用坐标来标记屏幕上的每一个像素，这就是<strong>屏幕空间</strong>，例如下图中的蓝色像素坐标为$(2,1)$。</p><p><img src="2.png" alt=""></p><p>但实际中，<strong>像素并不是真正的一个点</strong>，它是有大小的，而我们在使用刚才像素坐标时，实际上描述的是该像素左下角点的位置。</p><p>该像素的中心坐标实际上是$(2.5,1.5)$，占据的空间是$(2,1)$到$(3,2)$的这部分区域。</p><p>本文的主题光栅化（Rasterization），就是要讲如何用像素来进行图像的绘制。</p><h2 id="Rasterization——光栅化"><a href="#Rasterization——光栅化" class="headerlink" title="Rasterization——光栅化"></a>Rasterization——光栅化</h2><p>了解了屏幕的构成，我们接下来思考，如何将$[-1,1]^3$中的点转换到$[0,width]×[0,height]$的平面坐标上。</p><p><img src="3.png" alt=""></p><p>这里我们先不考虑空间中的$z$坐标，只考虑变换$x$与$y$坐标，那其实就是一个平移加缩放的变换，变换矩阵为：</p><script type="math/tex; mode=display">M_{viewport}=\begin{pmatrix}\frac{width}{2} & 0 & 0 & \frac{width}{2}\\0 & \frac{height}{2} & 0 & \frac{height}{2}\\0 & 0 & 1 & 0\\0 & 0 & 0 & 1\end{pmatrix}</script><p>需要注意的是，我们的变换只是将点转换到平面坐标上，而没有将其转换到具体的像素点上。</p><p>（理由正如刚才提到的，像素并不是真正的点，它是有大小的）</p><p>接下来我们就要探讨，如何进行这一步的转换。</p><h3 id="神奇的三角形"><a href="#神奇的三角形" class="headerlink" title="神奇的三角形"></a>神奇的三角形</h3><p>在图形学中，我们经常使用三角形来组成更复杂的多边形，例如下图中的圆球和海豚。</p><p><img src="4.png" width="60%"></p><p>这是因为三角形有很多优秀的性质，例如：</p><ul><li>本身是最基础的多边形，能构成其它任何多边形</li><li>三角形一定是一个平面图形（三点确定一个平面）</li><li>容易判断点在三角形内外</li><li>在三角形内容易进行插值运算（后续会详细提及）</li></ul><p>所以说，只要我们解决了如何绘制一个三角形的问题，就能解决绘制任何图形的问题。</p><p>举一个具体的例子，现在有一个红色三角形，知道它的三个顶点坐标，我们该如何使用像素将其绘制出来呢？</p><p><img src="5.png" width="60%"></p><h3 id="Sampling——采样"><a href="#Sampling——采样" class="headerlink" title="Sampling——采样"></a>Sampling——采样</h3><p>采样，就是将连续值转化为离散值的过程。在我们的问题中，像素就是离散值，因此可以用采样的方法来解决。</p><p>（想深入了解的话可以简单学习一下信号与系统）</p><p>具体而言，是使用像素的中心坐标来对屏幕上的图形进行采样。最简单的做法就是判断像素中心是否在三角形内，如果在那就显示，否则就不显示，如下图所示：</p><p><img src="6.png" alt=""></p><p>对于平面上的所有点，应满足函数：</p><script type="math/tex; mode=display">inside(t,x,y)=\begin{cases}1 & (x,y)\ in\ triangle\ t\\0 & otherwise\end{cases}</script><p>我们使用离散的像素来对该函数进行采样，制这个三角形的代码就可以写为：</p><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">for (int x=0; x&lt;xmax; ++x)    for (int y=0; x&lt;ymax; ++y)        image[x][y]=inside(t, x+0.5, y+0.5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>思路就是偏离所有的像素，逐个判断是否在三角形内。</p><p>现在问题就落在：该如何判断这个点是否在三角形内部呢？</p><p><img src="7.png" width="40%"></p><p>一个简单的方法是使用叉积来进行判断，假设我们像上图已知三角形$P_0P_1P_2$（顶点已按逆时针排序）和一点$Q$。</p><p>我们可以分别计算$\vec{P_0P_1}×\vec{P_0Q}$，$\vec{P_1P_2}×\vec{P_1Q}$，$\vec{P_2P_0}×\vec{P_2Q}$的结果，假如三者的结果都指向屏幕外，那就可以判断Q点在三角形内，反之则在三角形外。</p><p>在本例中，由于$\vec{P_2P_0}×\vec{P_2Q}$的结果向量指向屏幕内，所以可以得到$Q$在三角形外的结论。</p><p>当然，除了在三角形外和在三角形内，还有可能点刚好在三角形边上，就像下图中的点，我们究竟该说是在三角形1上，还是在三角形2上，或者说干脆不在任何一个上？</p><p><img src="8.png" width="40%"></p><p>答案是都可以，虽然在OpenGL等库中对此很严格的规定，但在我们学习的过程中并不重要，只要我们使用一套自洽的规则来进行判断，或者干脆不特殊处理就行。</p><p>比如我们就可以规定：在边上就在三角形内。那么这个点就既在三角形1内，也在三角形2内。</p><p>总而言之，不必过于纠结这种情况。</p><h3 id="Bounding-Box——包围盒"><a href="#Bounding-Box——包围盒" class="headerlink" title="Bounding Box——包围盒"></a>Bounding Box——包围盒</h3><p>在刚才的代码中，我们遍历了屏幕上所有的像素，但事实上，很多三角形只占据了屏幕中的一小部分，遍历所有像素无疑会造成额外的开销。</p><p>所以我们就可以只判断三角形所占据的那一块区域中的像素，这样就可以提高效率，这种将目标图形包含在内的图形，我们就称之为<strong>包围盒</strong>。</p><p>下图中的蓝色像素就是一个典型的包围盒，我们做采样时只需要对这些像素进行处理就可以了。</p><p><img src="9.png" width="40%"></p><p>需要注意的是包围盒并不一定要是矩形的，只是这里举的例子是这样的，矩形也比较便于处理。</p><p>这种边平行于坐标轴的包围盒非常常用，被简称为AABB（Axis-Aligned Bounding Box，轴对齐）包围盒。</p><p>包围盒的获得非常容易，假设三角形的顶点坐标为$P_0(x_0,y_0)$，$P_1(x_1,y_1)$，$P_2(x_2,y_2)$，那么其包围盒就是以点$(min\begin{Bmatrix}x_0,x_1,x_2\end{Bmatrix},min\begin{Bmatrix}y_0,y_1,y_2\end{Bmatrix})$为左下角，点$(max\begin{Bmatrix}x_0,x_1,x_2\end{Bmatrix},\begin{Bmatrix}y_0,y_1,y_2\end{Bmatrix})$为右上角的矩形。</p><h2 id="Antialiasing——反走样"><a href="#Antialiasing——反走样" class="headerlink" title="Antialiasing——反走样"></a>Antialiasing——反走样</h2><h3 id="Artifacts——瑕疵"><a href="#Artifacts——瑕疵" class="headerlink" title="Artifacts——瑕疵"></a>Artifacts——瑕疵</h3><p>很多时候，屏幕最终呈现出的画面会出现一些错误，例如锯齿、噪点等问题的出现，这些错误在图形学上我们都可以统称为Artifacts。</p><p>（闫老师不是很喜欢说瑕疵，而是直接说英文Artifacts，我个人也觉得直接说英文比较顺口，其实这个单词在图形学里还挺常见的，已经是一个梗的程度了）</p><p>这里我们介绍一些因采样引起的问题（Sampling Artifacts）。</p><h4 id="Jaggies——锯齿"><a href="#Jaggies——锯齿" class="headerlink" title="Jaggies——锯齿"></a>Jaggies——锯齿</h4><p>像素毕竟是离散的，因此在绘制图像时难免会出现差异，其中最普遍的一个问题就是锯齿。</p><p><img src="10.png" width="60%"></p><p>我们期望中的三角形应该像左图一样——拥有三条平滑的边，完美地符合数学上的定义，但在屏幕上可做不到。</p><p>真实的屏幕上的三角形像右图一样，其边缘为不规则的锯齿，如何解决锯齿也是图形学的一个经典课题。</p><p>该问题的根源原因在于<strong>采样频率不够高</strong>，即像素点不够多，理论上当有无限个像素点时就能形成完美的直线。</p><p>（我们平时说的高分辨率其实就是提高了采样频率，也就感觉锯齿减少了）</p><h4 id="Moire-pattern——摩尔纹"><a href="#Moire-pattern——摩尔纹" class="headerlink" title="Moire pattern——摩尔纹"></a>Moire pattern——摩尔纹</h4><p>摩尔纹是另外一个经典问题，有时我们拍摄条纹密集的物体，最终的成像却会变成奇怪的波纹条纹，就像下图展示的一样：</p><p><img src="11.png" width="60%"></p><p>这同样是因为采样频率低而产生的问题，当重复图案的周期频率超过采样频率时，图案就会出现一部分的缺失，当我们再现时便会出现这种问题。</p><p>闫老师给出了一个复现摩尔纹的办法，即将左图的奇数行奇数列删除，将其余部分重新拼合（也就是图片缩小为原来的1/4），再将其按原来的大小显示，就会变成右图这样的情况。</p><p>这个过程相当于将横向和纵向的采样频率各下降一半，此时其频率低于原始图案的重复频率，便出现了摩尔纹。</p><h4 id="Wagon-wheel-effect——车轮效应"><a href="#Wagon-wheel-effect——车轮效应" class="headerlink" title="Wagon wheel effect——车轮效应"></a>Wagon wheel effect——车轮效应</h4><p>在下图中，我们顺时针旋转一个轮盘，但奇怪的是，轮盘上的一些部分看上去像是在逆时针旋转。</p><p><img src="12.gif" alt=""></p><p>这种现象被称为车轮效应，与上述两者不同，这是时间维度上的采样频率不够而导致的。</p><h3 id="了解频率"><a href="#了解频率" class="headerlink" title="了解频率"></a>了解频率</h3><p>到这里我们已经提到了很多次频率这个词了，现在我们需要深入介绍一下。</p><h4 id="采样频率的影响"><a href="#采样频率的影响" class="headerlink" title="采样频率的影响"></a>采样频率的影响</h4><p>这里分析一般情况下，采样频率低为什么会造成走样。</p><p>以下图为例，假设我们要对蓝色的正弦波进行采样，但采样频率偏低，采样到的几个点已经标注在了图上：</p><p><img src="16.png" alt=""></p><p>但如果我们再引入一个函数，即图中的黑色正弦波，用相同的频率进行采样，那我们的采样结果将和之前的一致。</p><p>也就是说，用相同的办法对两个频率差距很大的函数进行采样，居然得到了一样的结果，这便是走样出现的原因。</p><h4 id="Fourier-Transform——傅里叶变换"><a href="#Fourier-Transform——傅里叶变换" class="headerlink" title="Fourier Transform——傅里叶变换"></a>Fourier Transform——傅里叶变换</h4><p>在微积分当中我们应该学过傅里叶级数，即任何周期函数都可以用正弦函数和余弦函数构成的无穷级数来表示。</p><p>其一般表达式为：</p><script type="math/tex; mode=display">f(x) = \sum_{n=0}^{\infty} \left( a_n \cos\left(2\pi fnx\right) + b_n \sin\left(2\pi fnx\right) \right)</script><p>通常我们都是在有限范围内处理函数，所以我们可以近似地认为可以用傅里叶级数来表达任何函数。</p><p> 而我们观察傅里叶级数可以知道，它实际上是无数个不同频率的正弦波和余弦波组成的，那么我们就可以将这个函数拆分为不同的频率段，为实现这一过程，我们使用的变换为傅里叶变换。</p><p>傅里叶变换的公式为：</p><script type="math/tex; mode=display">F(\omega) = \int_{-\infty}^{\infty} f(t) \cdot e^{-2\pi i\omega t} \, dt</script><p>其逆变换为：</p><script type="math/tex; mode=display">f(t) = \int_{-\infty}^{\infty} F(\omega) \cdot e^{2\pi i\omega t} \, d\omega</script><p>这样我们就可以把一个函数在其原始域（通常是时域）和频域之间进行相互转换了。</p><p>下图展示了对图片应用傅里叶变换后的结果：</p><p><img src="17.png" width="60%"></p><p>右图的中心区域代表低频信号，越靠外表示的信号频率越高，不难看出这张图片的大多数信息都集中在低频区。</p><p>（事实上很多图片的信息都是集中在低频区）</p><p>另外在频率图中还有两条相互垂直的白线，这是因为我们在应用傅里叶变换时，都希望原函数是周期函数，于是我们会将原图复制很多份，像铺地板一样铺在一起，这样会导致在每张图的边界处产生信号的跳变，从而形成这两条白线。</p><p>我们主要关注图片本身的信息，因此可以忽略这两条白线。</p><p>所以说，傅里叶变换让我们能从频率上“看”到这张图。</p><h4 id="Filtering——滤波"><a href="#Filtering——滤波" class="headerlink" title="Filtering——滤波"></a>Filtering——滤波</h4><p>滤波是信号处理领域中的一项重要任务，它指的是通过应用一种称为滤波器的函数或操作，对输入信号进行变换或修改，这里先介绍一些简单的滤波方式。</p><p>首先是<strong>高通滤波</strong>，我们会将低频信号全部过滤掉，它就会产生这样的效果：</p><p><img src="18.png" width="60%"></p><p>可以看出，图片中剩下的信息基本上都是”边界“，这并不难理解，因为边界两边往往会发生剧烈的变化，所以会包含很更多的高频信号。</p><p>相反地，还有<strong>低通滤波</strong>，即过滤掉高频信号，它的效果是这样的：</p><p><img src="19.png" width="60%"></p><p>图中只剩下了模糊的色块，原因与高通滤波是一致的，只是这里我们删除了边界。</p><p>或者我们也可以只取中间的一部分信号：</p><p><img src="20.png" width="60%"></p><p>事实上，滤波的内容并不仅仅只是简单的删除一部分信号，针对不同的问题，我们会对原始信号进行不同的滤波方式（例如下文就要介绍的卷积）。</p><p>我们可以看出，从频域的角度来分析图片，无疑是一个全新且实用的角度。</p><h4 id="Convolution——卷积"><a href="#Convolution——卷积" class="headerlink" title="Convolution——卷积"></a>Convolution——卷积</h4><p>卷积是图像处理中非常常见的一种操作，为了进行卷积，我们首先需要定义一个卷积核。</p><p>在下图中，我们定义的卷积核就是$[1/4,1/2,1/4]$，Signal是我们的原始信号。</p><p>进行卷积操作，就是将卷积核与原始信号对齐，然后类似向量点积一样进行成绩求和得到结果：</p><p><img src="21.png" width="60%"></p><p>计算完后将卷积核向右移动，对齐下一个信号，再次进行计算：</p><p><img src="22.png" width="60%"></p><p>直到所有的信号都计算完毕，卷积操作也就结束了。</p><p>如果Signal是我们的原始图片，那么从Signal到Result的过程就是一个滤波，Filter被称为滤波器。</p><p>卷积操作拥有两个对偶的特性：</p><ol><li>在空间域上进行卷积操作，相当于在频域上进行乘积操作。</li><li>在空间域上进行乘积操作，相当于在频域上进行卷积操作。</li></ol><p>该定理在这里我们不予证明，借由这个性质，我们进行卷积滤波时就可以有两种做法。</p><p><strong>做法一</strong>：</p><ul><li>直接在空间域上计算卷积</li></ul><p><strong>做法二</strong>：</p><ul><li>将图片和卷积核从空间域转换为频域（使用傅里叶变换）</li><li>在频域上进行乘法运算</li><li>将频域转换为空间域（使用逆傅里叶变换） </li></ul><p>下图展示了上述两种做法的过程：</p><p><img src="23.png" width="60%"></p><p>图中的这种滤波器被叫做方框滤波器（Box Filter），它是一个$n×n$的矩阵，其所有元素都是$\frac{1}{n×n}$。</p><p>其本质是计算了区域内所有像素的平均值，它在空间域与频域上的情况如下所示：</p><p><img src="24.png" width="50%"></p><p>如果我们加大方框滤波器的尺寸，那它对应的频率信号会变低：</p><p><img src="25.png" width="50%"></p><p>反映在实际效果上，就是我们使用的方框滤波器越大，那么结果图就会越模糊。</p><h4 id="从频域的角度理解采样"><a href="#从频域的角度理解采样" class="headerlink" title="从频域的角度理解采样"></a>从频域的角度理解采样</h4><p>现在我们可以从频域的角度来理解采样了。</p><p>回想我们之前提到的采样，实际上是使用了一个冲激函数与原函数相乘。下图中，图（a）是原函数，图（c）是冲激函数，进行采样得到的就是图（e）中的函数。</p><p><img src="26.png" width="60%"></p><p>刚才我们说过，在空间域上进行乘积操作，相当于在频域上进行卷积操作。因此从频域的角度来看，我们是做了一个函数卷积，如图（b）（d）（f）所示。</p><p>图（d）仍然是冲激函数，因为冲激函数在频域上依然是冲激函数，但周期不同。</p><p>所以<strong>采样的本质，是在重复原始信号的频谱</strong>。采样的频率，影响了频谱中重复信号的距离。</p><p>也就是说，如果我们的采样频率过低，会导致重复信号产生重叠，从而导致走样的出现。</p><p><img src="27.png" width="60%"></p><p>通过提高采样频率，能够从根本上解决走样的问题，但缺点是需要更大的开销，以及更多的像素。</p><h3 id="Blurring（Pre-Filtering）——模糊"><a href="#Blurring（Pre-Filtering）——模糊" class="headerlink" title="Blurring（Pre-Filtering）——模糊"></a>Blurring（Pre-Filtering）——模糊</h3><p>解决采样的Artifacts，除了提高采样频率，我们还可以在采样前对原始图案进行模糊处理，如下图：</p><p><img src="13.png" width="60%"></p><p>这么做能让边界处的像素使用中间颜色值，从而降低视觉上的锯齿感，下面是应用模糊前后的对比图：</p><p><img src="14.png" width="60%"></p><p>从频域的角度上说，将图像模糊之后，高频信号被滤除，于是采样后的信号便不会再重叠。</p><p><img src="28.png" width="60%"></p><p>这也解释了为什么模糊操作一定要在采样前进行，而不能颠倒两者的顺序。</p><p>具体的做法就是对图片进行一个卷积操作，然后采样即可。</p><h3 id="Supersampling——超级采样"><a href="#Supersampling——超级采样" class="headerlink" title="Supersampling——超级采样"></a>Supersampling——超级采样</h3><p>对于像素点的着色，我们可以更加直观地来看，下图展示了几种状态的像素着色，它们的区别在于本身有多少比例在三角形外和三角形内。</p><p><img src="29.png" width="60%"></p><p>可以发现，在三角形内的部分比例越高，像素着色越白，反之则越黑。</p><p>但其实这个覆盖比例是很难计算的，所以在实际应用中，我们使用另一种方法来近似。</p><p>我们假设每一个像素是可以再分的，例如我们将一个像素看作16个更小的像素：</p><p><img src="30.png" alt=""></p><p>分别判断16个点是否在三角形内，然后根据结果来近似得出三角形的覆盖率。</p><p>举一个具体的例子，我们用原始采样法来绘制三角形可能是这样的：</p><p><img src="31.png" width="60%"></p><p>使用超级采样的话，我们先将每个像素看作4个小像素，那么经过采样判断，结果应是：</p><p><img src="32.png" width="60%"></p><p>但我们知道，实际上每个像素只能着一色，所以对于每个实际像素，我们计算在三角形内的小像素比例。</p><p><img src="33.png" width="60%"></p><p>例如上方这个角处的像素，它有三个小像素在三角形内，所以该像素的取值就应是0.75，按此方式计算完所有像素，就完成了该三角形的绘制，并达到抗锯齿的效果。</p><h2 id="遮挡难题"><a href="#遮挡难题" class="headerlink" title="遮挡难题"></a>遮挡难题</h2><p>现在我们掌握了绘制平面图形的技术，但我们最初的问题可是绘制三维物体，三维物体转换到平面上时会出现<strong>遮挡</strong>问题，也就是物体互相覆盖的情形，为了保证正确成像，我们需要认真考虑这一问题。</p><h3 id="Painter’s-Algorithm——画家算法"><a href="#Painter’s-Algorithm——画家算法" class="headerlink" title="Painter’s Algorithm——画家算法"></a>Painter’s Algorithm——画家算法</h3><p>一个最简单的想法就是由远及近地进行绘制，这样近的物体就会覆盖远的物体，从而自然地处理遮挡问题，以画一个立方体为例：</p><p><img src="34.png" width="60%"></p><p>我们先绘制其后面，然后绘制左、右、下面，最后绘制上、前面，这样就可以准确表达立方体各个面间的遮挡关系，这一算法就是画家算法。</p><p>从程序的角度思考，我们需要对每个三角的深度来进行排序，假设有$n$个三角形，时间复杂度为$O(n\log(n))$。</p><p><img src="35.png" width="40%"></p><p>但画家算法的适用场景仅限于简单遮挡，如果面临上图中这种情况，那不管我们怎么调整每个三角的绘制顺序，都无法正确表达。</p><h3 id="Z-Buffer——深度缓存"><a href="#Z-Buffer——深度缓存" class="headerlink" title="Z-Buffer——深度缓存"></a>Z-Buffer——深度缓存</h3><p><strong>首先提醒，本文假设相机放在原点，向$z$轴正方向看去，所以默认$z$值为正。</strong></p><p>图形学中我们更常用的一种算法是深度缓存，相比于画家算法，它适用于更多的场景。</p><p>深度缓存的基本思想就是<strong>为每个像素记录最小的z值</strong>（也就是最小的深度值、最浅的距离），然后以此为依据来进行绘制。</p><p>为了实现这一过程，我们使用<strong>DepthBuffer</strong>和<strong>FrameBuffer</strong>来存储信息，其中DepthBuffer用以保存深度信息，Framebuffer用以保存色彩信息。</p><p>这里的DepthBuffer其实就是我们平时所说的深度图，它与我们的绘制结果是同时生成的，我们可以用灰度的形式绘制出来：</p><p><img src="36.png" width="60%"></p><p>我们用伪代码来解释Z-Buffer的过程：</p><pre class="line-numbers language-none"><code class="language-none">for (each triangle T)                   // go through each trianglefor (each sample (x, y, z) in T)if (z&lt;zbuffer[x,y])             // closest sample so farframebuffer[x,y] = rgb;     // update colorzbuffer[x,y] = z;           // update depthelse... // do nothing<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>简单而言就是遍历所有的三角，然后依据$z$值更新对应的DepthBuffer（代码中的zbuffer）和FrameBuffer。</p><p>下图是一个更加直观的示例，其中R代表无限大：</p><p><img src="37.png" width="60%"></p><p>在第一步中，由于红色三角形的深度（5）小于初始值（无限大），所以红色三角形对应的像素被全部更新为5。</p><p>而在第二步中，重点关注蓝色三角形中，和红色三角形重合的地方，某些深度小于5，某些则大于5，对那些小于5的深度进行更新，从而获得了正确的深度缓存。</p><p>假设有$n$个三角形，每个三角形覆盖的像素都是一个可估计的常数值，则时间复杂度为$O(n)$。</p><p>之所以节省了这么多，是因为Z-Buffer解决问题的方式是<strong>最小值</strong>，而非排序。</p><p>不难发现，在Z-Buffer算法中，遍历三角的顺序并不重要，无论顺序如何，最终的结果都是一致的。</p><p>OK，第二篇光栅化笔记，就此完结！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAMES101课程笔记（一）——Transformation</title>
      <link href="/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/"/>
      <url>/2023/09/14/games101-ke-cheng-bi-ji-yi-transformation/</url>
      
        <content type="html"><![CDATA[<h1 id="GAMES101课程笔记（一）——Transformation"><a href="#GAMES101课程笔记（一）——Transformation" class="headerlink" title="GAMES101课程笔记（一）——Transformation"></a>GAMES101课程笔记（一）——Transformation</h1><p>本文基于闫老师的GAMES101课程，如果想要更好的阅读体验，建议搭配原课程一起食用。</p><div style="position: relative;width: 80%;height: 0;padding-bottom: 50%;"><iframe src="//player.bilibili.com/player.html?aid=90798049&amp;bvid=BV1X7411F744&amp;cid=155049937&amp;p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%"> </iframe></div><h2 id="写在本系列之前"><a href="#写在本系列之前" class="headerlink" title="写在本系列之前"></a>写在本系列之前</h2><p>笔者是一位刚刚入学的研究生，浑浑噩噩了一整个大四以后终于决定干点正事。由于自己对计算机图形学很感兴趣，将来也希望能从事游戏相关的行业，所以就慕名来学习GAMES101的课程，并开启此系列作为自己的学习记录，如果文中有任何不正确的地方，还请各位大佬指正。</p><p>本系列略去了很大一部分的基础数学知识，尤其是线性代数部分，如果在阅读本系列时发现公式部分难以理解，建议自行补充对应的数学知识。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>本文的主题是变换（Transformation），从简单的平移、旋转和缩放，到复杂的仿射变换和透视变换，变换为我们提供了控制和呈现图像的有力工具。</p><p>变换不仅仅是计算机图形学的核心，它还渗透到各种领域，如视频游戏、动画制作、虚拟现实、计算机辅助设计和医学成像等。</p><p><img src="25.png" width="60%"></p><p>在图形学中，我们使用矩阵来表达变换，接下来的内容也据此展开。</p><h2 id="2D-Transformation"><a href="#2D-Transformation" class="headerlink" title="2D Transformation"></a>2D Transformation</h2><h3 id="Linear-Transforms——线性变换"><a href="#Linear-Transforms——线性变换" class="headerlink" title="Linear Transforms——线性变换"></a>Linear Transforms——线性变换</h3><p>在图像的变换中，如果变换前后的坐标满足如下关系：</p><script type="math/tex; mode=display">x'=ax+by \\y'=cx+dy</script><p>我们就说这是一个线性变换，依据矩阵的知识，我们可以将上述变换写为矩阵形式：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}a & b\\c & d\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><p>其中矩阵<script type="math/tex">\begin{bmatrix}a & b\\c & d\end{bmatrix}</script>就称为该变换的变换矩阵。</p><p>接下来我们先介绍几种基础的线性变换。</p><h4 id="Scale——缩放变换"><a href="#Scale——缩放变换" class="headerlink" title="Scale——缩放变换"></a>Scale——缩放变换</h4><p>该变换中，图片仅在x轴和y轴上成比例缩放，如下图所示：</p><p><img src="1.png" width="60%"></p><p>缩放变换的矩阵表达形式为：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}s_x & 0\\0 & s_y\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><h4 id="Reflection——反射变换"><a href="#Reflection——反射变换" class="headerlink" title="Reflection——反射变换"></a>Reflection——反射变换</h4><p>在缩放变换的基础之上，如果我们将$s_x$（$s_y$同理）取为负值，则可以实现将图像翻转，例如如果我们做如下变换：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}-1 & 0\\0 & 1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><p> 则变换的效果就会变成这样：</p><p><img src="2.png" width="60%"></p><h4 id="Shear——错切变换"><a href="#Shear——错切变换" class="headerlink" title="Shear——错切变换"></a>Shear——错切变换</h4><p>错切变换比较抽象，在该变换中，我们需要先指定一个方向。</p><p>假如我们指定$x$轴方向，则所有点的坐标变换都满足这样的条件：仅有$x$方向上的坐标发生改变，改变后的值为其原始各方向坐标的线性组合。</p><p>这么解释非常抽象，我们从课程中的具体例子来进行解释：</p><p><img src="3.png" width="60%"></p><p>在图示变换中，这个正方形在x轴方向上进行了错切变换。不难发现，变换前后所有的点，其$y$轴坐标都没有发生变化，因此我们只需关注$x$轴的坐标，依据错切变换的定义，它应满足</p><script type="math/tex; mode=display">x'=mx+ny</script><p>原始正方形的左上角顶点坐标为$(0,1)$，变换后其坐标为$(a,1)$；右上角顶点的原始坐标为$(1,1)$，变换后为$(a+1,1)$。</p><p>代入上述方程，解得$m=1,n=a$</p><p>从而得到该变换的变换矩阵为：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}-1 & a\\0 & 1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><script type="math/tex; mode=display"></script><h4 id="Rotation——旋转变换"><a href="#Rotation——旋转变换" class="headerlink" title="Rotation——旋转变换"></a>Rotation——旋转变换</h4><p>注意，我们这里说的旋转变换是指图像绕<strong>原点</strong>进行旋转，将图像沿逆时针旋转$\theta$的变换如下所示：</p><p><img src="4.png" width="60%"></p><p>不难推导出该变换的变换矩阵为：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}cos\theta & -sin\theta\\sin\theta & cos\theta\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}</script><p>（使用高中数学知识就可以进行推导，此处不再赘述）</p><h3 id="Homogeneous-Coordinates——齐次坐标"><a href="#Homogeneous-Coordinates——齐次坐标" class="headerlink" title="Homogeneous Coordinates——齐次坐标"></a>Homogeneous Coordinates——齐次坐标</h3><h4 id="什么是齐次坐标"><a href="#什么是齐次坐标" class="headerlink" title="什么是齐次坐标"></a>什么是齐次坐标</h4><p>我们思考这样一个问题：我们如何用矩阵表示平面上的平移变换？就像下图中的这种情况：</p><p><img src="5.png" width="60%"></p><p>我们可以很简单地写出这样一个形式：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}1 & 0\\0 & 1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}+\begin{bmatrix}t_x\\t_y \end{bmatrix}</script><p>我们发现，这个矩阵并没法写作线性变换的形式，所以平移<strong>不是线性变换</strong>。</p><p>但作为一个简单且常用的变换，我们希望平移也能和线性变换的矩阵形式统一，于是我们在二维坐标上额外加上一维$w$，变为齐次坐标，形式为$(x,y,w)$。</p><p>其中$w$的取值决定了该坐标表示的是一个点还是一个向量，也就是说：</p><script type="math/tex; mode=display">2D\ point = (x,y,w)^T (w\not=0)\\2D\ vector = (x,y,0)^T</script><p>这也导致在齐次坐标下，<strong>点的表示并不唯一</strong>，对于任何一个坐标$(x,y,w)(w\not=0)$，它代表的其实就是点$(x/w,y/w,1)$。</p><p>（这其实解决了欧式空间中，无穷远点无法表示的问题，以后有空再说8）</p><p>于是，上述的平移变换我们就可以写成：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\\1\end{bmatrix}=\begin{bmatrix}1 & 0 & t_x\\0 & 1 & t_y\\0 & 0  & 1\end{bmatrix}\begin{bmatrix}x\\y\\1\end{bmatrix}</script><p>这样，我们就可以将所有的线性变换，加上平移变换，统一地写为：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\\1\end{bmatrix}=\begin{bmatrix}a & b & t_x\\c & d & t_y\\0 & 0  & 1\end{bmatrix}\begin{bmatrix}x\\y\\1\end{bmatrix}</script><h4 id="齐次坐标的运算"><a href="#齐次坐标的运算" class="headerlink" title="齐次坐标的运算"></a>齐次坐标的运算</h4><p>刚才提到过，齐次坐标通过第三维的数值来区分点和向量，这么设计使得原坐标下的运算仍然兼容，例如：</p><script type="math/tex; mode=display">vector+vector=vector\ (0+0=0)\\point+vector=point\ (1+0=1)</script><p>此外由于齐次坐标点的表达方式，还支持一种运算：</p><script type="math/tex; mode=display">point+point=point\ (1+1=2)</script><p>这种运算的本质是求两个相加点的中点，结合前文内容应该不难理解。</p><h3 id="Inverse-Transform——逆变换"><a href="#Inverse-Transform——逆变换" class="headerlink" title="Inverse Transform——逆变换"></a>Inverse Transform——逆变换</h3><p>逆变换，指的是将变换后的图像变回原图像的过程，如下图：</p><p><img src="6.png" alt=""></p><p>在矩阵形式下，假设原变换的变换矩阵为$M$，则其逆变换的变换矩阵为其逆矩阵$M^{-1}$。</p><p>值得一提的是，对于旋转变换矩阵：</p><script type="math/tex; mode=display">R_\theta=\begin{bmatrix}cos\theta & -sin\theta\\sin\theta & cos\theta\end{bmatrix}</script><p>由于$R_\theta$一个正交矩阵，所以有：</p><script type="math/tex; mode=display">R_{-\theta}=\begin{bmatrix}cos(-\theta) & -sin(-\theta)\\sin(-\theta) & cos(-\theta)\end{bmatrix}=\begin{bmatrix}cos\theta & sin\theta\\-sin\theta & cos\theta\end{bmatrix}=R_\theta^T=R_\theta^{-1}</script><h3 id="Composing-Transforms——复合变换"><a href="#Composing-Transforms——复合变换" class="headerlink" title="Composing Transforms——复合变换"></a>Composing Transforms——复合变换</h3><p>很多时候，我们对图像的变换会涉及多个基础变换，考虑下图所示的变换：</p><p><img src="7.png" width="60%"></p><p>这个变换的一种分解是先进行一个45°的旋转，再向右平移一个单位，即：</p><p><img src="8.png" width="60%"></p><p>使用矩阵来表达上述过程，就是：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\\w'\end{bmatrix}=\begin{bmatrix}cos45° & -sin45° & 0\\sin45°& cos45° & 0\\0 & 0 & 1\end{bmatrix}\begin{bmatrix}1 & 0 & 1\\0 & 1 & 1\\0 & 0  & 1\end{bmatrix}\begin{bmatrix}x\\y\\w\end{bmatrix}</script><p>中间的两个矩阵刚好对应上述两步变换，应用顺序是从右往左。</p><p>这里之所以强调顺序，是因为如果我们交换两个步骤的顺序，也就是先平移再旋转，那产生的结果会完全不同：</p><p><img src="9.png" width="60%"></p><p>这对应的矩阵特性就是矩阵乘法不具有交换律，具体到本例子，就是：</p><script type="math/tex; mode=display">\begin{bmatrix}cos45° & -sin45° & 0\\sin45°& cos45° & 0\\0 & 0 & 1\end{bmatrix}\begin{bmatrix}1 & 0 & 1\\0 & 1 & 1\\0 & 0  & 1\end{bmatrix}\not=\begin{bmatrix}1 & 0 & 1\\0 & 1 & 1\\0 & 0  & 1\end{bmatrix}\begin{bmatrix}cos45° & -sin45° & 0\\sin45°& cos45° & 0\\0 & 0 & 1\end{bmatrix}</script><p>总结来说，假如我们现在有一系列变换$A_1,A_2,A_3,…$，那对应的矩阵表达就是：</p><script type="math/tex; mode=display">x^T =...·A_3·A_2·A_1·x</script><p>另外，由我们的变换一般式：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}a & b\\c & d\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}+\begin{bmatrix}t_x\\t_y \end{bmatrix}\Rightarrow\begin{bmatrix}x'\\y'\\1\end{bmatrix}=\begin{bmatrix}a & b & t_x\\c & d & t_y\\0 & 0  & 1\end{bmatrix}\begin{bmatrix}x\\y\\1\end{bmatrix}</script><p>不难看出，<strong>使用齐次坐标表达变换时，线性变换总是先于平移变换进行</strong>。</p><h2 id="3D-Transformation"><a href="#3D-Transformation" class="headerlink" title="3D Transformation"></a>3D Transformation</h2><p>三维的变换可以看做是二维变换的推广，其一般式也与二维变换的类似：</p><script type="math/tex; mode=display">\begin{bmatrix}x'\\y'\\z'\\1\end{bmatrix}=\begin{bmatrix}a & b & c & t_x\\d & e & f & t_y\\g & h & i & t_z\\0 & 0 & 0  & 1\end{bmatrix}\begin{bmatrix}x\\y\\z\\1\end{bmatrix}</script><h3 id="简单三维变换"><a href="#简单三维变换" class="headerlink" title="简单三维变换"></a>简单三维变换</h3><p>三维下的缩放变换与平移变换仍比较简单，与二维的情况比较相似。</p><p>缩放变换的变换矩阵式为：</p><script type="math/tex; mode=display">S(s_x,s_y,s_z)=\begin{bmatrix}s_x & 0 & 0 & 0\\0 & s_y & 0 & 0\\0 & 0 & s_z & 0\\0 & 0 & 0  & 1\end{bmatrix}</script><p>平移变换的变换矩阵为：</p><script type="math/tex; mode=display">T(t_x,t_y,t_z)=\begin{bmatrix}1 & 0 & 0 & t_x\\0 & 1 & 0 & t_y\\0 & 0 & 1 & t_z\\0 & 0 & 0  & 1\end{bmatrix}</script><h3 id="旋转变换"><a href="#旋转变换" class="headerlink" title="旋转变换"></a>旋转变换</h3><p>在三维情形下，旋转变换变为了绕特定<strong>轴</strong>进行，如下是绕$x$轴进行旋转变换的情况：</p><p><img src="10.png" alt=""></p><p>（本系列按右手定则来进行描述，即右手竖起大拇指握拳，拇指指向正方向，其余四指的方向为旋转正方向）</p><p>据此，我们可以分别写出绕三个轴进行旋转变换的变换矩阵：</p><script type="math/tex; mode=display">R_x(\alpha)=\begin{pmatrix}1 & 0 & 0 & 0\\0 & cos\alpha & -sin\alpha & 0\\ 0 & sin\alpha & cos\alpha & 0\\ 0 & 0 &0 & 1\end{pmatrix}\\R_y(\alpha)=\begin{pmatrix}cos\alpha & 0 & sin\alpha & 0\\0 & 1 & 0 & 0\\ -sin\alpha & 0 & cos\alpha & 0\\ 0 & 0 &0 & 1\end{pmatrix}\\R_z(\alpha)=\begin{pmatrix}cos\alpha & -sin\alpha & 0 & 0\\sin\alpha & cos\alpha & 0 & 0\\ 0 & 0 & 1 & 0\\ 0 & 0 &0 & 1\end{pmatrix}</script><p>其中$R_x(\alpha)$和$R_z(\alpha)$都包含有子矩阵$\begin{pmatrix}cos\alpha &amp; -sin\alpha \ sin\alpha &amp; cos\alpha\end{pmatrix}$，只有$R_y(\alpha)$是相反的旋转角。</p><p>以$z$轴举例（$x$轴同理），设$x$，$y$，$z$三个坐标轴上正方向的单位向量分别为$\boldsymbol{i}$，$\boldsymbol{j}$，$\boldsymbol{k}$，我们有：</p><script type="math/tex; mode=display">i×j=k</script><p>也就是在右手定则下，绕$z$轴旋转的正方向会是先$x$后$y$，符合坐标顺序（也就是$xyz$顺序）。</p><p>反观$y$轴，由于：</p><script type="math/tex; mode=display">k×i=j</script><p>顺序为先$z$后$x$，而在坐标顺序中，$x$排在$z$前面，顺序是相反的，所以这里加上负号。</p><p>（其实这么解释有点笼统，如果把变换矩阵和坐标乘出来看会比较好理解一点，但闫老师就是这么讲的。）</p><h3 id="Euler-angles——欧拉角"><a href="#Euler-angles——欧拉角" class="headerlink" title="Euler angles——欧拉角"></a>Euler angles——欧拉角</h3><p>在三维空间中，旋转是一个非常复杂的问题，因为在平面中仅有两个方向（顺时针与逆时针），但在空间中旋转的方向可以是任意的。</p><p>不过刚才我们知道了，绕坐标轴旋转的变换矩阵是很容易得到的。因此我们可以思考：是否有办法将任意的旋转变换，用这三个基础的旋转来进行描述？</p><p>也就是按下述方式分解任意旋转：</p><script type="math/tex; mode=display">R=R_x(\alpha)R_y(\beta)R_z(\gamma)</script><p>答案是肯定的，这种方式就是所谓的<strong>欧拉角</strong>，旋转所绕轴为$Yaw$（偏航角），$Yaw$（俯仰角），$Roll$（滚动角）。</p><p><img src="11.png" alt=""></p><h3 id="Rodrigues’-Rotation-formula"><a href="#Rodrigues’-Rotation-formula" class="headerlink" title="Rodrigues’ Rotation formula"></a>Rodrigues’ Rotation formula</h3><p>罗德里格斯旋转公式（Rodrigues’ Rotation formula）描述了另外一种旋转变换，即<strong>“物体绕任意轴$\boldsymbol{n}$旋转角度$\boldsymbol{\alpha}$”</strong>的旋转变换。</p><p>在别的地方这种方式也可能被称为“轴角”，即通过一轴一角表示旋转，其具体表达式为：</p><script type="math/tex; mode=display">R(n,\alpha)=cos\alpha·\boldsymbol{I}+(1-cos\alpha)\boldsymbol{nn}^T+sin\alpha·\begin{pmatrix}0 & -n_z & n_y \\n_z & 0 & -n_x\\-n_y & n_x & 0\end{pmatrix}</script><p>其中$\boldsymbol{I}$为单位矩阵，该公式的证明以后有空单独开篇文章写（画饼），有兴趣的读者可以先自行查阅。</p><h2 id="MVP-Transformation"><a href="#MVP-Transformation" class="headerlink" title="MVP Transformation"></a>MVP Transformation</h2><p>现在假想一个场景，就是你正在拍摄一张风景照，那么从三维场景变成相机中的一张照片，这个过程中都发生了些什么呢？</p><p>我们可以认为是进行了这样的三步：</p><ol><li>找到一处漂亮的风景（<strong>model</strong> transformation）</li><li>找到相机的完美角度（<strong>view</strong> transformation）</li><li>按下快门（<strong>projection</strong> transformation）</li></ol><p>以上三步就是计算机图形学中的MVP变换，接下来要重点讲解这些内容。</p><p>在开始之前先在这里写下一个重要的思想，<strong>MVP变换的本质是坐标系的转换</strong>。</p><h3 id="Model-Transformation——模型变换"><a href="#Model-Transformation——模型变换" class="headerlink" title="Model Transformation——模型变换"></a>Model Transformation——模型变换</h3><p>模型变换效果是将<strong>局部坐标</strong>转换至<strong>世界坐标</strong>。</p><p>局部坐标系，有时也被叫做模型空间（Model Space），在游戏引擎或者建模软件中非常常见，一般每个模型都会有一个局部坐标系。</p><p><img src="16.png" alt=""></p><p>“头在脖子的上面”，这句话其实就是在用局部坐标系描述人的构成。</p><p>课程中没有提到这一部分，是因为在很多问题中，给出的信息都已经是在世界坐标系下的，但我认为学习计算机图形学，还是得写一下这部分的内容。</p><p>至于变换矩阵的部分，与视图变换的过程还是比较相似的，这里就不详细展开了。</p><h3 id="View-Transformation——视图变换"><a href="#View-Transformation——视图变换" class="headerlink" title="View Transformation——视图变换"></a>View Transformation——视图变换</h3><p>视图变换就是怎么放置相机的问题，其实质是将<strong>世界坐标</strong>转换至<strong>相机坐标</strong>。</p><h4 id="相机的表达与相机坐标系"><a href="#相机的表达与相机坐标系" class="headerlink" title="相机的表达与相机坐标系"></a>相机的表达与相机坐标系</h4><p>讨论怎么放置相机，就要先对相机进行定义，相机的定义需要三个信息：</p><p>位置$e$、朝向$\vec{g}$、上方向$\vec{t}$</p><p>（注意$\vec{t}$与$\vec{g}$都是单位向量，且相互垂直）</p><p><img src="12.png" width="40%"></p><p>这样定义相机的同时，其实也建立起了一个<strong>相机坐标系</strong>。考虑下面的两种情况：</p><p><img src="13.png" alt=""></p><p>由于物体和相机的<strong>相对位置完全一致</strong>，相机拍摄出的照片也是完全一致的。</p><p>这时如果我们使用相机坐标系，就可以将两种情况统一到一起，就像下图所示：</p><p><img src="14.png" alt=""></p><p>在本系列中，我们规定$e$为相机坐标系原点，$\vec{t}$为$y$轴正方向，$\vec{g}$为$z$轴负方向。</p><h4 id="世界坐标到相机坐标"><a href="#世界坐标到相机坐标" class="headerlink" title="世界坐标到相机坐标"></a>世界坐标到相机坐标</h4><p>那么现在问题在于，我们的物体坐标和相机的$e$，$\vec{g}$，$\vec{t}$信息，都是在空间坐标系下的表达，我们该如何将其转换为相机坐标系下的表达呢？</p><p><img src="15.png" alt=""></p><p>以上图为例，我们考虑如何将右上的坐标系变为左下的坐标系。</p><p>其实思路是很简单的，我们先将$e$移动到原点，然后依次将各坐标轴旋转到对应位置即可。</p><p>于是我们能将视图变换的变换矩阵$M_{view}$拆解为一个旋转矩阵和一个平移矩阵的乘积：</p><script type="math/tex; mode=display">M_{view}=R_{view}T_{view}</script><p>平移矩阵$T_{view}$是很容易写出来的，只需要利用$e$就可以得出：</p><script type="math/tex; mode=display">T_{view}=\begin{bmatrix}1 & 0 & 0 & -x_e\\0 & 1 & 0 & -y_e\\0 & 0 & 1 & -z_e\\0 & 0 & 0 & 1\\\end{bmatrix}</script><p>旋转矩阵$R<em>{view}$就比较复杂，现在我们的目标是将$\vec{g}$旋转到$z$轴负方向，$\vec{t}$旋转到$y$轴正方向，这其实是很难写的，但如果我们先求$R</em>{view}^{-1}$，那么就会变得容易一点。</p><p>那$R_{view}^{-1}$的目标，就是将$z$轴负方向旋转到$\vec{g}$，$y$轴正方向旋转到$\vec{t}$，我们可以使用取特殊点的方式来进行求解。</p><p>假设$xyz$坐标系下有一点$(0,1,0)$，那在旋转后的坐标系下，其坐标应为$(x_t,y_t,z_t)$，也就是$\vec{t}$的三维</p><p>（这里就是先前将$\vec{t}$取为单位向量的好处）</p><p>那我们再设：</p><script type="math/tex; mode=display">R_{view}^{-1}=\begin{bmatrix}a & b & c & 0\\d & e & f & 0\\g & h & i & 0\\0 & 0 & 0  & 1\end{bmatrix}</script><p>应该有：</p><script type="math/tex; mode=display">\begin{bmatrix}x_t\\y_t\\z_t\\1\end{bmatrix}=\begin{bmatrix}a & b & c & 0\\d & e & f & 0\\g & h & i & 0\\0 & 0 & 0  & 1\end{bmatrix}\begin{bmatrix}0\\1\\0\\1\end{bmatrix}</script><p>不难得到$b=x_t$，$e=y_t$，$h=z_t$。</p><p>按照这一解法，我么最终可以得到：</p><script type="math/tex; mode=display">R_{view}^{-1}=\begin{bmatrix}x_{g×t} & x_t & x_{-g} & 0\\y_{g×t} & y_t & y_{-g} & 0\\x_{g×t} & z_t & z_{-g} & 0\\0 & 0 & 0  & 1\end{bmatrix}</script><p>最巧妙的一步就在这里，我们能够发现，$R_{view}^{-1}$是一个<strong>正交矩阵</strong>，所以我们得到：</p><script type="math/tex; mode=display">R_{view}={(R_{view}^{-1})}^T=\begin{bmatrix}x_{g×t} & y_{g×t} & z_{g×t} & 0\\x_t & y_t & z_t & 0\\x_{-g} & y_{-g} & z_{-g} & 0\\0 & 0 & 0  & 1\end{bmatrix}</script><p>至此，我们就得到了整个视图变换的变换矩阵。</p><h3 id="Projection-Transformation——投影变换"><a href="#Projection-Transformation——投影变换" class="headerlink" title="Projection Transformation——投影变换"></a>Projection Transformation——投影变换</h3><p>最后一步投影变换变换是进行“照相”，将三维变为二维，也就是<strong>相机坐标</strong>到<strong>屏幕坐标</strong>的转换。</p><p>常见的投影变换有两种，一种是<strong>透视投影</strong>，另一种是<strong>正交投影</strong>。</p><p><img src="17.png" alt=""></p><p>（相信学过美术和设计的同学一定不陌生）</p><h4 id="Orthographic-Projection——正交投影"><a href="#Orthographic-Projection——正交投影" class="headerlink" title="Orthographic Projection——正交投影"></a>Orthographic Projection——正交投影</h4><p>正交投影是最简单的一种投影，它所做的就是直接将物体沿坐标轴投射到平面上。</p><p><img src="18.png" width="60%"></p><p>最简单的做法，就是直接丢掉所有点的$z$坐标，再将其平移缩放至矩形$[-1 ， 1]^2$中。</p><p>（平移缩放的目的是为了方便后续的计算，也是一种约定俗成的做法）</p><p>不过在图形学中，我们通常采用的是另外一种方法。</p><p>首先我们提出一种表达空间长方体的新办法，那就是用$[l,r]×[b,t]×[f,n]$的形式，三个二元组分别表示该长方体在三个坐标轴上所占据的区间，如下图左：</p><p>（其实就是left，right，bottom，top，far和near的首字母）</p><p><img src="19.png" alt=""></p><p>然后我们考虑将该长方体变换到$[-1,1]^3$的标准立方体，图中已经很清楚地展示了这一过程，即先将其平移到原点，再进行缩放即可，该过程的变换矩阵非常容易写出，即：</p><script type="math/tex; mode=display">M_{ortho}=\begin{bmatrix}\frac{2}{r-l} & 0 & 0 & 0 \\0 & \frac{2}{t-b} & 0 & 0 \\0 & 0 & \frac{2}{n-f} &0 \\0 & 0 & 0 & 1 \end{bmatrix}\begin{bmatrix}1 & 0 & 0 & -\frac{r+l}{2}\\0 & 1 & 0 & -\frac{t+b}{2}\\0 & 0 & 1 & -\frac{n+f}{2}\\ 0 & 0 & 0 & 1\end{bmatrix}</script><h4 id="Prespective-Projection——透视投影"><a href="#Prespective-Projection——透视投影" class="headerlink" title="Prespective Projection——透视投影"></a>Prespective Projection——透视投影</h4><p>透视投影是一种更加符合人类视角的投影方式，拥有“近大远小”的特点。</p><p><img src="20.png" alt=""></p><p>在欧式几何中，有一条真理为“平行线永不相交”，但是在投影变换后，原先的两条平行线也会交于一点，就像下图中的两条铁轨</p><p><img src="21.png" width="50%"></p><p>那么我们该如何来做这样的透视投影呢？</p><p>我们首先思考投影变换与正交变换的区别在哪里，在下图中</p><p><img src="/22.png" alt=""></p><p>右边的长方体代表的是正交变换，而在投影变换中，我们是对一个截锥体进行操作。</p><p>在上一部分中，我们已经得到了正交变换的变换矩阵，那现在我们只需要将这个截锥体“挤压”成长方体，就可以直接沿用这一结论了。</p><p>接下来我们详细解释这一过程。先从截锥体的侧面图来看：</p><p><img src="23.png" alt=""></p><p>注意这里的$(x,y,z)$代表的是任意点，$n$代表的近平面的$z$坐标，$(x’,y’,z’)$表示的<strong>不是挤压后的点坐标，而是挤压后的点在近平面上正交投影的点</strong>。</p><p>原课程中似乎是直接将$(x’,y’,z’)$解释为挤压后的点坐标，但事实上，该点应该差不多在蓝点位置：</p><p><img src="24.png" alt=""></p><p>我们将变换后的点坐标记为$(x’’,y’’,z’’)$，由于从$(x’’,y’’,z’’)$到$(x’,y’,z’)$是正交变换，所以有$y’’=y’$。</p><p>利用相似三角形的知识，我们可以得到$y’’=y’=\frac{n}{z}y$，同理有$x’’=\frac{n}{z}x$。</p><p>但$z$轴坐标就不同了，我们第一反应是$z$坐标是不变的，但其实在这种挤压下，$z$坐标是<strong>会发生改变的</strong>。</p><p>（当然，远近两个平面上的点$z$坐标确实不会变）</p><p>根本原因在于我们想用矩阵来表达这种挤压，那其实就默认这种挤压是线性变换。</p><p>如果$z$坐标不变，它就不是一个线性变换，也就无法用矩阵写出了。</p><p>根据我们现在已知的信息，有：</p><script type="math/tex; mode=display">\begin{pmatrix}x''\\y''\\z''\\1\end{pmatrix}=\begin{pmatrix}\frac{n}{z}x\\\frac{n}{z}y\\unknown\\1\end{pmatrix}==\begin{pmatrix}nx\\ny\\unknown\\z\end{pmatrix}</script><p>那我们要求的挤压矩阵$M_{persp\rightarrow{ortho}}$应满足：</p><script type="math/tex; mode=display">M_{persp\rightarrow{ortho}}\begin{pmatrix}x\\y\\z\\1\end{pmatrix}=\begin{pmatrix}nx\\ny\\unknown\\z\end{pmatrix}\tag{1}</script><p>不难解得$M_{persp\rightarrow{ortho}}$的一部分参数为：</p><script type="math/tex; mode=display">M_{persp\rightarrow{ortho}}=\begin{bmatrix}n & 0 & 0 & 0 \\0 & n & 0 & 0 \\a & b & c & d \\0 & 0 & 0 & 1 \end{bmatrix}</script><p>其中$a$，$b$，$c$，$d$仍是未知数。</p><p>刚才我们提到过，远近平面上的点，其$z$坐标不会改变，那我们可以取远近平面上的点来进一步求解。</p><p>取近平面上任意一点$(x,y,n)$，该点变换后的坐标应仍是$(x,y,n)$，即为：</p><script type="math/tex; mode=display">\begin{pmatrix}x''\\y''\\z''\\1\end{pmatrix}=\begin{pmatrix}x\\y\\n\\1\end{pmatrix}==\begin{pmatrix}nx\\ny\\n^2\\n\end{pmatrix}</script><p>由公式(1)，有：</p><script type="math/tex; mode=display">\begin{bmatrix}n & 0 & 0 & 0 \\0 & n & 0 & 0 \\a & b & c & d \\0 & 0 & 0 & 1 \end{bmatrix}\begin{pmatrix}x\\y\\n\\1\end{pmatrix}=\begin{pmatrix}nx\\ny\\n^2\\n\end{pmatrix}</script><p>即对任意的$(x,y,n)$，有：</p><script type="math/tex; mode=display">ax+by+cn+d=n^2</script><p>可得$a=0$，$b=0$，所以该式可以简化为：</p><script type="math/tex; mode=display">cn+d=n^2\tag{2}</script><p>我们再取远平面上一点$(0,0,f,1)$，这是远平面上的中心点，所以变换有的坐标不变，即：</p><script type="math/tex; mode=display">\begin{pmatrix}x''\\y''\\z''\\1\end{pmatrix}=\begin{pmatrix}0\\0\\f\\1\end{pmatrix}==\begin{pmatrix}0\\0\\f^2\\f\end{pmatrix}</script><p>同上述步骤，我们代入(1)式，最终可得：</p><script type="math/tex; mode=display">cf+d=f^2\tag{3}</script><p>联立（2）（3）两式，我们最终解得：</p><script type="math/tex; mode=display">c=n+f\\d=-nf</script><p>至此，我们完成了$M_{persp\rightarrow{ortho}}$的求解，该矩阵的完整形式为：</p><script type="math/tex; mode=display">M_{persp\rightarrow{ortho}}=\begin{bmatrix}n & 0 & 0 & 0 \\0 & n & 0 & 0 \\0 & 0 & n+f & -nf \\0 & 0 & 0 & 1 \end{bmatrix}</script><p>将其与正交投影的变换矩阵相乘，就得到了投影变换的变换矩阵$M_{persp}$：</p><script type="math/tex; mode=display">M_{persp}=M_{ortho}M_{persp\rightarrow{ortho}}</script><h4 id="一些常见概念"><a href="#一些常见概念" class="headerlink" title="一些常见概念"></a>一些常见概念</h4><p>在很多时候我们会提到<strong>视场</strong>（Field-of-View，即FOV）以及<strong>纵横比</strong>（Aspect Ratio）这两个概念，在这里可以做出解释。</p><p>之前提到过，我们可以用$[l,r]×[b,t]×[f,n]$的方式来表示三维空间中的长方体，于是我们定义：</p><p><img src="26.png" alt=""></p><script type="math/tex; mode=display">tan\frac{fovY}{y}=\frac{t}{|n|}\\aspect=\frac{r}{t}</script><p>其中$fovY$表示$y$方向上的视场，$x$方向同理。</p><p>到这里，有关变换的部分就告一段落了，下篇笔记见！</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机图形学 </tag>
            
            <tag> GAMES101 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
